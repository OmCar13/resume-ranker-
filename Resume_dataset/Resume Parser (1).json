{"content": "KOMAL KESARWANI \nMob: - +91-9873993532 | komalkesarwani03@gmail.com |\n\n LinkedIn: https://www.linkedin.com/in/komal-kesarwani-8b41639a/\nObjective \n\nTo achieve a challenging position in Oracle Development in a company, where acquired skills will be utilized towards continued growth and achievements.\n\nSummary\n\n· IT professional with 4.1 years of work experience in IT industry.\n\n· Having basic knowledge in Hadoop stack, HDFS, Sqoop, Pig, Hive, Cloudera\nExperience\n\nSOFTWARE ENGINEER | TATA CONSULTANCY SERVICES LIMITED | NOV 2018- Till date\n· Working on SQL, PL/SQL, ORACLE 11g and UNIX.\n· Responsible for maintaining and modifying the sql queries, functions, procedures, triggers according to the user request and fix the critical issues.\n· Providing the support for banking application as a L2 support.\n\n· Having good knowledge of PL/SQL code debugging.\n\n· Work on different tools Geneos, Control-M, putty, Wintel server.\n· Basic knowledge of Hadoop and spark.\nORACLE DEVELOPER | ESPIRE INFOLABS PVT. LTD | SEP 2015- NOV 2018\n· Worked on SQL, PL/SQL, ORACLE 11g and UNIX \n· Provide end-to-end development of functionalities requested by the firm.\n\n· Carry out analysis of the given CR.\n\n· Provide solutions and implement the required changes.\n\nSkills & Abilities\n\nPROGRAMMING LANGUAGES\n· SQL\n· PL/SQL\n\n· MYSQL\n\n· UNIX\n\n· HIVE\nTOOL USED\n\n· Toad\n\n· Cloudera\n\n· Putty\n\n· VSS (Visual Source Safe) \n· JIRA\n· SQL developer\n\n· Service Now\n\n· Winscp\n DATABASES \n\n· MySQL.\n· HIVE \n\n· Oracle\n  Projects \nProject 1: ABACUS\nClient: FujiXerox\nRole: Oracle Developer\nTechnologies used: Sql, Plsql, Unix, Oracle 11g\n\nDescription: ABACUS stands for Administration Billing and Contract Update System. As the name suggests, it includes the complete process of billing for their worldwide customers up to invoicing. The major functionality of project includes enhancement of the existing functionality.\n\nProject 2: Deutsche Bank\nClient: Deutsche Bank\nRole: Oracle Developer\nTechnologies used: Sql, Plsql, Unix, Oracle 11g, Hadoop, hive\nDescription  It is Banking project, where we work for handling the multiple bank accounts and maintaining the compliance sector responsibilities.Analyze the production support issues and provide the solution to client.s\nWhere we have to look for trades and equities of multiple banks correlated with DB. I look into structural and functional aspect of application, consisting of 4 modules.\nEducation \nBACHELOR OF TECHNOLOGY | Jun 2015 | S.P Memorial Institute of Technology (UPTU)\nMajor: Computer Science \nMinor: Software Engineering \nScored: 73.6 \nPersonal information \n\nDate of Birth: 30/08/1994 \nNationality: Indian \nLanguage Known: Hindi, English \nNumber: 9873993532 \nDeclaration: \n\nI hereby declare that all the information provided is true to the best of my knowledge and belief.\n\n(KOMAL KESARWANI)","annotation":null,"extras":null,"metadata":{"first_done_at":1631178928000,"last_updated_at":1631178928000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "KOMAL KESARWANI \nMob: - +91-9873993532 | komalkesarwani03@gmail.com |\n\n LinkedIn: https://www.linkedin.com/in/komal-kesarwani-8b41639a/\nObjective \n\nTo achieve a challenging position in Oracle Development in a company, where acquired skills will be utilized towards continued growth and achievements.\n\nSummary\n\n· IT professional with 4.4 years of work experience in IT industry.\n\n· Having basic knowledge in Hadoop stack, HDFS, Sqoop, Pig, Hive, Cloudera\nExperience\n\nSOFTWARE ENGINEER | TATA CONSULTANCY SERVICES LIMITED | NOV 2018- Till date\n· Working on SQL, PL/SQL, ORACLE 11g and UNIX.\n· Responsible for maintaining and modifying the sql queries, functions, procedures, triggers according to the user request and fix the critical issues.\n· Providing the support for banking application as a L2 support.\n\n· Having good knowledge of PL/SQL code debugging.\n\n· Work on different tools Geneos, Control-M, putty, Wintel server.\n· Basic knowledge of Hadoop and spark.\nORACLE DEVELOPER | ESPIRE INFOLABS PVT. LTD | SEP 2015- NOV 2018\n· Worked on SQL, PL/SQL, ORACLE 11g and UNIX \n· Provide end-to-end development of functionalities requested by the firm.\n\n· Carry out analysis of the given CR.\n\n· Provide solutions and implement the required changes.\n\nSkills & Abilities\n\nPROGRAMMING LANGUAGES\n· SQL\n· PL/SQL\n\n· MYSQL\n\n· UNIX\n\n· HIVE\nTOOL USED\n\n· Toad\n\n· Cloudera\n\n· Putty\n\n· VSS (Visual Source Safe) \n· JIRA\n· SQL developer\n\n· Service Now\n\n· Winscp\n DATABASES \n\n· MySQL.\n· HIVE \n\n· Oracle\n  Projects \nProject 1: ABACUS\nClient: FujiXerox\nRole: Oracle Developer\nTechnologies used: Sql, Plsql, Unix, Oracle 11g\n\nDescription: ABACUS stands for Administration Billing and Contract Update System. As the name suggests, it includes the complete process of billing for their worldwide customers up to invoicing. The major functionality of project includes enhancement of the existing functionality.\n\nProject 2: Deutsche Bank\nClient: Deutsche Bank\nRole: Oracle Developer\nTechnologies used: Sql, Plsql, Unix, Oracle 11g, Hadoop, hive\nDescription  It is Banking project, where we work for handling the multiple bank accounts and maintaining the compliance sector responsibilities.Analyze the production support issues and provide the solution to client.s\nWhere we have to look for trades and equities of multiple banks correlated with DB. I look into structural and functional aspect of application, consisting of 4 modules.\nEducation \nBACHELOR OF TECHNOLOGY | Jun 2015 | S.P Memorial Institute of Technology (UPTU)\nMajor: Computer Science \nMinor: Software Engineering \nScored: 73.6 \nPersonal information \n\nDate of Birth: 30/08/1994 \nNationality: Indian \nLanguage Known: Hindi, English \nNumber: 9873993532 \nDeclaration: \n\nI hereby declare that all the information provided is true to the best of my knowledge and belief.\n\n(KOMAL KESARWANI)","annotation":[{"label":["Name"],"points":[{"start":2808,"end":2822,"text":"KOMAL KESARWANI"}]},{"label":["Phone"],"points":[{"start":2680,"end":2689,"text":"9873993532"}]},{"label":["Skills"],"points":[{"start":1995,"end":2000,"text":"Oracle"}]},{"label":["Total experience"],"points":[{"start":1958,"end":2407,"text":"Technologies used: Sql, Plsql, Unix, Oracle 11g, Hadoop, hive\nDescription  It is Banking project, where we work for handling the multiple bank accounts and maintaining the compliance sector responsibilities.Analyze the production support issues and provide the solution to client.s\nWhere we have to look for trades and equities of multiple banks correlated with DB. I look into structural and functional aspect of application, consisting of 4 modules"}]},{"label":["Skills"],"points":[{"start":1941,"end":1946,"text":"Oracle"}]},{"label":["Total experience"],"points":[{"start":1605,"end":1884,"text":"Description: ABACUS stands for Administration Billing and Contract Update System. As the name suggests, it includes the complete process of billing for their worldwide customers up to invoicing. The major functionality of project includes enhancement of the existing functionality"}]},{"label":["Skills"],"points":[{"start":1593,"end":1598,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1539,"end":1544,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1478,"end":1483,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":1462,"end":1464,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1406,"end":1408,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1309,"end":1311,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1307,"end":1311,"text":"MYSQL"}]},{"label":["Skills"],"points":[{"start":1300,"end":1302,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1297,"end":1302,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":1291,"end":1293,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1049,"end":1051,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1046,"end":1051,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":1041,"end":1043,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":837,"end":839,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":834,"end":839,"text":"PL/SQL"}]},{"label":["Total experience"],"points":[{"start":591,"end":738,"text":"Responsible for maintaining and modifying the sql queries, functions, procedures, triggers according to the user request and fix the critical issues"}]},{"label":["Skills"],"points":[{"start":563,"end":565,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":560,"end":565,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":555,"end":557,"text":"SQL"}]},{"label":["Experience in current company"],"points":[{"start":486,"end":518,"text":"TATA CONSULTANCY SERVICES LIMITED"}]},{"label":["designation"],"points":[{"start":466,"end":482,"text":"SOFTWARE ENGINEER"}]},{"label":["Skills"],"points":[{"start":185,"end":190,"text":"Oracle"}]},{"label":["Total experience"],"points":[{"start":148,"end":297,"text":"To achieve a challenging position in Oracle Development in a company, where acquired skills will be utilized towards continued growth and achievements"}]},{"label":["Email"],"points":[{"start":41,"end":66,"text":"komalkesarwani03@gmail.com"}]},{"label":["Phone"],"points":[{"start":28,"end":37,"text":"9873993532"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"KOMAL KESARWANI"}]}],"extras":null,"metadata":{"first_done_at":1631178425000,"last_updated_at":1631178425000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Name              : Peeyush Jain                       \nEmail Address:  peeyush4j@gmail.com               \t\t\t\t\nContact No: +91-8793722196, 7610319401                                \n\nObjective\nTo pursue the kind of work that enables me to utilize and enhance my technical skills and capabilities, that leads to growth as an individual as well as that of the organization.\n\n\nProfessional Summary\n\n\t\n\n\t\n· Software Engineer in Zensar Technologies, Pune from 2 Dec 2015 to till date.\n· Three years  eight monthsof Technical experience in Business Intelligence, Data Analysis & Visualization, Advanced Analytics, Data Warehouse Development, Support and Implementation.\n· Excellent experience in BI Tools like Tableau 2018 + , SQL, Oracle 11g database.\n· Designed and Developed reports and dashboards for Cisco Client.\n· Very good knowledge in Business Intelligence concepts and process.\n· Ease in dealing with end users while working on KPIs, Requirements and detail designs.\n· Avid quick learner with strong problem solving skill analytical interpersonal and commination skill. Has good team work skills and invariably meets client expectations.\n· Expertise in conducting root cause analysis, analyzing work pattern and providing insight to developers.\n· Possesses good experience of assisting in the analysis, upgrading of processes & systems and analytical techniques and providing key metrics to the customer to enable them to take business critical decision.\n· Has Experience in Design, Customizations development, Support, Implementation, and Maintenance projects.\n· Good knowledge of Server Admin & Access Management\n· Effective in working independently and collaboratively in teams.\n· Worked in Tabcmd , Web Data Connector , Tabpy and TableauServerClient API.\n\n\n\t\n\n\n\n\n    COMPETENCIES\n \n\tCategory\n\tMajor Skills – Primary \n\t Minor Skills – Secondary \n\n\tVerticals\n\tManufacturing\n\t\n\n\tDomains / Programming Skills \n(As Applicable)\n\tTableau , SQL , Hive , Unix, Shell Scripting\n\tHive, Sqoop,  Python, Job Scheduler\n\n\tTools & Techniques\n\tTableau 2019.1\n\t\n\n\tDatabases\n\tOracle 11g, \n\t\n\n\tSoftware Tools\n\tTableau 2018.2  and \n\tToad, Hue\n\n\tOperating Systems\n\tWindows\n\tLINUX\n\n\n\n                                                 EXPERIENCE SUMMARY\n \n\tCategory\n\tDescription\n\tNo of Projects\n\n\tRole\n\tDeveloper \n\t4\n\n\tLifecycle\n\tEnhancement , Implementation and deployment\n\t4\n\n\n \n\n\n\n                                          \n\n\n\n\n   Education\n                      B.Tech in Computer Science and Engineering from Maulana Azad National Institute of Technology Bhopal\n\n\n\t                     Degree\n\t  Board/University\n\t              Institute\n\tPercentage/CGPA\n\n\t               B.Tech\tMANIT Bhopal\tMANIT Bhopal\t       62.8\nClass XII                          MP Board                    Tek chand jain School, Ambah\t       72.8\nClass X                            MP Board                   Tek chand jain School, Ambah\t        67.8\n\n\n\n\n                         PROFESSIONAL EXPERIENCE\n\n\n\n\t\n\n\t\nProject Profile: \n\nProject Name : Product Quality Dashboard\nClient Name    : Cisco System\nTechnologies  : Tableau 2018 , Hive , Oracle\n\n\nProject Quality Dashboard is designed for the PQE’s for their internal monthly review of the quality metrics. To design and develop the metric PQE’s needs to travers different application to gather the data. By the implementation of this initiative Product Quality dashboard is the single source of gathering the different metric required for the internal review.\n\nRole: Software Engineer\n\nContribution / Highlights  :  \n\nAs a Tableau Developer performed the following responsibilities.\n· Requirement gathering from client.\n· Analysis of data and formation of reuired data.. \n· Examining raw data, drawing conclusions & developing graphical views \n· Designing and Developing reports using Tableau.\n· Implemented LOD, Row level security , Actions , Groups , sets as per requirenment.\n· Testing Using Oracle \n· Fixes the issues identified in testing phase \n· Performed Production Testing, which ensures that the new system will perform correctly in a production environment and interface correctly with other production systems \n· Making Enhancements in Developed Report according to customer need.\n \n\n\t\n\n\n\n\n\n\n\n\t\n\n\t\nProject Profile: \n\nProject Name : Net Promoter Score\nClient Name    : Cisco System\nTechnologies  : Tableau 2018 , Hive , Shell Scripting , Excel , Sqoop\n\n\nNPS is Net promotor score, it is feedback given by end user in form of survey when the SR raised by him is closed. Whenever agent closes a CR, it becomes important for Cisco get feedback on overall handling of the case. A survey is sent to random end user based on logic and the data collected through the survey is used to take analytical decisions.\n\nRole: Software Engineer\n\nContribution / Highlights  :  \n\nAs a team member I was actively involved in the below phases of project :\n· Involved in various phases of analysis of the existing system.\n· I worked on hive for data extraction, loading and scripting.\n· Create sqoop script for loading the data from Hadoop system to oracle or vice-versa.\n· Worked on shell script as per client requirement.\n·  Build dashboard from scratch based on Service request life cycle that helps to end user to get to know how many request we resolved for a given set of time.\n· Preparing the analysis documents that will help in identifying the components required for customization.\n· Worked in writing scripting for fetching and loading the data from one data source to our NPS system.\n·  Provide production support for the deployed project till it is stabilized \n\n\t\n\n\n\n\n\n\t\n\n\t\nProject Profile: \n\nProject Name : SSO\nClient Name    : Cisco System\nTechnologies  : Tableau 10.5 , Hive \n\n\nSSO is an organization under cisco that provide the services to Global TAC organization in terms of all metrics based on the definition of business. All our delivery platform is IBITS application based on Java that redirect to all existing dashboard to tableau server. For backend perspective, we were using Oracle database and migrated into hadoop.\n\nRole: Software Engineer\n\nContribution / Highlights  :  \n\nAs a team member I was actively involved in the below phases of project :\n· Implemented Row level security for restricting the data based on user and User filter.\n· Implemented complex requirement involving use of Level of Details.\n· Preparing the analysis documents that will help in identifying the components required for customization.\n· Worked in Lead Generation, TAC Sales Adoption.. Etc. area.\n· Create dashboard in tableau as per client requirement and implemented new features of tableau like cross data source, Level of detail expression, JavaScript API, Data blending, Security etc.\n· Also created dashboards using different chart like Bar chart, tabular chart, Pie chart, dual combinations etc. in tableau and publish in tableau server. \n· Development of code as per the business requirements.\n· Used Aracadia and Hive connection and worked on migration stuff from oracle to Hadoop.\n· Worked in hive and have basic understanding of Hadoop.\n· Created Solution Design Specification Document and Functional Document in every release.\n· Providing fixes to the issues identified in testing phase.\n· Implemented Web data connector in tableau.\n· Packaging of the developed component to be deployed in production environment.\n· Provide production support for the deployed project till it is stabilized \n\n\n\n\n\t\n\n\t\nProject Profile: \n\nProject Name  : TL 9000\nClient Name    : Cisco System\nTechnologies  : Tableau 9 ,  OBIEE 11g , Oracle\n\n\nThis project TL 9000 is a quality standard developed by the Quality Excellence for Suppliers of Telecommunications Forum, better known as the Quest Forum. TL 9000 is a globally recognized quality standard and is designed to improve telecommunications or information and communication technologies (ICT) products and services.\n\nRole: Software Engineer\n\nContribution / Highlights  :  \n\nAs a team member I was actively involved in the below phases of project :\n· Involved in various phases of analysis of the existing system.\n· Preparing the analysis documents that will help in identifying the components required for customization.\n· Preparing the Source to Target documents and there by identify the road map for effective optimization.\n· Implemented Repository database create joins, variables, alias, import metadata etc. that were extensively used in the project.\n· Create reports in OBIEE as per client requirement and implemented new features of OBIEE like navigation link, prompts, Guided Navigation, Session variable, Presentation variable etc.\n· Deploy the code in stage as well as in Production as per standard.\n· Also created dashboards using different chart like Bar chart, tabular chart, Pie chart, dual combinations etc. in tableau and publish in tableau server. \n· Development of code as per the business requirements.\n· Created Solution Design Specification Document and Functional Document in every release.\n· Providing fixes to the issues identified in testing phase.\n· Packaging of the developed component to be deployed in production environment.\n· Provide production support for the deployed project till it is stabilized \n\n\t\n\n\n\n\n\n\n\n\n\n\nEMPLOYMENT HISTORY\n\n\n\tEmployer\n\tFrom\n\tTo\n\tDesignation\n\tArea\n\n\tZensar Technologies\n\t02 Dec 2015 \n\tTill Date\n\tSoftware Engineer\n\tImplementation, Customizations development, Support and Maintenance, in OBIEE and Tableau, hive and oracle.\n\n\n\nPERSONAL DETAILS\n\nName:            Peeyush Jain \n\nDate of Birth: 08 July 1993\n\nLanguage:     English , Hindi \n\nEmail:            Peeyush4j@gmail.com\n\nMobile:          +91 8793722196 , 7610319401\n\nPermanent Address : Mayur Gali near Post Office Ambah, Morena, Madhya Pradesh\n\nCurrent Address :  Anand Building lane no. 1 Ganpati society Tukaram Nagar Kharadi","annotation":[{"label":["Phone"],"points":[{"start":9625,"end":9634,"text":"7610319401"}]},{"label":["Phone"],"points":[{"start":9612,"end":9621,"text":"8793722196"}]},{"label":["Name"],"points":[{"start":9476,"end":9487,"text":"Peeyush Jain"}]},{"label":["Skills"],"points":[{"start":9412,"end":9418,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":7931,"end":8001,"text":"As a team member I was actively involved in the below phases of project"}]},{"label":["Total experience"],"points":[{"start":7547,"end":7870,"text":"This project TL 9000 is a quality standard developed by the Quality Excellence for Suppliers of Telecommunications Forum, better known as the Quest Forum. TL 9000 is a globally recognized quality standard and is designed to improve telecommunications or information and communication technologies (ICT) products and services"}]},{"label":["Skills"],"points":[{"start":7513,"end":7519,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":6108,"end":6178,"text":"As a team member I was actively involved in the below phases of project"}]},{"label":["Total experience"],"points":[{"start":5700,"end":6047,"text":"SSO is an organization under cisco that provide the services to Global TAC organization in terms of all metrics based on the definition of business. All our delivery platform is IBITS application based on Java that redirect to all existing dashboard to tableau server. For backend perspective, we were using Oracle database and migrated into hadoop"}]},{"label":["Skills"],"points":[{"start":5677,"end":5683,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":5133,"end":5287,"text":"Build dashboard from scratch based on Service request life cycle that helps to end user to get to know how many request we resolved for a given set of time"}]},{"label":["Total experience"],"points":[{"start":4789,"end":4859,"text":"As a team member I was actively involved in the below phases of project"}]},{"label":["Total experience"],"points":[{"start":4380,"end":4728,"text":"NPS is Net promotor score, it is feedback given by end user in form of survey when the SR raised by him is closed. Whenever agent closes a CR, it becomes important for Cisco get feedback on overall handling of the case. A survey is sent to random end user based on logic and the data collected through the survey is used to take analytical decisions"}]},{"label":["Skills"],"points":[{"start":4324,"end":4330,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":3967,"end":4135,"text":" Performed Production Testing, which ensures that the new system will perform correctly in a production environment and interface correctly with other production systems"}]},{"label":["Skills"],"points":[{"start":3800,"end":3806,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":3538,"end":3544,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":3111,"end":3472,"text":"Project Quality Dashboard is designed for the PQE’s for their internal monthly review of the quality metrics. To design and develop the metric PQE’s needs to travers different application to gather the data. By the implementation of this initiative Product Quality dashboard is the single source of gathering the different metric required for the internal review"}]},{"label":["Skills"],"points":[{"start":3080,"end":3086,"text":"Tableau"}]},{"label":["10 %"],"points":[{"start":2809,"end":2911,"text":"Class X                            MP Board                   Tek chand jain School, Ambah\t        67.8"}]},{"label":["12 %"],"points":[{"start":2705,"end":2807,"text":"Class XII                          MP Board                    Tek chand jain School, Ambah\t       72.8"}]},{"label":["Highest degree"],"points":[{"start":2449,"end":2548,"text":"B.Tech in Computer Science and Engineering from Maulana Azad National Institute of Technology Bhopal"}]},{"label":["Skills"],"points":[{"start":2098,"end":2104,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":2035,"end":2041,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1991,"end":1996,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1941,"end":1943,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1931,"end":1937,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1738,"end":1744,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":1251,"end":1456,"text":"Possesses good experience of assisting in the analysis, upgrading of processes & systems and analytical techniques and providing key metrics to the customer to enable them to take business critical decision"}]},{"label":["Total experience"],"points":[{"start":973,"end":1139,"text":"Avid quick learner with strong problem solving skill analytical interpersonal and commination skill. Has good team work skills and invariably meets client expectations"}]},{"label":["Total experience"],"points":[{"start":749,"end":810,"text":"Designed and Developed reports and dashboards for Cisco Client"}]},{"label":["Skills"],"points":[{"start":721,"end":723,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":704,"end":710,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":482,"end":661,"text":"Three years  eight monthsof Technical experience in Business Intelligence, Data Analysis & Visualization, Advanced Analytics, Data Warehouse Development, Support and Implementation"}]},{"label":["Total experience"],"points":[{"start":193,"end":369,"text":"To pursue the kind of work that enables me to utilize and enhance my technical skills and capabilities, that leads to growth as an individual as well as that of the organization"}]},{"label":["Phone"],"points":[{"start":139,"end":148,"text":"7610319401"}]},{"label":["Phone"],"points":[{"start":127,"end":136,"text":"8793722196"}]},{"label":["Email"],"points":[{"start":72,"end":90,"text":"peeyush4j@gmail.com"}]},{"label":["Name"],"points":[{"start":20,"end":31,"text":"Peeyush Jain"}]}],"extras":null,"metadata":{"first_done_at":1631182826000,"last_updated_at":1631182826000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "VANCED COMPUTING \n\n \n\nPOST GRADUATE DIPLO\n\nANALYTICS \n\nCENTRE FOR DEVELOPMENT O\n\n,BANGALORE \n\nSecured 81% during course  \n\n \n\nTeam oriented individual with superb co\n\n, Offering exceptional programming, stati\n\nresearch abilities to extract, clean, and p\n\nthat on data science models. Recently co\n\nGraduate Diploma in BigData Analytics.\n\n \n\nE D U C AT I O N  \n\nFebruray 2019  \n\nto \n\nAugust 2019 \n\n \n\nBACHELOR OF TECHNOL\n\nGautam Buddha Technical \n\n2007-2011 \n\nImage Generation Using Dee\n\nGenerative Adversarial Netw\n\nIn this project first we perform\n\nstudy between Generative Ad\n\n(GAN) and its successor Deep\n\nGenerative Adversarial Netwo\n\nmodels and comparing their r\n\nperformance. \n\nIn second Part using the DCG\n\narchitecture and  parameters\n\nDCGAN paper we developed \n\ngenerated non existing data b\n\ndistribution of original data.\n\nAPI  Used  :  KERAS  with Tens\n\n,Pytorch   \n\n \n\nP R O J E C T S  \n\nS H I P R A  S A X\n \n\nDIPLOMA IN BIGDATA \n\nT OF ADVANCED COMPUTING \n\nb communication abilities \n\n, statistical analysis, and \n\nand prepare data and apply \n\ntly completed Post \n\nics. \n\n \n\nHNOLOGY  (IT) \n\nical University ,Lucknow \n\n Deep convolution \n\network \n\nrformed a comparative \n\ne Adversarial Network \n\neep Convolution \n\network (DCGAN) using two \n\neir respective \n\nDCGAN standard \n\nters proposed by original \n\nped a   model and \n\nata based on the \n\nata. \n\nTensorflow backend \n\n  PYTHON \n\n   R \n\n  MACHINE     \n\n  LEARNING \n\n  SQL \n\n   Tableau \n\n   Spark \n\n Hadoop \n\n  Ms Excel \n\n Hive \n\n    Statistical     \n\n    Analysis \n\n \n\nT E C H N I\n\n Exc\nskil\n\n Good a\ncriti\n\n Pro\n\n Curi\n\n Abi\nwith re\n\n Tea\n\n Tim\n\nN O N  T E\n\nS A X E N A  \n\n         \n\n \n\n \n\n         \n\nN I C A L  S K I L L S  \n\nExcellent communication \n\nskills \n\nGood analytical skills and \n\ncritical thinking \n\nProblem Solving Attitude \n\nCuriosity for discovery \n\nAbility to draw parallel \n\nwith real world problem \n\nTeam oriented individual \n\nTime management  \n\n T E C H N I C A L  S K I L L S  \n\n9719554864 \n\nSaxena.shipra2303@Gmail.com\n\n147-148  Govind  Vihar  Colony \n\nVikas Nagar  Mathura ,UP \n\n281001 \n\n\n\n \n\n \n\n                                                       \n\n \n\n                                     \n\n                                                                                                                                              \n\n                                                                                                                                                      \n\n Hands on  experience of machine learning classification ,clustering, \n\nRegression  and Ensemble learning models. \n\nWorked on Natural language processing projects like Text    \n\nclassification ,sentiment Analysis, Text  summarization.                         \n\nOther  libraries used : Scikitlearn, Spacy, Pyspark \n\n \n\nO t h e r  l i n k s  \n\nLinkedIn: https://www.linkedin.com/in/shipra-saxena-b9574726/ \nHackerrank: https://www.hackerrank.com/shiprathegr8","annotation":null,"extras":null,"metadata":{"first_done_at":1631178951000,"last_updated_at":1631178951000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "VANCED COMPUTING \n\n \n\nPOST GRADUATE DIPLO\n\nANALYTICS \n\nCENTRE FOR DEVELOPMENT O\n\n,BANGALORE \n\nSecured 81% during course  \n\n \n\nTeam oriented individual with superb co\n\n, Offering exceptional programming, stati\n\nresearch abilities to extract, clean, and p\n\nthat on data science models. Recently co\n\nGraduate Diploma in BigData Analytics.\n\n \n\nE D U C AT I O N  \n\nFebruray 2019  \n\nto \n\nAugust 2019 \n\n \n\nBACHELOR OF TECHNOL\n\nGautam Buddha Technical \n\n2007-2011 \n\nImage Generation Using Dee\n\nGenerative Adversarial Netw\n\nIn this project first we perform\n\nstudy between Generative Ad\n\n(GAN) and its successor Deep\n\nGenerative Adversarial Netwo\n\nmodels and comparing their r\n\nperformance. \n\nIn second Part using the DCG\n\narchitecture and  parameters\n\nDCGAN paper we developed \n\ngenerated non existing data b\n\ndistribution of original data.\n\nAPI  Used  :  KERAS  with Tens\n\n,Pytorch   \n\n \n\nP R O J E C T S  \n\nS H I P R A  S A X\n \n\nDIPLOMA IN BIGDATA \n\nT OF ADVANCED COMPUTING \n\nb communication abilities \n\n, statistical analysis, and \n\nand prepare data and apply \n\ntly completed Post \n\nics. \n\n \n\nHNOLOGY  (IT) \n\nical University ,Lucknow \n\n Deep convolution \n\network \n\nrformed a comparative \n\ne Adversarial Network \n\neep Convolution \n\network (DCGAN) using two \n\neir respective \n\nDCGAN standard \n\nters proposed by original \n\nped a   model and \n\nata based on the \n\nata. \n\nTensorflow backend \n\n  PYTHON \n\n   R \n\n  MACHINE     \n\n  LEARNING \n\n  SQL \n\n   Tableau \n\n   Spark \n\n Hadoop \n\n  Ms Excel \n\n Hive \n\n    Statistical     \n\n    Analysis \n\n \n\nT E C H N I\n\n Exc\nskil\n\n Good a\ncriti\n\n Pro\n\n Curi\n\n Abi\nwith re\n\n Tea\n\n Tim\n\nN O N  T E\n\nS A X E N A  \n\n         \n\n \n\n \n\n         \n\nN I C A L  S K I L L S  \n\nExcellent communication \n\nskills \n\nGood analytical skills and \n\ncritical thinking \n\nProblem Solving Attitude \n\nCuriosity for discovery \n\nAbility to draw parallel \n\nwith real world problem \n\nTeam oriented individual \n\nTime management  \n\n T E C H N I C A L  S K I L L S  \n\n9719554864 \n\nSaxena.shipra2303@Gmail.com\n\n147-148  Govind  Vihar  Colony \n\nVikas Nagar  Mathura ,UP \n\n281001 \n\n\n\n \n\n \n\n                                                       \n\n \n\n                                     \n\n                                                                                                                                              \n\n                                                                                                                                                      \n\n Hands on  experience of machine learning classification ,clustering, \n\nRegression  and Ensemble learning models. \n\nWorked on Natural language processing projects like Text    \n\nclassification ,sentiment Analysis, Text  summarization.                         \n\nOther  libraries used : Scikitlearn, Spacy, Pyspark \n\n \n\nO t h e r  l i n k s  \n\nLinkedIn: https://www.linkedin.com/in/shipra-saxena-b9574726/ \nHackerrank: https://www.hackerrank.com/shiprathegr8","annotation":[{"label":["Total experience"],"points":[{"start":2598,"end":2793,"text":"Worked on Natural language processing projects like Text    \n\nclassification ,sentiment Analysis, Text  summarization.                         \n\nOther  libraries used : Scikitlearn, Spacy, Pyspark"}]},{"label":["Total experience"],"points":[{"start":2482,"end":2593,"text":" Hands on  experience of machine learning classification ,clustering, \n\nRegression  and Ensemble learning models"}]},{"label":["Address"],"points":[{"start":2010,"end":2076,"text":"147-148  Govind  Vihar  Colony \n\nVikas Nagar  Mathura ,UP \n\n281001 "}]},{"label":["Email"],"points":[{"start":1981,"end":2007,"text":"Saxena.shipra2303@Gmail.com"}]},{"label":["Phone"],"points":[{"start":1968,"end":1977,"text":"9719554864"}]},{"label":["Name"],"points":[{"start":1616,"end":1638,"text":"N O N  T E\n\nS A X E N A"}]},{"label":["Skills"],"points":[{"start":1472,"end":1479,"text":"Ms Excel"}]},{"label":["Skills"],"points":[{"start":1461,"end":1466,"text":"Hadoop"}]},{"label":["Skills"],"points":[{"start":1452,"end":1456,"text":"Spark"}]},{"label":["Skills"],"points":[{"start":1439,"end":1445,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1430,"end":1432,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1394,"end":1395,"text":" R"}]},{"label":["Skills"],"points":[{"start":1383,"end":1388,"text":"PYTHON"}]},{"label":["Skills"],"points":[{"start":907,"end":908,"text":" R"}]},{"label":["Skills"],"points":[{"start":882,"end":883,"text":" R"}]},{"label":["Highest degree"],"points":[{"start":399,"end":455,"text":"BACHELOR OF TECHNOL\n\nGautam Buddha Technical \n\n2007-2011 "}]},{"label":["Skills"],"points":[{"start":283,"end":284,"text":" R"}]}],"extras":null,"metadata":{"first_done_at":1631178644000,"last_updated_at":1631178644000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "AKHIL BHATNAGAR              \nEmail: akhilbhatnagar13@gmail.com \nContact no: +91-9808967379       \nWork Experience: 2 years (Wipro)              \n\n \n\nPERSONAL DETAILS \n \nFathers Name: Mr.Anupam Bhatnagar \nDate of Birth: 30-sept-1995 \nNationality     : INDIAN \nMarital Status: Single \nLanguages Known: English,Hindi,French(Not Proficient) \nSex: Male \n\n \n\nCAREER OBJECTIVE \nTo be a part of an organization where I can fully utilize my skills and make a significant contribution to the success of \nthe employer and at the same time lead to my individual growth. \n\n \nArea(s) of Interest: Development and Programming \nEDUCATIONAL QUALIFICATIONS \n\n    \n\nYear  Degree/Certificate University/School CGPA / \n% \n\n2011 High School(C.B.S.E.) Dayawati Dharmavira Public \nSchool,Bijnor,UP 8.2 \n\n2013 Intermediate(C.B.S.E.) Dayawati Dharmavira Public \nSchool,Bijnor,UP \n\n83.2% \n\n2017 B.Tech- Computer Science and \nEngineering \n\nSRM University, NCR Campus,UP 8.306 \n\n \n\n• Designed Shopping Management System in C++ in class 12th \n• Designed Supermarket Billing System in MATLAB in B.Tech 1st year \n• Designed Examination Duties Allotment Software in DotNet in B.Tech 3rd year \n• Designed Disease Statistics Prediction and health precautions using data mining techniques in \n\nB.Tech    4th year \n \n\nWipro Limited      Hyderabad    (Oct’17-Feb’18) \n“HSBC Account Developer L1” \n• As a L1 developer,I learned skills like unix,Hadoop,Hadoop Admin.  \n•   I designed small modules  of the project.  \n\n \nWipro Limited      Hyderabad    (Mar’18-Apr’19) \n“HSBC Account Developer L2” \n• As a L2 developer,I learned skills like Datastage,Control-M,Teradata,Linux,RTC.  \n•   I handled 4 projects end to end from requirement gathering to post production support.  \n\n \nWipro Limited      Greater Noida   (Jun’19-Oct’19) \n“CITI Account Incident Management L1” \n• As a L1Support,I did health checks,gathered knowledge on reporting and handling Incidents including different \n\nteams.  \n \n\nACADEMIC \n\nWORK EXPERIENCE \n\n\n\n• Obtained Certificate in 11th Pioneer Olympiad and ranked 34 held at Dayawati Dharmavira Public School in the \nyear 2010. \n\n• Obtained Certificate of Talent Search Quiz Competition Conducted by Moradabad Institute of Technology held \non 3rd December 2012. \n\n• Obtained the certificate of Talent Hunt Examination held at Vivek College Bijnor and secured appreciable rank in \nthe year 2013. \n\n• Qualified CAREER Institute Exam in C++ and secured the grade A in the year 2013. \n• Obtained Certificate of the Annual Robotics Workshop held on 18th January 2014 conducted by I.S.T.E. SRM \n\nStudent Chapter at SRM University NCR Campus. \n• Obtained Certificate of participating in the national workshop in Linguistic Competence held on 31 January 2014 \n\nat SRM University NCR Campus. \n• Scored First place in the CODEJACK event in the fest CYBONITO 2014 held in SRM University, NCR Campus \n\nheld on 25, 26 February 2014. \n• Co-Ordinated the event CODEJACK in the fest CYBONITO 2015 held in SRM University, NCR Campus held in \n\n2016. \n \n\n \n\nCOMPETENCIES \n \n\nLanguages: C, C++, Java,Phython(Limited Functionality),Visual Basic,SQL \n\nPlatforms: Windows,Unix,Linux \n\nMicrosoft Office Tools: Excel,Powerpoint,Word \n\nHardware platforms programmed: 8085, 8086 micro-processor \n\nTools Used: MATLAB,neatbeans,Visual Studio,Teradata,Informatica,SAP BO(Business Objects),Datastage,Control-\nM,RTC,Informatica \n\nDatabase Used: MySQL,Oracle,Teradata \n\nCurrent technology Learning: Hadoop and GCP/AWS \n\n \n\n \n\n \n\n \n\n \n\nEXTRA CURRICULAR ACTIVITIES  \n• The candidate has participated in different Speech Competition and Group Discussions. \n• The candidate has won Second prize in the District Level Swimming Competition in 2010. \n• The candidate has won Second prize in the State Level Swimming Competition in 2010.   \n• The candidate has shown an active participation in various debates, and won numerous essay and art competitions \n\nduring his tenure at Dayawati Dharmavira Public School, Bijnor.  \n• The candidate has secured first rank in the Coding Competition at School level in the year 2012. \n• The candidate has won National Level Prayer Singing Competition in the year 2007.  \n• Obtained certificates of different ranks in various Olympiad. \n\n \n \n \n \n \n\nACHIEVEMENTS \n\n\n\nSTRENGTHS \n• Team Work \n• Discipline \n• Management \n• Adaptability \n\n \n\n \n\n \n\nHOBBIES \n• To play badminton and swimming. \n• Long drives on my motor-bike. \n• Listening music, watching movies. \n• To spare time on computer. \n\n \n \n \n \nI, AKHIL BHATNAGAR do here by confirm that the information given above is true to the best of my \nknowledge.","annotation":[{"label":["Name"],"points":[{"start":4478,"end":4492,"text":"AKHIL BHATNAGAR"}]},{"label":["Skills"],"points":[{"start":4228,"end":4228,"text":"C"}]},{"label":["Skills"],"points":[{"start":4118,"end":4118,"text":"C"}]},{"label":["Skills"],"points":[{"start":4017,"end":4017,"text":"C"}]},{"label":["Skills"],"points":[{"start":4010,"end":4010,"text":"C"}]},{"label":["Skills"],"points":[{"start":3758,"end":3758,"text":"C"}]},{"label":["Skills"],"points":[{"start":3671,"end":3671,"text":"C"}]},{"label":["Skills"],"points":[{"start":3567,"end":3567,"text":"C"}]},{"label":["Skills"],"points":[{"start":3502,"end":3502,"text":"C"}]},{"label":["Skills"],"points":[{"start":3495,"end":3495,"text":"C"}]},{"label":["Skills"],"points":[{"start":3490,"end":3490,"text":"C"}]},{"label":["Skills"],"points":[{"start":3460,"end":3460,"text":"C"}]},{"label":["Skills"],"points":[{"start":3419,"end":3419,"text":"C"}]},{"label":["Skills"],"points":[{"start":3401,"end":3406,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":3397,"end":3399,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3364,"end":3364,"text":"C"}]},{"label":["Skills"],"points":[{"start":3351,"end":3351,"text":"C"}]},{"label":["Skills"],"points":[{"start":3185,"end":3188,"text":"Word"}]},{"label":["Skills"],"points":[{"start":3174,"end":3183,"text":"Powerpoint"}]},{"label":["Skills"],"points":[{"start":3168,"end":3172,"text":"Excel"}]},{"label":["Skills"],"points":[{"start":3106,"end":3108,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3100,"end":3104,"text":"Basic"}]},{"label":["Skills"],"points":[{"start":3062,"end":3068,"text":"Phython"}]},{"label":["Skills"],"points":[{"start":3057,"end":3060,"text":"Java"}]},{"label":["Skills"],"points":[{"start":3052,"end":3054,"text":"C++"}]},{"label":["Skills"],"points":[{"start":3052,"end":3052,"text":"C"}]},{"label":["Skills"],"points":[{"start":3049,"end":3049,"text":"C"}]},{"label":["Skills"],"points":[{"start":3029,"end":3029,"text":"C"}]},{"label":["Skills"],"points":[{"start":3021,"end":3021,"text":"C"}]},{"label":["Skills"],"points":[{"start":2991,"end":2991,"text":"C"}]},{"label":["Skills"],"points":[{"start":2988,"end":2988,"text":"C"}]},{"label":["Skills"],"points":[{"start":2949,"end":2949,"text":"C"}]},{"label":["Skills"],"points":[{"start":2934,"end":2934,"text":"C"}]},{"label":["Skills"],"points":[{"start":2928,"end":2928,"text":"C"}]},{"label":["Skills"],"points":[{"start":2905,"end":2905,"text":"C"}]},{"label":["Skills"],"points":[{"start":2863,"end":2863,"text":"C"}]},{"label":["Skills"],"points":[{"start":2860,"end":2860,"text":"C"}]},{"label":["Skills"],"points":[{"start":2821,"end":2821,"text":"C"}]},{"label":["Skills"],"points":[{"start":2800,"end":2800,"text":"C"}]},{"label":["Skills"],"points":[{"start":2794,"end":2794,"text":"C"}]},{"label":["Skills"],"points":[{"start":2757,"end":2757,"text":"C"}]},{"label":["Skills"],"points":[{"start":2754,"end":2754,"text":"C"}]},{"label":["Skills"],"points":[{"start":2698,"end":2698,"text":"C"}]},{"label":["Skills"],"points":[{"start":2630,"end":2630,"text":"C"}]},{"label":["Total experience"],"points":[{"start":2621,"end":2762,"text":"Obtained Certificate of participating in the national workshop in Linguistic Competence held on 31 January 2014 \n\nat SRM University NCR Campus"}]},{"label":["Skills"],"points":[{"start":2610,"end":2610,"text":"C"}]},{"label":["Skills"],"points":[{"start":2607,"end":2607,"text":"C"}]},{"label":["Skills"],"points":[{"start":2580,"end":2580,"text":"C"}]},{"label":["Skills"],"points":[{"start":2474,"end":2474,"text":"C"}]},{"label":["Total experience"],"points":[{"start":2465,"end":2615,"text":"Obtained Certificate of the Annual Robotics Workshop held on 18th January 2014 conducted by I.S.T.E. SRM \n\nStudent Chapter at SRM University NCR Campus"}]},{"label":["Skills"],"points":[{"start":2416,"end":2418,"text":"C++"}]},{"label":["Skills"],"points":[{"start":2416,"end":2416,"text":"C"}]},{"label":["Skills"],"points":[{"start":2391,"end":2391,"text":"C"}]},{"label":["Skills"],"points":[{"start":2314,"end":2314,"text":"C"}]},{"label":["Total experience"],"points":[{"start":2248,"end":2374,"text":"Obtained the certificate of Talent Hunt Examination held at Vivek College Bijnor and secured appreciable rank in \nthe year 2013"}]},{"label":["Skills"],"points":[{"start":2169,"end":2169,"text":"C"}]},{"label":["Skills"],"points":[{"start":2157,"end":2157,"text":"C"}]},{"label":["Skills"],"points":[{"start":2123,"end":2123,"text":"C"}]},{"label":["Total experience"],"points":[{"start":2114,"end":2241,"text":"Obtained Certificate of Talent Search Quiz Competition Conducted by Moradabad Institute of Technology held \non 3rd December 2012"}]},{"label":["Skills"],"points":[{"start":1998,"end":1998,"text":"C"}]},{"label":["Total experience"],"points":[{"start":1989,"end":2107,"text":"Obtained Certificate in 11th Pioneer Olympiad and ranked 34 held at Dayawati Dharmavira Public School in the \nyear 2010"}]},{"label":["Skills"],"points":[{"start":1980,"end":1980,"text":"C"}]},{"label":["Skills"],"points":[{"start":1963,"end":1963,"text":"C"}]},{"label":["Skills"],"points":[{"start":1957,"end":1957,"text":"C"}]},{"label":["Skills"],"points":[{"start":1792,"end":1792,"text":"C"}]},{"label":["Experience in current company"],"points":[{"start":1739,"end":1743,"text":"Wipro"}]},{"label":["Skills"],"points":[{"start":1638,"end":1638,"text":"C"}]},{"label":["Skills"],"points":[{"start":1611,"end":1611,"text":"C"}]},{"label":["Skills"],"points":[{"start":1534,"end":1534,"text":"C"}]},{"label":["Experience in current company"],"points":[{"start":1481,"end":1485,"text":"Wipro"}]},{"label":["Skills"],"points":[{"start":1335,"end":1335,"text":"C"}]},{"label":["Experience in current company"],"points":[{"start":1282,"end":1286,"text":"Wipro"}]},{"label":["Skills"],"points":[{"start":995,"end":997,"text":"C++"}]},{"label":["Skills"],"points":[{"start":995,"end":995,"text":"C"}]},{"label":["Skills"],"points":[{"start":933,"end":933,"text":"C"}]},{"label":["Skills"],"points":[{"start":930,"end":930,"text":"C"}]},{"label":["Skills"],"points":[{"start":877,"end":877,"text":"C"}]},{"label":["Highest degree"],"points":[{"start":864,"end":910,"text":"2017 B.Tech- Computer Science and \nEngineering "}]},{"label":["Skills"],"points":[{"start":799,"end":799,"text":"C"}]},{"label":["12 %"],"points":[{"start":781,"end":861,"text":"2013 Intermediate(C.B.S.E.) Dayawati Dharmavira Public \nSchool,Bijnor,UP \n\n83.2% "}]},{"label":["Skills"],"points":[{"start":720,"end":720,"text":"C"}]},{"label":["10 %"],"points":[{"start":703,"end":777,"text":"2011 High School(C.B.S.E.) Dayawati Dharmavira Public \nSchool,Bijnor,UP 8.2"}]},{"label":["Skills"],"points":[{"start":691,"end":691,"text":"C"}]},{"label":["Skills"],"points":[{"start":661,"end":661,"text":"C"}]},{"label":["Skills"],"points":[{"start":632,"end":632,"text":"C"}]},{"label":["Skills"],"points":[{"start":616,"end":616,"text":"C"}]},{"label":["Total experience"],"points":[{"start":372,"end":557,"text":"To be a part of an organization where I can fully utilize my skills and make a significant contribution to the success of \nthe employer and at the same time lead to my individual growth."}]},{"label":["Skills"],"points":[{"start":365,"end":365,"text":"C"}]},{"label":["Skills"],"points":[{"start":354,"end":354,"text":"C"}]},{"label":["Experience in current company"],"points":[{"start":125,"end":129,"text":"Wipro"}]},{"label":["Phone"],"points":[{"start":81,"end":90,"text":"9808967379"}]},{"label":["Skills"],"points":[{"start":65,"end":65,"text":"C"}]},{"label":["Email"],"points":[{"start":37,"end":62,"text":"akhilbhatnagar13@gmail.com"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"AKHIL BHATNAGAR"}]}],"extras":null,"metadata":{"first_done_at":1631169972000,"last_updated_at":1631169972000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Dishant Passi\nBusiness Analyst\n\ndishantpassi05@gmail.com\n\n8447029042\n\nlinkedin.com/in/dishantpassi\n\nSeeking challenging assignments in report development that would facilitate the maximum utilisation and application of my broad\nskills. A dynamic professional with experience in reporting tools (plx Dash-boards, SQL and Tableau) with good analytical and problem\nsolving skills.\n\nWORK EXPERIENCE\n\n04/2018 – 11/2019\n\nTechnical Business Analyst\nVaco Binary Semantics (on-site Google)\n\nProject Name- Google Express Customer Order Management\n\nInvolved in understanding business requirement document like BRD, FRD\nwith the client and upper management team\n\nPrepared sales/orders' reports and dashboards depicting the seller\nmetrics of the merchant's data using TABLEAU\n\nHad expertise in both product and project based workflow including\ngathering requirements, implementation.\n\nPrepared and performed unit test cases on the generated dashboards\n\nTrained the new joiners by giving functional and technical knowledge\nrelated to the product and project workflow.\n\n08/2017 – 03/2018\n\nData Analyst\nVaco Binary Semantics (on-site Google)\n\nProject Name- Merchant’s Metadata Analysis and Reporting\n\nUtilized Google PLX tools and implemented new scripts that increased\nthe data quality by 25%\n\nWriting plx (DREMEL-SQL) queries to fetch required data from Database\ntables with adequate filters and applying cleaning mechanism\n\nCollected and analyzed data on established merchants, marketing\nchannels and sources\n\nIdentified, analyzed poor data quality/overmerges at the product's back-\nend\n\n06/2017 – 07/2017\n\nTrainee Analyst\nNIC, Ministry of IT\n\nDeveloped Key Performance Indicators to monitor temperature trends in\nDelhi\n\nUsed python's visualization lib matplotlib by dispalying data via graph\n\nShowed record breaking highest and lowest temperatures in past\ndecade by overlaying a scatter plot\n\nEDUCATION\n\n2013 – 2017\n\nB.tech in Computer Science\nDronacharya college of Engineering\n\nI - XII\nRamjas Public School\n\nSKILLS\n\nBusiness Requirement Gathering &\nAnalysis\n\nTableau MySQL VBA Excel\n\nVisualization of Data Insights\n\nSalesforce(Reporting)\n\nACHIEVEMENTS\n\nStar Performer (Q3- Vaco Binary\nSemantics)\nHave been awarded for exceptional quarterly(Q3)\nperformance in my office\n\nRising Star (Q1- Vaco Binary Semantics)\nFor exceptional consistent quality score in Q1 in\nmy worklfow\n\nDebugging Coordinator\nOrganised various debugging competitions at\ncollege's Technical fest\n\nDistrict Speech contest winner\nRepresented my district (North West) in\nToastmasters International Area Contests\n\nNGO Executive\nOrganised a mini fest for 300 orphanages through\nAIESEC in year 2016\n\nINTERESTS\n\nFootball Tennis\n\non-ground media activites\n\nPublic speaking (Toastmasters)\n\nTraveling\n\nKey Responsibilities\n\nKey Responsibilities\n\nKey Responsibilities\n\nmailto:dishantpassi05@gmail.com\nhttps://www.linkedin.com/in/dishantpassi/","annotation":null,"extras":null,"metadata":{"first_done_at":1631178813000,"last_updated_at":1631178813000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "CURRICULUM VITAE\n\n\n              ARPIT KUMAR DUBEY\n               Address    B - 198, KHANPUR, NEW DELHI, 110062\n               E- Mail       arpitdubey02@gmail.com\n               Contact     +919354520935/ +918865016370\n\nCareer Objective:\n\n“To work in a professional environment with a growing organization and to put my best effort for the technical enhancements of organization and myself”  \n\n\nProfile Summary:\n\nDatabase Developer having experience with 2.2 years of database designing and implementation using SQL server 2008, 2012, 2017 Writing Stored Procedure, Joins, Functions, Complex Query, Creating Trigger, Bulk Insert, Scheduling, Backup, Recovery, Pivot,  Index and Views. Test databases and perform bug fixes. Work on Basic knowledge C, Python. Ability to learn & develop using new technologies quickly. Effective in working independently and collaboratively in teams.\n\nTechnical Skills:\n\nDatabases: MSSQL SERVER 2008, 2012, 2017.\nLanguage: SQL, SWIFT 4, 4.1 and C.\nWeb Technology: HTML, CSS, JQUERY.\nOperating System: WINDOWS 7/8/8.1/10\n\n\nAcademic Profile\n\n· B.Tech (2013-2017) from IIMT ENGINEERING COLLEGE, MEERUT Approved by Dr. A.P.J. Abdul Kalam Technical University, Lucknow, Uttar pradesh.\n\nExperience\n\n   COMPANY -  GAUTAM SOLAR PVT.LTD, NEW DELHI\n    DESIGNATION: Database Developer\n    DURATION: 22-Oct-2018 TO Till Date\n   \n   COMPANY -  MULTIMIND CREATIONS, NEW DELHI\n    DESIGNATION: Database Developer\n    DURATION: 02-Jun-2017 TO 21-Oct-2018\n\n\n\n\nProfessional Experience\n\nProject 1:  MMCNAV (AUTOMATED REAL TIME SMS & SMART TRANSPORT MONITORING  SYSTEM)         \nClient: Multimind Creations\nTechnical Environment: ASP.NET 4.5, C#, BOOTSTRAP, SQL SERVER 2008, Android.\n\nDescription: MMCNAV is specially designed for school/colleges to manage their fleet of buses effortlessly by transforming them into smart bus. It smoothen the administrative task along with the safety of a minor. It keeps parents informed about their child safety with school bus tracking portal from their PC or Laptop. It helps to get real time information with the help of GPS tracking for convenience, safety and quick action in case of emergency.\n\nResponsibilities\n· Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements.\n· Develop database tables and Procedures.\n· Create complex queries, index, joins, views, stored procedures and triggers to support application development.\n\n· Coordinate and work with other technical staff to develop relational databases and secondary databases\n\n\nProject 2: BSES Rajdhani Power Limited (BRPL)\nClient: BSES\nTechnical Environment: ASP.NET 4.5, C#, BOOTSTRAP, SQL SERVER 2008, Android.\nDescription: BRPL distributes power to an area spread over 750 sq. km with a customer density of 3100 per sq. km. It's over 2.4 million customers are spread in 21 districts across South and West areas including. Since taking over distribution, 'BSES' singular mission has been to provide reliable and quality electricity supply.\nResponsibilities\n· Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements.\n· Develop database tables and dictionaries.\n· Create complex queries, joins, index, views, stored procedures and triggers to support application development.\n\n· Coordinate and work with other technical staff to develop relational databases and secondary databases\n\n\n\nProject 3: Customer Management Service (CMS)\nClient: GAUTAM SOLAR\nTechnical Environment: PHP, Wordpress , SQL SERVER 2012, Android.\nDescription: The CRM system is a set of software applications that help an organization determine the needs and preferences of their customers by managing, organizing, tracking and storing all customer interactions. \n\n\n\nResponsibilities\n· Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements.\n· Develop database tables and dictionaries.\n· Create complex queries, joins, index, views, stored procedures and triggers to support application development.\n\n· Coordinate and work with other technical staff to develop relational databases and secondary databases.\n\nProject 4:  Pradhan Mantri Sahaj Bijli Har Ghar Yojana  (Saubhagya Scheme)\nClient:  GOVERNMENT OF INDIA\nTechnical Environment: PHP, BOOTSTRAP, ADO.NET, SQL SERVER 2012, Android. \nDescription: The Saubhagya Scheme or Pradhan Mantri Sahaj Bijli Har Ghar Yojana is an Indian government project to provide electricity to all households. The Pradhan Mantri Sahaj Bijli Har Ghar Yojna, named ‘Saubhagya’, which will be executed just before the next general elections, aims to improve the environment, public health, education and connectivity with the help of last-mile power connections across India. It will help reduce the use of kerosene lamps in non-electrified households. \nResponsibilities\n· Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements.\n· Develop database tables and dictionaries.\n· Create complex queries, joins, index, views, stored procedures and triggers to support application development.\n\n· Coordinate and work with other technical staff to develop relational databases and secondary databases.\n\nProject 5:  Atal Jyoti Yojana (AJAY SCHEME)\n\nClient:  GOVERNMENT OF INDIA\nTechnical Environment: PHP, BOOTSTRAP, ADO.NET, SQL SERVER 2012, Android. \nDescription: Towards this goal, the Ministry of New and Renewable Energy (MNRE) launched the Atal Jyoti Yojana (AJAY) to illuminate dark regions across five states through solar power with high mast solar LED street lights. These lights will be installed on major roads, markets, and public places, thereby contributing to safety, and enabling a better quality of life.\nResponsibilities\n· Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements.\n· Develop database tables and dictionaries.\n· Create complex queries, joins, index, views, stored procedures and triggers to support application development.\n\n· Coordinate and work with other technical staff to develop relational databases and secondary databases.\n\n\n\nPersonal Details\n· Father’s Name\t\t\t:  Mr. Kaushal Kishor Dubey \n· Date of birth   \t\t\t:  05 July 1993\n· Gender                               : Male\n· Marital Status   \t\t:  Unmarried\n· Hobbies\t\t            :  Listening to music, Browsing, Travelling and Cricket.\n· Permanent Address\t\t: 136/4A, RASULABAD, ALLAHABAD\n\nDeclaration\nI hereby declare that all the information are true to and correct to the best of my knowledge.\nPlace:- New Delhi \t                                                                                            (Arpit Kumar Dubey)\nDate:-","annotation":[{"label":["Total experience"],"points":[{"start":6116,"end":6217,"text":"Coordinate and work with other technical staff to develop relational databases and secondary databases"}]},{"label":["Total experience"],"points":[{"start":5828,"end":5952,"text":"Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements"}]},{"label":["Skills"],"points":[{"start":5412,"end":5414,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":5364,"end":5807,"text":"Technical Environment: PHP, BOOTSTRAP, ADO.NET, SQL SERVER 2012, Android. \nDescription: Towards this goal, the Ministry of New and Renewable Energy (MNRE) launched the Atal Jyoti Yojana (AJAY) to illuminate dark regions across five states through solar power with high mast solar LED street lights. These lights will be installed on major roads, markets, and public places, thereby contributing to safety, and enabling a better quality of life."}]},{"label":["Total experience"],"points":[{"start":5185,"end":5286,"text":"Coordinate and work with other technical staff to develop relational databases and secondary databases"}]},{"label":["Total experience"],"points":[{"start":4897,"end":5021,"text":"Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements"}]},{"label":["Skills"],"points":[{"start":4356,"end":4358,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":4099,"end":4200,"text":"Coordinate and work with other technical staff to develop relational databases and secondary databases"}]},{"label":["Total experience"],"points":[{"start":3811,"end":3935,"text":"Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements"}]},{"label":["Skills"],"points":[{"start":3546,"end":3548,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":3334,"end":3435,"text":"Coordinate and work with other technical staff to develop relational databases and secondary databases"}]},{"label":["Total experience"],"points":[{"start":3046,"end":3170,"text":"Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements"}]},{"label":["Skills"],"points":[{"start":2672,"end":2674,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2457,"end":2558,"text":"Coordinate and work with other technical staff to develop relational databases and secondary databases"}]},{"label":["Total experience"],"points":[{"start":2171,"end":2295,"text":"Responsible for understanding client requirement, Design, develop and implement database systems based on client requirements"}]},{"label":["Total experience"],"points":[{"start":1699,"end":2148,"text":"Description: MMCNAV is specially designed for school/colleges to manage their fleet of buses effortlessly by transforming them into smart bus. It smoothen the administrative task along with the safety of a minor. It keeps parents informed about their child safety with school bus tracking portal from their PC or Laptop. It helps to get real time information with the help of GPS tracking for convenience, safety and quick action in case of emergency"}]},{"label":["Skills"],"points":[{"start":1672,"end":1674,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":1514,"end":1581,"text":"MMCNAV (AUTOMATED REAL TIME SMS & SMART TRANSPORT MONITORING  SYSTEM"}]},{"label":["Last company"],"points":[{"start":1365,"end":1394,"text":"MULTIMIND CREATIONS, NEW DELHI"}]},{"label":["Experience in current company"],"points":[{"start":1240,"end":1270,"text":"GAUTAM SOLAR PVT.LTD, NEW DELHI"}]},{"label":["Highest degree"],"points":[{"start":1075,"end":1210,"text":"B.Tech (2013-2017) from IIMT ENGINEERING COLLEGE, MEERUT Approved by Dr. A.P.J. Abdul Kalam Technical University, Lucknow, Uttar pradesh"}]},{"label":["Skills"],"points":[{"start":961,"end":965,"text":"SWIFT"}]},{"label":["Skills"],"points":[{"start":956,"end":958,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":917,"end":919,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":915,"end":919,"text":"MSSQL"}]},{"label":["Skills"],"points":[{"start":514,"end":516,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":415,"end":881,"text":"Database Developer having experience with 2.2 years of database designing and implementation using SQL server 2008, 2012, 2017 Writing Stored Procedure, Joins, Functions, Complex Query, Creating Trigger, Bulk Insert, Scheduling, Backup, Recovery, Pivot,  Index and Views. Test databases and perform bug fixes. Work on Basic knowledge C, Python. Ability to learn & develop using new technologies quickly. Effective in working independently and collaboratively in teams"}]},{"label":["Total experience"],"points":[{"start":242,"end":390,"text":"To work in a professional environment with a growing organization and to put my best effort for the technical enhancements of organization and myself"}]},{"label":["Phone"],"points":[{"start":210,"end":219,"text":"8865016370"}]},{"label":["Phone"],"points":[{"start":195,"end":204,"text":"9354520935"}]},{"label":["Email"],"points":[{"start":142,"end":163,"text":"arpitdubey02@gmail.com"}]},{"label":["Name"],"points":[{"start":33,"end":49,"text":"ARPIT KUMAR DUBEY"}]}],"extras":null,"metadata":{"first_done_at":1631182649000,"last_updated_at":1631182649000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "HARSHITA JAISWAL \n+919434572159 \n\nEmail · jaiswalharshita17@gmail.com \n \n\nMotivated professional with technical expertise to translate business requirements into scalable, highly \n\nresilient and successful system solutions. \n\n \n\n     EXPERIENCE \n\nJANUARY, 2019 – MARCH, 2019  \n\nSTAFF CONSULTANT (TECHNICAL), ORACLE FINANCIAL SERVICES SOFTWARE \n\nLIMITED \n Developed complex requirements related to generation of Account Statements and \n\nDWH using dynamic SQL  which reduced effort hours \n\n Providing guidance, assistance, and support to various clients, deploying solutions \nusing the latest development tools and methodologies \n\n Implemented scripts for automation using Database Scheduler Jobs and SQL \nprocedures   \n\nJULY, 2016 – JANUARY, 2019 \n\nSTAFF CONSULTANT (TECHNICAL), ORACLE FINANCIAL SERVICES SOFTWARE \nLIMITED \n\n Customized and developed application screens, provided post-\nimplementation support, change request management, and production \ntroubleshooting \n\n Server administration for internal development and testing \n\n Translated business requirements into technical requirements and delivered \napplication code that is fully tested and meets the business requirement. \n\n Wrote clean, clear and well-tested code for various projects using PL/SQL. \n Expertise in requirement analysis, development and implementation of a project \n\n \n     EDUCATION \n\nJUNE 2016 \n\nB. TECH IN ELECTRONICS AND COMMUNICATION, NIT DURGAPUR \n\n Graduated with 8.73 CGPA \n\n Core Committee Member of Indian Society for Technical Education, Students Chapter \nDurgapur \n\n Member/Volunteer of Bihari More Education Project, a self-help group which funds \nand helps underprivileged students of Bihari More, Durgapur. \n\n Won many prizes in technical quiz, essay and paper presentations. \n\n \n\n     SKILLS \n\n SQL,PL/SQL and databases(Oracle and \nPostgres) \n\n Proficiency in MS Excel and Tableau \n \n\n \n\n \n\n \n\n \n\n \n\n Teamwork \n\n Strong verbal and written communication \nskills \n\n Excellent analytical, problem solving and \ndecision-making skills \n\n \n\n \n\nmailto:jaiswalharshita17@gmail.com","annotation":[{"label":["Email"],"points":[{"start":2056,"end":2082,"text":"jaiswalharshita17@gmail.com"}]},{"label":["Skills"],"points":[{"start":1881,"end":1887,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1868,"end":1875,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":1809,"end":1811,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1806,"end":1811,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":1802,"end":1804,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":1568,"end":1708,"text":"Member/Volunteer of Bihari More Education Project, a self-help group which funds \nand helps underprivileged students of Bihari More, Durgapur"}]},{"label":["Total experience"],"points":[{"start":1472,"end":1562,"text":"Core Committee Member of Indian Society for Technical Education, Students Chapter \nDurgapur"}]},{"label":["Highest degree"],"points":[{"start":1384,"end":1437,"text":"B. TECH IN ELECTRONICS AND COMMUNICATION, NIT DURGAPUR"}]},{"label":["Skills"],"points":[{"start":1264,"end":1266,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1261,"end":1266,"text":"PL/SQL"}]},{"label":["Total experience"],"points":[{"start":1040,"end":1187,"text":"Translated business requirements into technical requirements and delivered \napplication code that is fully tested and meets the business requirement"}]},{"label":["Total experience"],"points":[{"start":829,"end":972,"text":"Customized and developed application screens, provided post-\nimplementation support, change request management, and production \ntroubleshooting "}]},{"label":["designation"],"points":[{"start":751,"end":766,"text":"STAFF CONSULTANT"}]},{"label":["Skills"],"points":[{"start":702,"end":704,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":491,"end":627,"text":"Providing guidance, assistance, and support to various clients, deploying solutions \nusing the latest development tools and methodologies"}]},{"label":["Skills"],"points":[{"start":455,"end":457,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":356,"end":485,"text":"Developed complex requirements related to generation of Account Statements and \n\nDWH using dynamic SQL  which reduced effort hours"}]},{"label":["Experience in current company"],"points":[{"start":308,"end":352,"text":"ORACLE FINANCIAL SERVICES SOFTWARE \n\nLIMITED "}]},{"label":["designation"],"points":[{"start":278,"end":293,"text":"STAFF CONSULTANT"}]},{"label":["Total experience"],"points":[{"start":74,"end":221,"text":"Motivated professional with technical expertise to translate business requirements into scalable, highly \n\nresilient and successful system solutions"}]},{"label":["Email"],"points":[{"start":42,"end":68,"text":"jaiswalharshita17@gmail.com"}]},{"label":["Phone"],"points":[{"start":21,"end":30,"text":"9434572159"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"HARSHITA JAISWAL"}]}],"extras":null,"metadata":{"first_done_at":1631170062000,"last_updated_at":1631170062000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "CURRICULUM VITAE\n\nSHALLY SINGH\n\nPh No: 91-9667055083\nmailto: sshally4@gmail.com \nOBJECTIVE   \nTo utilize my skills towards a challenging job in a growth oriented and leading edge organization that re-organizes and values individuals as well as the team contribution and which will provide opportunities for growth and achievement. \n\nTotal Work Experience\t: 7.3 yrs\nPower BI Developer\t: 2 yrs\n\n● Worked as Process Analyst \n   Company  : Accenture Solutions Private Ltd., Mumbai \n   Duration   : 17th Sept’18 – 24th June’19 \n\n● Worked as Senior Analyst (Onsite visit to Dublin- Ireland)\n   Company  : HCL Technologies Ltd., Noida\n   Duration   : 1st May’12 – 31st Aug’18\n\n● Worked as SQL Developer\n   Company  : XentaQsys Technologies Pvt Ltd., Gurgaon (Client -AONHEWITT)\n   Duration   : 8th Nov 2010 – to – 27th April 2011\n\nSKILLS\n● Databases\t\t: Oracle 11g/MS SQL Server 2014\n● Reporting Tools (BI Tool): MS Excel, Power BI Desktop\n Tools\t\t\t: SQL*Loader, IMPDP, EXPDP, SQL Developer\n● Campaign Tool\t\t: ADOBE \n● Languages\t\t: PL/SQL, T-SQL\n● Operating System\t: Windows XP, Windows10\n\nSUMMARY\n● An Oracle Certified Professional (OCP) with around 7+ years of total IT experience in support utilizing MS SQL Server, Oracle \n   9i/11g, Data Visualization tool Power BI, along with Campaign Analyst exposure into digital marketing using ADOBE campaign tool. \n● Experience on Power BI Desktop to connect with different data sources like Oracle, SQL Server and MS Excel, importing the data \n   and transforming them in a way to present the data in form of dashboard.\n● Knowledge on publishing Power BI reports to web. \n Having database experience using Oracle 11g, SQL, PL/SQL, T-SQL, Stored procedures, Functions, Exception Handling, Triggers, \n   Indexes.\n Used Data Pump Import and Export, SQL*Loader utilities for data loading in tables.\n Good knowledge on Creating Tables, Views, applying Constraints.\n Used PL/SQL to create Packages, Functions and Procedures. \n● Hands on experience on basic and advanced Excel skills like using Pivot Tables, VLookup and Charts.\n● Hands on experience on gathering data from external sources like Business Express, EDW and Oracle and transforming that \n   required data as per requirement. \n● A good team player with proficiency in technical writing and presentations.\n● Having good analytical, communication and interpersonal skills.\n● Have an ability to work under time constraints and experience on team handling at offshore.\n\nPROFESSIONAL EXPERIENCE\n● Company\t: Accenture Solutions Private Ltd.\n   Client\t\t: Novo Nordisk (US Client-Pharmaceutical company dealing in Medicines)\n   Role\t\t: Power BI Developer (Process Analyst)\nEnvironment\t: ADOBE, HTML, MS SQL Server, MS Excel, Power BI\nDuration\t: Nov’18 – till – 20th June’19  \n \n Roles & Responsibilities\n● Imported data from SQL Server DB to Power BI to generate reports.\n● Created DAX queries to generate computed columns in Power BI.\n● Published reports and Dashboards using Power BI.\n● Fetched data from multiple tables using SQL Join queries, uploaded them into ADOBE tool and executed the deliveries.\n● Gathered and translated business requirements in form of reports and presented to the client.\n● Had been part of team handling, daily and weekly stand up calls with the client.\n● Responsible for data preparation of marketing campaigns as per the requirements by client. Job involves creating flowcharts in \n   ADOBE campaign tool and finding the targetable audience for various types of marketing campaigns such as cross sell, retention, \n   acquisition via different channels like Out Bound Calls (OBC), E-mail.\n\n● Company\t: HCL Technologies Ltd, Noida.\n   Client\t\t: Eir (Ireland Client- Telecommunication company dealing in Fixed, Mobile and Broadband telecommunications)\n   Role\t\t: Power BI Developer (Senior Analyst) \n   Environment\t: ADOBE, HTML, MS SQL Server, MS Excel, Power BI\n   Duration\t: Jan’17 onwards – till – 20th Aug’18    \n\n   Onsite visit to Dublin-Ireland on Business Visa for the Client- eir for understanding of ADOBE Tool (Campaign   \n   Marketing tool), to attend meetings and requirement study about creation of campaign.\n\nRole & Responsibilities\n To create Campaigns Management for fixed and mobile networks using ADOBE as campaign Management tool.\n Using MS-Excel for generating weekly and monthly reports for all the channels (Fixed, Mobile and SMB) \n   with the status and presenting to the higher management.\n Fetching data from multiple tables using Joins.\n Designed, developed and maintained Power BI reports based on the user requirements.\n Developed Power BI data visualization using different types of charts.\n Updating Lists on weekly basis exported from database and external tools to load in ADOBE tool.\n Being part of designing, development and process documentation to produce required reporting, analytics and visualization \n      deliverables.\n Handling offshore team and helping with their concerns.\n Taking daily and weekly calls with the client for the discussion of the business requirement and preparing campaigns \n   accordingly.\n As per the roadmap, distributing the campaigns among the team and gathering the status of campaigns at the end of the day.\n\n \n● Company\t: HCL Technologies Ltd, Noida.\n   Client\t\t: HCL Internal Project (Overtime Calculation – All HCL BSERV processes)\n   Role\t\t: Data Analyst  \n   Environment\t: Oracle SQL Developer, MS Excel\n   Duration\t: Jan’14 onwards – till – Dec’16    \n\n Roles and Responsibilities:\n Used SQL*Loader tool as ETL tool to load data from flat files obtained from various processes \n   every day.\n Writing SQL queries to fetch data from the database.\n Preparing multiple Reports using MS Excel and publishing them using Tableau.\n Processing of data.\n Database maintenance. \n\n● Company\t: HCL Technologies Ltd, Noida.\n   Client\t\t: British Telecom (BT- Telecommunication)\n   Role\t\t: Database Developer  \n   Environment\t: Oracle 9i, MS Excel, Linux\n   Duration\t: June’12 – till – Dec’13    \n\n  Roles and Responsibilities\n  ● Gathering the desired requirements and normalizing the data as per the request.\n  ● Interacting with client via e-mail, chat, phone calls and video conferencing to work as per the request on the desired issues.\n  ● Setting up the new database and normalizing the data accordingly.\n\n● Company\t: XentaQsys Technologies Pvt Ltd., Gurgoan.\n   Client\t\t: AONHewitt\n   Role\t\t: Database Developer  \n   Environment\t: MS SQL Server 2005\n   Duration\t: 5 months \nDescription: The project was basically dealing with the Pension Plans taken by the customers from different Banks like Goldman Sachs, Deutsche bank, Citigroup Inc, . Different schemes were taken up so that good lump sum amount to be given at the time of their retirements.\n\nResponsibilities\n● Extracting data from multiple tables using Joins.\n● Working with the DML statements.\n● Using DTS to transfer files from Excel datasheets to SQL Server database.\n● Using BCP utility for importing exporting data from one database to another database.\n● Designed and tested DTS packages required for data transfer from consolidated files to database tables.\n\nCERTIFICATION\n● Oracle 10g Upgradation from SSI Institute.\n● Oracle 9i OCA & OCP (Oracle Certified Professional) from SSI Institute.\n● GNIIT from NIIT PitamPura.\n\nACADEMIC QUALIFICATION\n● GNIIT from NIIT, PitamPura\n● BCA from Manipal University.\n● XII from St.Sophia’s Sr. Sec School.\n● X from Bal Bharti Public School.","annotation":[{"label":["10 %"],"points":[{"start":7396,"end":7426,"text":"X from Bal Bharti Public School"}]},{"label":["12 %"],"points":[{"start":7357,"end":7391,"text":"XII from St.Sophia’s Sr. Sec School"}]},{"label":["Grad. score"],"points":[{"start":7326,"end":7352,"text":"BCA from Manipal University"}]},{"label":["Highest degree"],"points":[{"start":7297,"end":7322,"text":"GNIIT from NIIT, PitamPura"}]},{"label":["Skills"],"points":[{"start":6417,"end":6422,"text":"MS SQL"}]},{"label":["Number of company worked"],"points":[{"start":6303,"end":6332,"text":"XentaQsys Technologies Pvt Ltd"}]},{"label":["Total experience"],"points":[{"start":6009,"end":6087,"text":"Gathering the desired requirements and normalizing the data as per the request."}]},{"label":["Skills"],"points":[{"start":5481,"end":5490,"text":"SQL*Loader"}]},{"label":["Total experience"],"points":[{"start":4165,"end":4877,"text":" To create Campaigns Management for fixed and mobile networks using ADOBE as campaign Management tool.\n Using MS-Excel for generating weekly and monthly reports for all the channels (Fixed, Mobile and SMB) \n   with the status and presenting to the higher management.\n Fetching data from multiple tables using Joins.\n Designed, developed and maintained Power BI reports based on the user requirements.\n Developed Power BI data visualization using different types of charts.\n Updating Lists on weekly basis exported from database and external tools to load in ADOBE tool.\n Being part of designing, development and process documentation to produce required reporting, analytics and visualization \n      deliverables."}]},{"label":["Total experience"],"points":[{"start":3938,"end":4138,"text":"Onsite visit to Dublin-Ireland on Business Visa for the Client- eir for understanding of ADOBE Tool (Campaign   \n   Marketing tool), to attend meetings and requirement study about creation of campaign."}]},{"label":["Skills"],"points":[{"start":3846,"end":3851,"text":"MS SQL"}]},{"label":["designation"],"points":[{"start":3799,"end":3812,"text":"Senior Analyst"}]},{"label":["Skills"],"points":[{"start":2686,"end":2691,"text":"MS SQL"}]},{"label":["Total experience"],"points":[{"start":1959,"end":2219,"text":" Hands on experience on basic and advanced Excel skills like using Pivot Tables, VLookup and Charts.\n● Hands on experience on gathering data from external sources like Business Express, EDW and Oracle and transforming that \n   required data as per requirement. "}]},{"label":["Skills"],"points":[{"start":1904,"end":1909,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":1784,"end":1793,"text":"SQL*Loader"}]},{"label":["Total experience"],"points":[{"start":1750,"end":1895,"text":"Used Data Pump Import and Export, SQL*Loader utilities for data loading in tables.\n Good knowledge on Creating Tables, Views, applying Constraints"}]},{"label":["Skills"],"points":[{"start":1669,"end":1673,"text":"T-SQL"}]},{"label":["Skills"],"points":[{"start":1661,"end":1666,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":1644,"end":1653,"text":"Oracle 11g"}]},{"label":["Total experience"],"points":[{"start":1560,"end":1747,"text":"Knowledge on publishing Power BI reports to web. \n Having database experience using Oracle 11g, SQL, PL/SQL, T-SQL, Stored procedures, Functions, Exception Handling, Triggers, \n   Indexes."}]},{"label":["Total experience"],"points":[{"start":1354,"end":1556,"text":"Experience on Power BI Desktop to connect with different data sources like Oracle, SQL Server and MS Excel, importing the data \n   and transforming them in a way to present the data in form of dashboard."}]},{"label":["Skills"],"points":[{"start":1196,"end":1201,"text":"MS SQL"}]},{"label":["Total experience"],"points":[{"start":1092,"end":1348,"text":"An Oracle Certified Professional (OCP) with around 7+ years of total IT experience in support utilizing MS SQL Server, Oracle \n   9i/11g, Data Visualization tool Power BI, along with Campaign Analyst exposure into digital marketing using ADOBE campaign tool"}]},{"label":["Skills"],"points":[{"start":1032,"end":1036,"text":"T-SQL"}]},{"label":["Skills"],"points":[{"start":1024,"end":1029,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":943,"end":952,"text":"SQL*Loader"}]},{"label":["Skills"],"points":[{"start":857,"end":862,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":846,"end":855,"text":"Oracle 11g"}]},{"label":["Number of company worked"],"points":[{"start":710,"end":739,"text":"XentaQsys Technologies Pvt Ltd"}]},{"label":["Last company"],"points":[{"start":598,"end":626,"text":" HCL Technologies Ltd., Noida"}]},{"label":["designation"],"points":[{"start":536,"end":549,"text":"Senior Analyst"}]},{"label":["Experience in current company"],"points":[{"start":436,"end":475,"text":"Accenture Solutions Private Ltd., Mumbai"}]},{"label":["Total experience"],"points":[{"start":94,"end":328,"text":"To utilize my skills towards a challenging job in a growth oriented and leading edge organization that re-organizes and values individuals as well as the team contribution and which will provide opportunities for growth and achievement"}]},{"label":["Email"],"points":[{"start":61,"end":78,"text":"sshally4@gmail.com"}]},{"label":["Phone"],"points":[{"start":42,"end":51,"text":"9667055083"}]},{"label":["Name"],"points":[{"start":18,"end":29,"text":"SHALLY SINGH"}]}],"extras":null,"metadata":{"first_done_at":1631183470000,"last_updated_at":1631183470000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "DIPAK SAXENA\n35, Lawerence Street, Block C-3 Flat - K, Dist - Hooghly 712258\nMob: +91 98369 39320, 8617295886; Email: dipak.saxena@rediff.com\n\n\nAn enthusiastic professional 7+years of IT experience as Microsoft SQL Server developer implementing SSIS and SSRS using Microsoft Business Intelligence development studio (MSBI), SQL Server data tools (SSDT) and Power BI\n\n\nTechnical Skills\n\n\tPlatforms\n\tMS SQL Server\n\n\tDatabase\n\tSQL Server 7.0/2000/2005/2008/2012  ; Transact-SQL\n\n\tTool\n\tSSRS , SSIS , Power BI\n\n\n\nCore Competencies\t\n\n· Sound knowledge of SQL Server and T-SQL in constructing triggers, tables, user functions, views, indexes, user profiles, relational database models, data dictionaries, and data integrity.\n· Excellent report creation skills using Microsoft Reporting Services\n· Extensive hands-on experience in several Data Flow transformations including Derived-Column, Script, Slowly Changing Dimension, Look up, Data Conversion, Conditional-Split techniques, Merge, Multicast, Union All.\n· Expertise in Power BI, Power BI Pro, Power BI Mobile.\n· Created, Maintained & scheduled various reports in SSRS like Ad-hoc Reports, Canned Reports, and Master Reports & Parameterized Reports, Drill Down Report, Drill Through Report using SQL Server Reporting Services SSIS 2005.\n· Experience in configuration and maintain Report Manager and Report Server for SSRS, Deployed and Scheduled the Reports in Report Manager\nProfessional Experience\n\nNityo Infotech Pvt Ltd (Business Associate, Kolkata)\nSoftware Developer (May  2018- Oct 2018)\n· Project: Ease Production support\nClient: Chubb Insurance Account\nDatabase: SQL Server 2012\nToll: SSIS, Power Bi\n\nProject Description: \nIBM    design theI inbound and outbound  interface  SSIS package an d  is responsible for extracting data from client  data base  and excel and text file in inbound   database  and load data in outbound   database   Major portion of the project is SQL SERVER 2012 database including SSIS  and Power BI\nResponsibilities:\n· Imported data from SQL Server DB, Azure SQL DB to Power BI to generate reports.\n· Created Dax Queries to generated computed columns in Power BI.\n· Generated computed tables in Power BI by using Dax.\n· Used Power BI, Power Pivot to develop data analysis prototype, and used Power View and Power Map to visualize reports\n· Published Power BI Reports in the required originations and Made Power BI Dashboards available in Web clients and mobile apps\n· Used Power BI Gateways to keep the dashboards and reports up to date.\n· Published reports and dashboards using Power BI.\n\n\nIdexcel Technologies (Business Associate, Kolkata)\nSenior Software Developer (Sep 2016- Dec 2016)\n· Project: ADF\nClient: United Bank Of India\nDatabase: SQL Server 2012\nToll: SSRS 2014, SSIS\n\nProject Description: \nPWC   design the ADF STRUCTURE AND is responsible for extracting data from bank data base in staging database and project in Phase and also responsible for reporting using SSRS.\n Major portion of the project is SQL SERVER 2012 database including SSRS.\n\nResponsibilities:\n· Gathered Business Requirement of the project and File specification and create the design document for as per requirement. \n· Implemented business logic using SSRS (Reporting Services), stored procedures and function.\n· Enhancement with SqlSever 2012, Developed Report using Reporting Services and SQL Stored Procedure Modifications.\n· \n\nDynProIndia Pvt Ltd(Business Associate, Kolkata)\nSoftware Developer (Sep 2014- Sep 2015)\n\n· Project: Group Retirement Scheme(GRS)\nClient: Manulife, Canada\nDatabase: Sql Server 2012\nReporting Toll: SSRS 2008\nToll: Biz talk Server\nProject Description: IBM is responsible for supporting the project, which involves day to day support activities, enhancements in existing ETL. The project, enabled by Large Case (LC), will provide the robust analytical capability necessary to support decision making to achieve anticipated business growth. IBM developed a application called GRS (Group Retirement Scheme). Application based on SSIS, SSRS, BizTalk server and power builder. Application divided different module like Demographic and Eligibility, Payroll, Contribution.\nResponsibilities:\n· Gathered Business Requirement of the project and File specification and create the design document for as per requirement.\n· Implemented business logic using SSRS (Reporting Services), SSIS (Integration Services), stored procedures and functions and BizTalk server.\n· Enhancement with sql server 2008, Developed I Report using Reporting Services , Power BI Sand SQL Stored Procedure Modifications.\n\nD2K Technologies, Mumbai \nSoftware Developer (Aug 2012- 05 May 2014)\n\n· Project: BASELII and Balance Sheet\nClient: United Bank of India(UBI), Kolkata\nDuration: Aug 2012– May 2014; \nTeam Size: 5\nTechnology: .NET\nDatabase: Sql Server 2008\nReporting Toll: SSRS 2008 , Power Bi\nSSIS Toll: SSIS\nProject Description: To suit the requirement of a systematic presentation D2K has designed & developed proprietary report formats to serve the objective of compilation and verification. Basel II aims to encourage the use of modern risk management techniques; and to encourage banks to ensure that their risk management capabilities are commensurate with the risks of their business. Previously, regulators' main focus was on credit risk and market risk. Basel II takes a more sophisticated approach to credit risk, in that it allows banks to make use of internal ratings based Approach - or 'IRB Approach' as they have become known - to calculate their capital requirement for credit risk.\nResponsibilities:\n· Head a team of 5 members; report to the Project Leader.\n· Gathered Business Requirement of the project and implemented business logic using SSRS (Reporting Services), SSIS (Integration Services), stored procedures and functions.\n· Enhancement with SqlSever 2008, Developed Basel II Report using Reporting Services and SQL Stored Procedure Modifications.\n· Developed Power BI model used for financial reporting of P & L and Headcount. \n· Designed and documented the entire Architecture of Power bi Poc\n· Expertise in writing complex DAX functions in Power BI and Power Pivot. \n· Automated Power Query refresh using power shell script and windows task scheduler. \nBeas Consultancy(As a Business Associate), Kolkata\nSoftware Developer (Dec 2011- July 2012)\n· Project: E-procurement\nClient: PPMO-Nepal\nDuration: Dec 2011– July 2012; \nTeam Size: 15\nTechnology: J2EE\nFramework: Struts 2, Springs 2.5 (for database connectivity)\nDatabase: MySQL 5.5\nApplication server: JBoss\nIDE: Eclipse\nProject Description: E-procurement web portal of Nepal is designed to facilitate the bidder to submit their bids through e-submission. Proposed alternative for submission of bid through e-submission is used to increase transparency, non-discrimination, equality of access, and open competition. This site provides easy to use internet access for tender information, information on award of contracts and an alternate facility to submit bids through e-submission to all interested bidders as specified in the Instructions to Bidders.\nResponsibilities:\n· Head a team of 15 members; report to the Project Leader.\n· Gathered Business Requirement of the project and implemented business logic using stored procedures functions and triggers.\n· Enhancement with MySQL, Developed and SQL Stored Procedure Modifications.\n\nBeas Consultancy (As a Business Associate), Kolkata\nSoftware Developer (June 2011- Dec 2011)\n\nProjects Undertaken\n· Encompass\nClient: PWCUK\nDuration: June 2011 – Dec 2011; \nTeam Size: 12\nTechnology: J2EE\nDatabase: MS SQL Server 2005\nProject Description: PWC is responsible for supporting the project, which involves day to day support activities, enhancements in existing MS SQL Server. PWC developed a Sql server 2005 / Java based application called Encompass in 2004. Application based on (MS SQL SERVER, JAVA). With finance functions under increased pressure, with regulatory, compliance and risk management requirements becoming ever more complex, it is essential that where possible, processes are both transparent easily monitored.\nEncompass is the stand alone technology solution from PWC for monitoring, tracking and recording all tax and other finance processes. \n\nResponsibilities:\n· Head a team of 12 members; report to the Project Leader.\n· Gathered Business Requirement of the project and implemented business logic using stored procedures functions and triggers.\n· Enhancement with SQL Server 2005, Developed and SQL Stored Procedure Modifications.\n· Handled Testing (unit testing & system testing) & debugging.\n· Oversaw Maintenance, Trouble Shooting and Documentation.\n\nUtso Consultancy (As a Business Associate), Kolkata\nAsst. System Engineer (Sep 2006- Nov 2008)\n\nProjects Undertaken\n· OCD-Sales Force Automation\nClient: Johnson & Johnson, Kolkata\nDuration: Apr 2008 - Nov 2008; Team Size: 18\nPlatform Used: MS SQL Server, MS .NET Framework, Windows Servers\nSoftware Used: T-SQL, SSRS, SSIS, VB.net\nProject Description: TCS is responsible for supporting the project, which involves day to day support activities, enhancements in existing ETL. The project, enabled by Cognos Data Manager, will provide the robust analytical capability necessary to support decision making to achieve anticipated business growth. TCS developed a Sql server 2005 / ASP.net based application called SFA in 2008. Application based on SSIS, SSRS. Application Loads the data from and in .CSV, Excel file using SSIS Package. Developed a report using SSRS. OCD Developed one tool called GCHT (Global Customer Hierarchy Tool). Front End of the project is developed in VB.Net .Major portion of this project is SQL SERVER 2005 database including SSIS, SSRS. There is also a Web Portion of this application developed by ASP.NET using VB.net.\nResponsibilities:\n· Head a team of 5 members; report to the Project Leader..\n· Gathered Business Requirement of the project and implemented business logic using stored procedures functions and triggers.\n· Handled Testing (unit testing & system testing) & debugging.\n· Handled the Review & Testing of developed codes and fixing the bugs detected in testing phase.\n· Documentation \n· Wrote detailed technical specifications and implementation plans for SQL Server data warehouse extract, transform, and load (ETL) processes. Implementation plans included data definition scripts for tables, views, stored procedures, and SSIS packages. Designed SQL Server data warehouse integrations for OCD-SFA. \n\n· American Psyche System Healthcare (APS)\nClient: American Psyche System Healthcare, Kolkata\nDuration: Sep 2006 - Mar 2008; \nTeam Size: 38\nPlatform Used: MS SQL Server\nSoftware Used: T-SQL, PL/SQL\nProject Description: APS had developed an Oracle9i/ ASP based application called WV CARECONNECTION in 2000. Application loads the encrypted data files and processes them through the Medicaid rules and gives the authorization of no. of units required for medication treatment. APS has also developed another SQL Server/ASP based application based on the existing CARECONNECTION application, which involves development of new web pages and creation of new data extracts supporting the requirements of a new contract between APS and the State of West Virginia in the year of 2003. \nResponsibilities:\n· Gathered Business Requirement of the project; Implemented Business Logic using Packages, Stored Procedures Functions and Triggers.\n· Handled Testing (Unit testing & system testing) & debugging; review & testing of developed codes.\n· Fixing the bugs detected in testing phase.\n\nEducational Qualification\n· B.Com, University Of Calcutta (1996)\n\nResume of Dipak Saxena / Page 1 of 4","annotation":[{"label":["Grad. score"],"points":[{"start":11604,"end":11639,"text":"B.Com, University Of Calcutta (1996)"}]},{"label":["Skills"],"points":[{"start":11007,"end":11016,"text":"SQL Server"}]},{"label":["Total experience"],"points":[{"start":10700,"end":11277,"text":"Project Description: APS had developed an Oracle9i/ ASP based application called WV CARECONNECTION in 2000. Application loads the encrypted data files and processes them through the Medicaid rules and gives the authorization of no. of units required for medication treatment. APS has also developed another SQL Server/ASP based application based on the existing CARECONNECTION application, which involves development of new web pages and creation of new data extracts supporting the requirements of a new contract between APS and the State of West Virginia in the year of 2003. "}]},{"label":["Skills"],"points":[{"start":10660,"end":10669,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":10657,"end":10662,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":10449,"end":10458,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":10425,"end":10428,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":10257,"end":10266,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":9717,"end":9720,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":9711,"end":9714,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":9519,"end":9522,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":9480,"end":9483,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":9412,"end":9415,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":9406,"end":9409,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":8993,"end":9804,"text":"Project Description: TCS is responsible for supporting the project, which involves day to day support activities, enhancements in existing ETL. The project, enabled by Cognos Data Manager, will provide the robust analytical capability necessary to support decision making to achieve anticipated business growth. TCS developed a Sql server 2005 / ASP.net based application called SFA in 2008. Application based on SSIS, SSRS. Application Loads the data from and in .CSV, Excel file using SSIS Package. Developed a report using SSRS. OCD Developed one tool called GCHT (Global Customer Hierarchy Tool). Front End of the project is developed in VB.Net .Major portion of this project is SQL SERVER 2005 database including SSIS, SSRS. There is also a Web Portion of this application developed by ASP.NET using VB.net."}]},{"label":["Skills"],"points":[{"start":8980,"end":8983,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":8974,"end":8977,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":8905,"end":8914,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":8902,"end":8907,"text":"MS SQL"}]},{"label":["designation"],"points":[{"start":8685,"end":8702,"text":"Business Associate"}]},{"label":["Skills"],"points":[{"start":8472,"end":8481,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":7868,"end":7873,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":7751,"end":7760,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":7748,"end":7753,"text":"MS SQL"}]},{"label":["Total experience"],"points":[{"start":7609,"end":8111,"text":"Project Description: PWC is responsible for supporting the project, which involves day to day support activities, enhancements in existing MS SQL Server. PWC developed a Sql server 2005 / Java based application called Encompass in 2004. Application based on (MS SQL SERVER, JAVA). With finance functions under increased pressure, with regulatory, compliance and risk management requirements becoming ever more complex, it is essential that where possible, processes are both transparent easily monitored"}]},{"label":["Skills"],"points":[{"start":7593,"end":7602,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":7590,"end":7595,"text":"MS SQL"}]},{"label":["designation"],"points":[{"start":7399,"end":7416,"text":"Business Associate"}]},{"label":["Total experience"],"points":[{"start":6563,"end":7093,"text":"Project Description: E-procurement web portal of Nepal is designed to facilitate the bidder to submit their bids through e-submission. Proposed alternative for submission of bid through e-submission is used to increase transparency, non-discrimination, equality of access, and open competition. This site provides easy to use internet access for tender information, information on award of contracts and an alternate facility to submit bids through e-submission to all interested bidders as specified in the Instructions to Bidders"}]},{"label":["designation"],"points":[{"start":6266,"end":6283,"text":"Business Associate"}]},{"label":["Skills"],"points":[{"start":6131,"end":6138,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":5749,"end":5752,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":5722,"end":5725,"text":"SSRS"}]},{"label":["Total experience"],"points":[{"start":5640,"end":5808,"text":"Gathered Business Requirement of the project and implemented business logic using SSRS (Reporting Services), SSIS (Integration Services), stored procedures and functions"}]},{"label":["Total experience"],"points":[{"start":4872,"end":5559,"text":"Project Description: To suit the requirement of a systematic presentation D2K has designed & developed proprietary report formats to serve the objective of compilation and verification. Basel II aims to encourage the use of modern risk management techniques; and to encourage banks to ensure that their risk management capabilities are commensurate with the risks of their business. Previously, regulators' main focus was on credit risk and market risk. Basel II takes a more sophisticated approach to credit risk, in that it allows banks to make use of internal ratings based Approach - or 'IRB Approach' as they have become known - to calculate their capital requirement for credit risk"}]},{"label":["Skills"],"points":[{"start":4867,"end":4870,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":4856,"end":4859,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":4835,"end":4838,"text":"SSRS"}]},{"label":["Last company"],"points":[{"start":4582,"end":4605,"text":"D2K Technologies, Mumbai"}]},{"label":["Skills"],"points":[{"start":4531,"end":4538,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":4368,"end":4371,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":4341,"end":4344,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":4029,"end":4032,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":4023,"end":4026,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":3628,"end":4160,"text":"Project Description: IBM is responsible for supporting the project, which involves day to day support activities, enhancements in existing ETL. The project, enabled by Large Case (LC), will provide the robust analytical capability necessary to support decision making to achieve anticipated business growth. IBM developed a application called GRS (Group Retirement Scheme). Application based on SSIS, SSRS, BizTalk server and power builder. Application divided different module like Demographic and Eligibility, Payroll, Contribution"}]},{"label":["Skills"],"points":[{"start":3596,"end":3599,"text":"SSRS"}]},{"label":["designation"],"points":[{"start":3419,"end":3445,"text":"Business Associate, Kolkata"}]},{"label":["designation"],"points":[{"start":3419,"end":3436,"text":"Business Associate"}]},{"label":["Skills"],"points":[{"start":3220,"end":3223,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":3034,"end":3037,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":2960,"end":2963,"text":"SSRS"}]},{"label":["Total experience"],"points":[{"start":2788,"end":3037,"text":"PWC   design the ADF STRUCTURE AND is responsible for extracting data from bank data base in staging database and project in Phase and also responsible for reporting using SSRS.\n Major portion of the project is SQL SERVER 2012 database including SSRS"}]},{"label":["Skills"],"points":[{"start":2760,"end":2763,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2749,"end":2752,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":2727,"end":2736,"text":"SQL Server"}]},{"label":["designation"],"points":[{"start":2597,"end":2623,"text":"Business Associate, Kolkata"}]},{"label":["designation"],"points":[{"start":2597,"end":2614,"text":"Business Associate"}]},{"label":["Skills"],"points":[{"start":2563,"end":2570,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2457,"end":2464,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2389,"end":2396,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2334,"end":2341,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2209,"end":2216,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2179,"end":2186,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2138,"end":2145,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2053,"end":2060,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2022,"end":2031,"text":"SQL Server"}]},{"label":["Total experience"],"points":[{"start":2003,"end":2080,"text":"Imported data from SQL Server DB, Azure SQL DB to Power BI to generate reports"}]},{"label":["Skills"],"points":[{"start":1974,"end":1981,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":1964,"end":1967,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1733,"end":1736,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":1681,"end":1981,"text":"IBM    design theI inbound and outbound  interface  SSIS package an d  is responsible for extracting data from client  data base  and excel and text file in inbound   database  and load data in outbound   database   Major portion of the project is SQL SERVER 2012 database including SSIS  and Power BI"}]},{"label":["Skills"],"points":[{"start":1643,"end":1646,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1621,"end":1630,"text":"SQL Server"}]},{"label":["designation"],"points":[{"start":1474,"end":1491,"text":"Business Associate"}]},{"label":["Experience in current company"],"points":[{"start":1450,"end":1471,"text":"Nityo Infotech Pvt Ltd"}]},{"label":["Skills"],"points":[{"start":1366,"end":1369,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":1275,"end":1278,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1245,"end":1254,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1113,"end":1116,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":1043,"end":1050,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":1029,"end":1036,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":1019,"end":1026,"text":"Power BI"}]},{"label":["Total experience"],"points":[{"start":791,"end":1001,"text":"Extensive hands-on experience in several Data Flow transformations including Derived-Column, Script, Slowly Changing Dimension, Look up, Data Conversion, Conditional-Split techniques, Merge, Multicast, Union All"}]},{"label":["Skills"],"points":[{"start":550,"end":559,"text":"SQL Server"}]},{"label":["Total experience"],"points":[{"start":531,"end":716,"text":"Sound knowledge of SQL Server and T-SQL in constructing triggers, tables, user functions, views, indexes, user profiles, relational database models, data dictionaries, and data integrity"}]},{"label":["Skills"],"points":[{"start":497,"end":504,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":490,"end":493,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":483,"end":486,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":424,"end":433,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":401,"end":410,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":398,"end":403,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":357,"end":364,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":324,"end":333,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":254,"end":257,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":245,"end":248,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":211,"end":220,"text":"SQL Server"}]},{"label":["Total experience"],"points":[{"start":144,"end":364,"text":"An enthusiastic professional 7+years of IT experience as Microsoft SQL Server developer implementing SSIS and SSRS using Microsoft Business Intelligence development studio (MSBI), SQL Server data tools (SSDT) and Power BI"}]},{"label":["Email"],"points":[{"start":118,"end":140,"text":"dipak.saxena@rediff.com"}]},{"label":["Phone"],"points":[{"start":99,"end":108,"text":"8617295886"}]},{"label":["Phone"],"points":[{"start":86,"end":96,"text":"98369 39320"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"DIPAK SAXENA"}]}],"extras":null,"metadata":{"first_done_at":1631183208000,"last_updated_at":1631183208000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Priyanka Garg\nAdvanced Analyst\n\npriyankagarg1124@gmail.com\n\n8376055750\n\nShahdara, Delhi\n\nlinkedin.com/in/priyanka-garg-80a9a5192\n\nExperienced Data Analyst with a demonstrated history of working in the accounting industry. Skilled in multiple technologies like SQL\nServer, VBA , Power BI , Alteryx. A professional with a Bachelor’s Degree focused on Electronics & Communication Engineering\n\nWORK EXPERIENCE\n\n06/2019 – Present\n\nAdvanced Analyst\nErnst & Young LLP, Gurgaon\n\nGurgaon\nErnst & Young is a multinational professional services firm. E&Y is\nconsidered one of the Big Four accounting firms. E&Y advanced its\nmarket presence in Digital & Strategic consulting and entered into\ndirect competition with \"Big Three\" companies, namely Bain, McKinsey,\nand BCG.\n\nDesign, develop and evolve the analysis and visualization\ncapabilities of the TAS suite of applications.\n\nWorks on managing projects and ensure smooth service\ndelivery on assigned products, engagements and/or\ngeographies.\n\nExecute, or provide expert advice related to data\nmodeling and data preparation for analysis.\n\n03/2017 – 06/2019\n\nAnalyst\nErnst & Young LLP, Gurgaon\n\nGurgaon\nEY - TAS\n\nJoined as Analyst to help incubate new financial analytic\nproducts by executing Pilot, Proof of Concept projects\nto establish capabilities and credibility with users and\nclients\n\nCreating various dashboard and user interfacing tools\nusing various analytical technologies like VBA, Alteryx,\nSpotfire etc. to help team achieve desired outputs.\n\nDirect communication with users to understand project\nrequirements and efforts.\n\nEDUCATION\n\n08/2012 – 07/2016\n\nB. Tech: Electronics and Communication\nEngineering (82.12 %)\nAIACT&R (GGSIPU)\n\nDelhi\n\n04/2011 – 03/2012\n\nIntermediate (94.40 %)\nNavin Bharti Sr. Sec. School\n\nDelhi\n\n04/2009 – 03/2010\n\nSSC (9.6 CGPA)\nNavin Bharti Sr. Sec. School\n\nDelhi\n\nSKILLS\n\nVBA , Spotfire , Alteryx, SQL Server , Power BI, MS-Excel\n\nPERSONAL PROJECTS\n\nMaxwell\nThis is a CARVEX support engagement which aims to provide\nreport view for the financials of various MRC's to carve out.\n\nWorked on creation of various scripts in SQL (using\nparameterized functions, stored procedure, basic DDL and DML\nqueries), automations using VBA and Consolidation of various\nsales registers using ETL Tool Alteryx and generate excel based\nreports.\n\nEmpower\nThis project aimed at developing an excel based add-in which\nhas the capability to consolidate the financials of different\nportfolio in a formatted flat file structure with data checks\nreport.\n\nIn this engagement we used VBA to provide an easy to use\ninterface solution. Various quick macros have also been\nprovided in the tool like break external links etc.\n\nBluepoint\nThis project involved property management of 23 service plazas\nlocated in New York. I worked in delivering the finished\nvisualization product in terms of Spotfire Dashboard which can\nhelp in analysing their monthly TBs and income statements to\nget deeper insights into their assets\n\nACHIEVEMENTS\n\nE&Y Badge (Bronze badge in Data Science (Excel -\nVBA ) (2019)\nE&Y badges are the way to earn digital certification in future -\nfocused skills that differentiate individual in the market\n\nRole and Responsibilities\n\nAchievements/Tasks\n\nmailto:priyankagarg1124@gmail.com\nhttps://www.linkedin.com/in/priyanka-garg-80a9a5192/","annotation":[{"label":["Email"],"points":[{"start":3220,"end":3245,"text":"priyankagarg1124@gmail.com"}]},{"label":["Skills"],"points":[{"start":3028,"end":3030,"text":"VBA"}]},{"label":["Total experience"],"points":[{"start":2979,"end":3163,"text":"E&Y Badge (Bronze badge in Data Science (Excel -\nVBA ) (2019)\nE&Y badges are the way to earn digital certification in future -\nfocused skills that differentiate individual in the market"}]},{"label":["Skills"],"points":[{"start":2836,"end":2843,"text":"Spotfire"}]},{"label":["Total experience"],"points":[{"start":2672,"end":2962,"text":"Bluepoint\nThis project involved property management of 23 service plazas\nlocated in New York. I worked in delivering the finished\nvisualization product in terms of Spotfire Dashboard which can\nhelp in analysing their monthly TBs and income statements to\nget deeper insights into their assets"}]},{"label":["Skills"],"points":[{"start":2533,"end":2535,"text":"VBA"}]},{"label":["Total experience"],"points":[{"start":2506,"end":2669,"text":"In this engagement we used VBA to provide an easy to use\ninterface solution. Various quick macros have also been\nprovided in the tool like break external links etc."}]},{"label":["Total experience"],"points":[{"start":2312,"end":2502,"text":"This project aimed at developing an excel based add-in which\nhas the capability to consolidate the financials of different\nportfolio in a formatted flat file structure with data checks\nreport"}]},{"label":["Skills"],"points":[{"start":2261,"end":2267,"text":"Alteryx"}]},{"label":["Skills"],"points":[{"start":2197,"end":2199,"text":"VBA"}]},{"label":["Total experience"],"points":[{"start":2056,"end":2301,"text":"Worked on creation of various scripts in SQL (using\nparameterized functions, stored procedure, basic DDL and DML\nqueries), automations using VBA and Consolidation of various\nsales registers using ETL Tool Alteryx and generate excel based\nreports."}]},{"label":["Skills"],"points":[{"start":1898,"end":1905,"text":"MS-Excel"}]},{"label":["Skills"],"points":[{"start":1888,"end":1895,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":1875,"end":1884,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":1866,"end":1872,"text":"Alteryx"}]},{"label":["Skills"],"points":[{"start":1855,"end":1862,"text":"Spotfire"}]},{"label":["Skills"],"points":[{"start":1849,"end":1851,"text":"VBA"}]},{"label":["10 %"],"points":[{"start":1789,"end":1838,"text":"SSC (9.6 CGPA)\nNavin Bharti Sr. Sec. School\n\nDelhi"}]},{"label":["12 %"],"points":[{"start":1710,"end":1767,"text":"Intermediate (94.40 %)\nNavin Bharti Sr. Sec. School\n\nDelhi"}]},{"label":["Highest degree"],"points":[{"start":1605,"end":1689,"text":"B. Tech: Electronics and Communication\nEngineering (82.12 %)\nAIACT&R (GGSIPU)\n\nDelhi\n"}]},{"label":["Skills"],"points":[{"start":1441,"end":1448,"text":"Spotfire"}]},{"label":["Skills"],"points":[{"start":1432,"end":1438,"text":"Alteryx"}]},{"label":["Skills"],"points":[{"start":1427,"end":1429,"text":"VBA"}]},{"label":["Total experience"],"points":[{"start":1330,"end":1492,"text":"Creating various dashboard and user interfacing tools\nusing various analytical technologies like VBA, Alteryx,\nSpotfire etc. to help team achieve desired outputs.\n"}]},{"label":["Total experience"],"points":[{"start":1151,"end":1327,"text":"Joined as Analyst to help incubate new financial analytic\nproducts by executing Pilot, Proof of Concept projects\nto establish capabilities and credibility with users and\nclients"}]},{"label":["Experience in current company"],"points":[{"start":1105,"end":1130,"text":"Ernst & Young LLP, Gurgaon"}]},{"label":["Total experience"],"points":[{"start":983,"end":1074,"text":"Execute, or provide expert advice related to data\nmodeling and data preparation for analysis"}]},{"label":["Total experience"],"points":[{"start":866,"end":979,"text":"Works on managing projects and ensure smooth service\ndelivery on assigned products, engagements and/or\ngeographies"}]},{"label":["Total experience"],"points":[{"start":760,"end":862,"text":"Design, develop and evolve the analysis and visualization\ncapabilities of the TAS suite of applications"}]},{"label":["Total experience"],"points":[{"start":479,"end":757,"text":"Ernst & Young is a multinational professional services firm. E&Y is\nconsidered one of the Big Four accounting firms. E&Y advanced its\nmarket presence in Digital & Strategic consulting and entered into\ndirect competition with \"Big Three\" companies, namely Bain, McKinsey,\nand BCG."}]},{"label":["Experience in current company"],"points":[{"start":443,"end":468,"text":"Ernst & Young LLP, Gurgaon"}]},{"label":["designation"],"points":[{"start":426,"end":441,"text":"Advanced Analyst"}]},{"label":["Skills"],"points":[{"start":289,"end":295,"text":"Alteryx"}]},{"label":["Skills"],"points":[{"start":278,"end":285,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":272,"end":274,"text":"VBA"}]},{"label":["Total experience"],"points":[{"start":130,"end":388,"text":"Experienced Data Analyst with a demonstrated history of working in the accounting industry. Skilled in multiple technologies like SQL\nServer, VBA , Power BI , Alteryx. A professional with a Bachelor’s Degree focused on Electronics & Communication Engineering\n"}]},{"label":["Phone"],"points":[{"start":60,"end":69,"text":"8376055750"}]},{"label":["Email"],"points":[{"start":32,"end":57,"text":"priyankagarg1124@gmail.com"}]},{"label":["designation"],"points":[{"start":14,"end":29,"text":"Advanced Analyst"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"Priyanka Garg"}]}],"extras":null,"metadata":{"first_done_at":1631170660000,"last_updated_at":1631170660000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "MOHITAWANA\nAnalyst\n[ awanamohit5@gmail.com Ó +91 9999270907 ½ NewDelhi, India ¯ linkedin.com/in/mohitawana/  github.com/mohit-awana\n\nMOST PROUDOF\n3 PythonDeveloper at Carla simulatorAutonomous Driving ChallengeWork-\n\nshop, held at CVPR 2019 in Long\nBeach, CA.\nhttps://carlachallenge.org/team/\n\n3 HALFMARATHON at IDBIClocked 1 hour 51minutes at the IDBI\nHalfMarathon (21km).\n\nz Revels 2018 at SOIS,Manipal Univer-sity, Manipal\nPart of sponsorship initiatives team for\n‘Revels2018’- Annual cultural fest\n\nSTRENGTHS\nSQL Python Unix DataModeling\nMS SQL Server Data Visualisation\nDataMining MS Excel|VBA\nStatistical Analysis MongoDB\n\nLANGUAGES\nEnglish ○○○○○\n\nHindi ○○○○○\n\nEDUCATION\nM.E. Big Data andData Analytics\nSOIS,Manipal Univeristy, Karnataka\n� July 2017 – June 2019\n9.01 CGPA\nB.Tech.Mechanical and Automation\nAmity University, Noida\n� August 2011 –November 2015\n6.25 CGPA\nClass XII Notre Dame School\nAISSE\n� May 2010 –May 2011\n82.4 %\nClass X Notre Dame School\nAISSE\n� May 2009 –May 2010\n84%\n\nEXPERIENCE\nData Science Analyst\nIntello Transpo Pvt. Ltd\n� June 2019 –Ongoing ½ Noida\n• Handled all segments of data science division: from data scraping, col-\nlating, triangulating, normalization andmunging to analysis of massive\nstructured/unstructured data.\n\n• Acceleratedmonthly datamanipulation task from a day to 5minutes\nby automation via python script.\n\n• Developed a traffic accident predictionmodel based on driver person-\nality traits.\n\n• Optimized SQL query performance by 25% to run and derive reports\nfromDataWarehouse.\n\nData Analyst Intern\nKPIT TECHNOLOGIES INDIA PVT\n� May 2018 – April 2019 ½ Bengaluru\n• Developed clear and structured analytical plans and analyzed data\nsets to derive into actionable insights and recommendations to influ-\nence data-driven decision.\n\n• Built test cases and Python scripts based on detail data design and\nfunctional design for carla simulator.\n\n• Designed atomic functions to integrate data from cross functional\nAPIs.\n\nPROJECTS\nPredict loan default\nFunding agency/institution\n\n• Used classification technique to create amodel to predict loan de-\nfault.\n\n• Libraries used sklearn,Pandas, Numpy,Matplotlib, Seaborn.\n github.com/mohit-awana/Predict-Loan-Default\n\nTraffic Scenario Generation using python\nFunding agency/institution\n\n• Created traffic scenarios in Carla simulator using behavior trees.\n• Libraries used PyTrees, Numpy, Scikit, Git, Pandas.\n github.com/carla-simulator/scenario_srunner","annotation":[{"label":["Total experience"],"points":[{"start":2276,"end":2340,"text":"Created traffic scenarios in Carla simulator using behavior trees"}]},{"label":["Total experience"],"points":[{"start":2101,"end":2202,"text":"Libraries used sklearn,Pandas, Numpy,Matplotlib, Seaborn.\n github.com/mohit-awana/Predict-Loan-Default"}]},{"label":["Skills"],"points":[{"start":1802,"end":1807,"text":"Python"}]},{"label":["Total experience"],"points":[{"start":1615,"end":1775,"text":"Developed clear and structured analytical plans and analyzed data\nsets to derive into actionable insights and recommendations to influ-\nence data-driven decision"}]},{"label":["Skills"],"points":[{"start":1454,"end":1456,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":1258,"end":1352,"text":"Acceleratedmonthly datamanipulation task from a day to 5minutes\nby automation via python script"}]},{"label":["Total experience"],"points":[{"start":1082,"end":1253,"text":"Handled all segments of data science division: from data scraping, col-\nlating, triangulating, normalization andmunging to analysis of massive\nstructured/unstructured data."}]},{"label":["Experience in current company"],"points":[{"start":1026,"end":1049,"text":"Intello Transpo Pvt. Ltd"}]},{"label":["10 %"],"points":[{"start":936,"end":991,"text":"Class X Notre Dame School\nAISSE\n� May 2009 –May 2010\n84%"}]},{"label":["12 %"],"points":[{"start":874,"end":934,"text":"Class XII Notre Dame School\nAISSE\n� May 2010 –May 2011\n82.4 %"}]},{"label":["Highest degree"],"points":[{"start":778,"end":872,"text":"B.Tech.Mechanical and Automation\nAmity University, Noida\n� August 2011 –November 2015\n6.25 CGPA"}]},{"label":["Highest degree"],"points":[{"start":677,"end":776,"text":"M.E. Big Data andData Analytics\nSOIS,Manipal Univeristy, Karnataka\n� July 2017 – June 2019\n9.01 CGPA"}]},{"label":["Skills"],"points":[{"start":595,"end":597,"text":"VBA"}]},{"label":["Skills"],"points":[{"start":586,"end":593,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":545,"end":547,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":517,"end":522,"text":"Python"}]},{"label":["Skills"],"points":[{"start":513,"end":515,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":375,"end":500,"text":"z Revels 2018 at SOIS,Manipal Univer-sity, Manipal\nPart of sponsorship initiatives team for\n‘Revels2018’- Annual cultural fest"}]},{"label":["designation"],"points":[{"start":148,"end":162,"text":"PythonDeveloper"}]},{"label":["Skills"],"points":[{"start":148,"end":153,"text":"Python"}]},{"label":["Phone"],"points":[{"start":49,"end":58,"text":"9999270907"}]},{"label":["Email"],"points":[{"start":21,"end":41,"text":"awanamohit5@gmail.com"}]},{"label":["Name"],"points":[{"start":0,"end":9,"text":"MOHITAWANA"}]}],"extras":null,"metadata":{"first_done_at":1631167111000,"last_updated_at":1631167111000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Dheeraj Rao\nAnalyst BI and Reporting\nBritish Telecom,Gurugram\nMail ID : dheerajrao1988@gmail.com\tMobile : +91 9466726361 Objective\nTo   secure a   position  in  a  technology  driven  organization  that  would  lead  me  to  contribute  my skills  and abilities  in  its  development  and  to  excel  in  this  progressive  software/analytics environment  to  my  top  potential.\n\nProfessional Summary\n· A result oriented professional with 4 years of experience as a SAS Programmer with Britsh Telecom.\n· Strong command over SAS/BASE, SAS/SQL, SAS/Macros, MS Excel.\n· Basic commands in Unix.\n· Good understanding of VBA codes\n· Experience in data management, cleaning, reporting and integration using SAS Programming skills.\n· Accountability  for  quality, timeliness and efficiency for the work assigned to me.\n· Ability to derive insights from complex data for presentation and decision making.\n· Strong leadership, problem-solving, planning, team-building  and  project  management  skills.\n\nKey Skills\n· Experience in SAS Coding, Reporting, Data Management and Data Mining.\n· Experience in analysis and sanity checking, validating and manipulating complex data using\nDATA-step Programming, SAS Procedures, SAS Functions, SAS/Macros and MS Excel.\nAnalysis of  business requirement document.\n· Experience on Base SAS, SAS/SQL, SAS/ODS, MS Excel , SAS Enterprise guide.\n· Experience in extracting data and creating data sets from various sources like Excel, flat files using SAS.\n· Producing customized reports for  Performance Optimization.\n· Creating charts and Bars as final outputs using PROC Gplot/Gchart.\n· Experience in direct client dealing.\n\nTechnical Skills SAS Tools:\n· SAS v9.3, v9.4(SAS/BASE, SAS/SQL, SAS/MACROS, SAS/GRAPHS, SAS/REPORT,SAS/ODS)\n· SAS/EG.\nSoftware & Technologies\nOffice Tools: MS Excel, MS PowerPoint, MS Word,BMC Remedy,OBIEE (Oracle Business Intelligence) 11g,SQL Developer 18.1                   \n Platforms :Microsoft Windows7,8,10 \n\n\n\nProjects Summary\nProject Name: 1425 - PT0 E2E Total Movement Tracker    \nClient\t: Multiple\nDomain\t: Telecom\nDescription : Provision Tails End to End Report  measures the speed of recovery of any order after the CCD has been missed and minimize customer dissatisfaction. Drive on customer satisfaction, productivity and performance improvement. We need to write queries to pull out data and find out relevant variables as per the requirement.\nRoles and Responsibilities:\n\n· Responsible for working in the following modules for data preparation:\n          - Perform Sanity checks\n          - Data extraction, cleaning and manipulation\n          - Create macros for complex and recursive programming\n          - Validating data sets, comparing results and records trend analysis\n· Responsible for Data Analysis for the various feed from the source system\n· Running the BAU’s i.e. Business as Usual\n· Interaction with the client to understand the requirement of the project and\n            required updates\n· Used SAS /Base for reporting purpose and SAS/MACROS for automating the same.\n· Design and development of SAS code whenever there is an ad hoc requirement.\n            Reporting using ODS.\n\nProject Name: 733 Missapp Report\nClient\t: Multiple\nDomain\t: Telecom\nDescription: Drive on customer satisfaction and Openreach performance at issuing and meeting appointments. It is used to support and analyze promise failures impacting on RFT.\n\nRoles and Responsibilities :\n\n· Perform Sanity checks, Data extraction, cleaning.\n· Validating data sets, comparing results and records trend analysis\n· Responsible for Data Analysis for the various feed from the source system\n· Running the BAU’s i.e. Business as Usual\n· Interaction with the client to understand the requirement of the project and\n              required updates\n· Used SAS /Base for reporting purpose and SAS/MACROS for automating the same.\n· Design and development of SAS code whenever there is an ad hoc requirement.\n·  Reporting using ODS.\n\nPrevious Organizations:\n\nWorked with Bharti Airtel Services India - (from March 2014 to September 2015)\nas Network Surveillance Engineer.\n\n\n\n\nRoles and Responsibilities :\n\n· Provide support to team members for Technical issues.\n· Creating various reports using MS Excel.\n· Auditing the Tickets raised by engineers in BMC Remedy.\n· Coordinate with field engineers and provide telephonic support for fault rectification.\n· Responsible for handling Hourly/daily/Monthly Incident report/ Trouble Ticket report/ Critical/Major Outage Report/Ring Collapse Report.\n\nWorked with Bharti Infratel Limited (from Mar 2012 to Mar 2014) as Network Surveillance Engineer\n\nRoles and Responsibilities :\n\n· Monitoring Critical Power Alarms via tools provided by IBM i.e. Netcool and Maximo(TSRM).\n· Creating message for group sites down and spreading the same via software Campaign Module.\n· Coordinate with field engineers and provide telephonic support for fault rectification.\n· Responsible for handling Hourly/daily/Monthly Incident report/ Trouble Ticket report/Critical/Major Outage Report.\n\nQualifications:\n\n\tDegree\n\tInstitute/University\n\tPassing Year\n\tSpecialization\n\n\tB.Tech\n\tGurgaon Institute of Tech and Management\n\t2011 (67%)\n\tECE\n\n\tXII\n\tCBSE\n\t2007 (77%)\n\tPhysics,Che mistry, Mathemati\ncs\n\n\tX\n\tHBSE\n\t2005(77%)\n\tAll General Subjects\n\n\n\nAchievements:\n\n· Received champion of  the quarter  award  in 2018.\n· Winner of BT GBS TT Tournament.","annotation":[{"label":["10 %"],"points":[{"start":5257,"end":5296,"text":"X\n\tHBSE\n\t2005(77%)\n\tAll General Subjects"}]},{"label":["12 %"],"points":[{"start":5199,"end":5250,"text":"XII\n\tCBSE\n\t2007 (77%)\n\tPhysics,Che mistry, Mathemati"}]},{"label":["Highest degree"],"points":[{"start":5131,"end":5195,"text":"B.Tech\n\tGurgaon Institute of Tech and Management\n\t2011 (67%)\n\tECE"}]},{"label":["Total experience"],"points":[{"start":4846,"end":4931,"text":"Coordinate with field engineers and provide telephonic support for fault rectification"}]},{"label":["Total experience"],"points":[{"start":4303,"end":4388,"text":"Coordinate with field engineers and provide telephonic support for fault rectification"}]},{"label":["Skills"],"points":[{"start":4233,"end":4240,"text":"MS Excel"}]},{"label":["Last company"],"points":[{"start":4009,"end":4036,"text":"Bharti Airtel Services India"}]},{"label":["Skills"],"points":[{"start":3897,"end":3899,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3837,"end":3842,"text":"MACROS"}]},{"label":["Skills"],"points":[{"start":3833,"end":3835,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3797,"end":3799,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":3233,"end":3406,"text":"Description: Drive on customer satisfaction and Openreach performance at issuing and meeting appointments. It is used to support and analyze promise failures impacting on RFT"}]},{"label":["Skills"],"points":[{"start":3081,"end":3083,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3021,"end":3026,"text":"MACROS"}]},{"label":["Skills"],"points":[{"start":3017,"end":3019,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2981,"end":2983,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":2093,"end":2410,"text":"Provision Tails End to End Report  measures the speed of recovery of any order after the CCD has been missed and minimize customer dissatisfaction. Drive on customer satisfaction, productivity and performance improvement. We need to write queries to pull out data and find out relevant variables as per the requirement"}]},{"label":["Skills"],"points":[{"start":1893,"end":1895,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1808,"end":1815,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":1762,"end":1764,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1751,"end":1753,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1740,"end":1742,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1728,"end":1730,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1720,"end":1725,"text":"MACROS"}]},{"label":["Skills"],"points":[{"start":1716,"end":1718,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1711,"end":1713,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1707,"end":1709,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1697,"end":1699,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1682,"end":1684,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1669,"end":1671,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1476,"end":1478,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1349,"end":1351,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1338,"end":1345,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":1329,"end":1331,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1324,"end":1326,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1320,"end":1322,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1315,"end":1317,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1240,"end":1247,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":1229,"end":1234,"text":"Macros"}]},{"label":["Skills"],"points":[{"start":1225,"end":1227,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1210,"end":1212,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1194,"end":1196,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1022,"end":1024,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":1008,"end":1075,"text":"Experience in SAS Coding, Reporting, Data Management and Data Mining"}]},{"label":["Total experience"],"points":[{"start":727,"end":809,"text":"Accountability  for  quality, timeliness and efficiency for the work assigned to me"}]},{"label":["Skills"],"points":[{"start":701,"end":703,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":628,"end":722,"text":"Experience in data management, cleaning, reporting and integration using SAS Programming skills"}]},{"label":["Skills"],"points":[{"start":556,"end":563,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":548,"end":553,"text":"Macros"}]},{"label":["Skills"],"points":[{"start":544,"end":546,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":539,"end":541,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":535,"end":537,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":525,"end":527,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":467,"end":469,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":404,"end":500,"text":"A result oriented professional with 4 years of experience as a SAS Programmer with Britsh Telecom"}]},{"label":["Total experience"],"points":[{"start":131,"end":377,"text":"To   secure a   position  in  a  technology  driven  organization  that  would  lead  me  to  contribute  my skills  and abilities  in  its  development  and  to  excel  in  this  progressive  software/analytics environment  to  my  top  potential"}]},{"label":["Phone"],"points":[{"start":110,"end":119,"text":"9466726361"}]},{"label":["Email"],"points":[{"start":72,"end":95,"text":"dheerajrao1988@gmail.com"}]},{"label":["designation"],"points":[{"start":12,"end":35,"text":"Analyst BI and Reporting"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Dheeraj Rao"}]}],"extras":null,"metadata":{"first_done_at":1631181995000,"last_updated_at":1631181995000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "ALIYA TARIQ                                                                                                            \n aliya.tariq9@gmail.com\n +91-9205059544\n\n\nPROFESSIONAL SNAPSHOT\n\n· Data analytics (SQL & SAS) professional with 5 years of experience. \n· Currently associated with Wipro as  Analyst Programmer since 2017.\n· SAS Institute Certified SAS Base Programmer for SAS 9.\n· Proficient in SAS Base and Advanced SAS programming with superior experience in ODS and SAS Macros.\n· Extensive experience in data modelling, analysing and manipulating large datasets, constructing, deploying and maintaining data-driven systems using SAS and SQL on mainframe z/OS platform and UNIX.\n· Experience in agile methodology and SDLC, managing projects and agile teams.\n· Superior ability in data automation using batch jobs and SAS code to deliver business intelligence solutions such as reports, insight metrics calculations, prediction reports, alerts etc.\n· Solid understanding of health care industry functions such as Health Plan Enrolments, Medical Claims and Providers. \n· Self-directed and able to function both independently and as part of a team, managing deadlines and priorities.\n\nTECHNICAL PROFICIENCY\n\n· Programming Languages    :  SAS Base, Advanced SAS, SAS Macros,  SQL, JCL and Hive\n· Databases\t                 :  IBM DB2 9, Oracle Database 11g\n· Operating Systems              :  z/OS, Microsoft Windows 10 , UNIX\n· Tools\t   \t                 :   SQL Utility, Oracle VM Virtual Box, Control-M, MS Excel , SAS Studio\n\nWORK EXPERIENCE\n. \n#1- Wipro [Gurgaon, Haryana]\n· Analyst Programmer                                                                                                                     Apr 2017 to Present\n\n Project #1:  Your Spending Account – DI\n\n· Duration:  10  months\n· Role:  Systems Analyst\n· Environment:  z/OS mainframe\n· Technology:  SAS Base, SAS Macros, SQL, ODS, HTML, JCL, IBM DB2 Studio, TSO/ISPF\n\n· Description:  The project deals with managing the data integration and reporting process of YSA. This project requirement has several reporting, predictions, alerts, metrics calculation and data integration code development.\n\n· Roles and Responsibilities:\n· Interacted with business analysts, gathering and analysing requirements into coding interfaces.\n· Implemented the entire rollover process for about 250 clients with more than 100 different plans for a total population of nearly 40 million participants. \n· Automated the entire rollover process from data integration to data visualization.\n· Provided upkeep and analysis for changes to batch systems for Aon Hewitt's Your Spending Account product.\n· Designed and implemented policies and procedures for disaster recovery and data archive to ensure protection of data.\n· Developed data automation code to integrate and transform data from multiple sources to create custom reports, calculate billing metrics, predictions, alerts etc.\n· Created several SAS macros to encapsulate common business logics for all clients for code modularity.\n· Extensively used SAS macros to dynamically write SAS statements.\n· Added pluggable logic to incrementally add new client level logics without modifying global business logic.\n· Lead a team of 4 programmers and assist them in translating analysis and requirements into robust and efficient code.\n· Enforced coding standards and created accurate technical documentation.\n· Delivered PROV-IT sessions and user acceptance testing to the stakeholders.\nProject #2:  Wired Commute Monthly Load/Recon Process -YSA Banking LEAN Event\n\n· Duration: 12 months\n· Role:  Batch Systems Analyst\n· Environment:   UNIX\n· Technology:  SAS Base, SAS Macros, SQL, ODS, HTML, Unix Shell Scripting,  IBM DB2 Studio\n\nDescription:  The Wired commute is commuter benefit partner of the YSA (Your Spending Account); it offers pre-tax commuter benefits to participants who opt for commuter plans with YSA.  This project required us to code reconciliation logic to sync data both on wired commute and YSA database.\n\n· Roles and Responsibilities:\n· Speed up the Wired Commute Monthly Reconciliation Process.\n· Extensively used SAS macros to generate datasets by comparing data on YSA database and WC file, and load the adjustments to the YSA or send the adjustments to wired commute to load and sync.\n· Analysed large datasets and optimized the loading process of the Deduction and Adjustment file data using custom loader procedure created using SAS and SQL.\n· Optimised complex PROC SQL queries (using views, common table expressions and indexes) which were pulling deductions / adjustments to be loaded to tables so that they can be included on the client-level file.\n· Created a parallel processing system to perform concurrent data processing to achieve faster execution time.\n· Increased throughput via creating multiple data streams and efficiently scheduled pipelined system.\n· Created compare and differ macros using SAS macros, table lookups and arrays to automate the comparison of various datasets.\n· Deployed a new secured EFT system between Wired Commute and YSA for up/down stream of large amount of data and reporting system to ensure the participant’s records are in sync.\n· Extensively worked on unit test scripts and documented them for production release.\n· Created action plans to track identified open issues and action items related to the project.\n· 15% performance gain in code execution and data loading against system benchmark.\n\n\n#2- Aon Hewitt [Gurgaon, Haryana]\n· Senior Batch Technical Specialist                                                                                            Oct 2015 to Mar 2017\n\nProject #1:  BIRT – Batch Integration and Regression Testing\n\n· Duration:  10  months\n· Role:  Analyst\n· Environment: z/OS\n· Technology:  SAS Base, SAS Macros, SQL, ODS, JCL, IBM DB2 Studio\n\n· Description:  The project required performing intensive integration and regression testing on all the batch (SAS) codes and provide fix for all defects during production support and testing.\n\n· Roles and Responsibilities:\n· Developed scripts to automate the testing of batch codes on different testing environment.\n· Developed scripts to perform data flow testing on all major batch jobs streams.\n· Implemented problem detection and prevention strategies to reduce database problems and improve service quality.\n· Enhanced several batch codes for reusability, modularity and performance.\n· 24x7 production support and fixed up all the on-going defects encountered.\n· Optimized and tuned SAS codes and SQL queries.\n· Refactored codes and replaced redundant codes with pluggable logic to provide code trimming and modularity.\n· Developed data quality checks code to validate reports and data loads against provided estimates.\n· Developed several batch utilities in SAS and JCL like extract data, include keys, maps, batch trace etc.\n· Integration and regression test codes and assisted in developing deployment scripts for releases.\n· Enforced coding standards and created accurate technical documentation.\n\n#3- Aon Hewitt [Gurgaon, Haryana]\n· Batch Technical Specialist                                                                                            June 2014 to Sep 2015\n\nProject #1:  Your Spending Account – Billing and Reporting\n\n· Duration:  10  months\n· Role:  Programmer\n· Environment: UNIX\n· Technology:  SQL, SAS Base, SAS Macros, ODS, Unix Shell Scripting, IBM DB2 Studio\n\n· Description:  The project required developing codes to generate ad-hoc reports and automating the periodic reports.\n\n· Roles and Responsibilities:\n· Developed efficient code to generate accurate reports as per requirement.\n· Developed enterprise level SAS code to generate client billing details and metric calculation for over 250 clients.\n· Created code to predict client health using billing metrics against benchmark values.\n· SAS DATA step and PROC step programming with extensive use of SAS function, PROC SQL, lookups, indexing and arrays.\n· Setup robust mailing logic to send the report to the recipient in the desired formats (HTML, XML, PDF, XLS etc.) using SAS ODS.\n· Optimized and tuned the reporting codes (SQL queries and SAS codes) to reduce the CPU cost and timely deliver the reports.\n\nTRAININGS\t\n\n· MS-Excel (Basics, Advanced)\n· Business Writing and Communication\n· Business Etiquettes\n\nEDUCATION\t\n\n· Bachelor of Technology in Computer Science, 2014 batch from U.P. Technical University with 74.2%.\n· Higher Secondary Certificate (class 12th) CBSE board in 2010 with 74.4%.\n· Secondary School Certificate (class 10th) ICSE board in 2008 from with 84.4%. \n\nACHIEVEMENTS AND RECOGNITIONS\n\n· Platinum Individual Award, 2017 at Aon Hewitt for outstanding performance.\n· Tier-2 Award, 2015 at Aon Hewitt for Billing Project.\n\nDECLARATION\n\nI hereby declare that the information provided by me is true to the best of my knowledge and understanding. \n\nPlace:   Delhi    \t\t\t\t\t\t\t\t\t\t         \nDate:","annotation":[{"label":["10 %"],"points":[{"start":8533,"end":8609,"text":"Secondary School Certificate (class 10th) ICSE board in 2008 from with 84.4%."}]},{"label":["12 %"],"points":[{"start":8458,"end":8528,"text":"Higher Secondary Certificate (class 12th) CBSE board in 2010 with 74.4%"}]},{"label":["Highest degree"],"points":[{"start":8358,"end":8454,"text":"Bachelor of Technology in Computer Science, 2014 batch from U.P. Technical University with 74.2%."}]},{"label":["Skills"],"points":[{"start":8256,"end":8263,"text":"MS-Excel"}]},{"label":["Skills"],"points":[{"start":8159,"end":8161,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":8118,"end":8238,"text":"Optimized and tuned the reporting codes (SQL queries and SAS codes) to reduce the CPU cost and timely deliver the reports"}]},{"label":["Skills"],"points":[{"start":7951,"end":7953,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":7782,"end":7865,"text":"Created code to predict client health using billing metrics against benchmark values"}]},{"label":["Skills"],"points":[{"start":7382,"end":7391,"text":"SAS Macros"}]},{"label":["Skills"],"points":[{"start":7372,"end":7379,"text":"SAS Base"}]},{"label":["Skills"],"points":[{"start":7367,"end":7369,"text":"SQL"}]},{"label":["Last company"],"points":[{"start":7055,"end":7082,"text":"Aon Hewitt [Gurgaon, Haryana"}]},{"label":["Skills"],"points":[{"start":6546,"end":6548,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":5845,"end":6033,"text":"Description:  The project required performing intensive integration and regression testing on all the batch (SAS) codes and provide fix for all defects during production support and testing"}]},{"label":["Skills"],"points":[{"start":5812,"end":5814,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":5800,"end":5809,"text":"SAS Macros"}]},{"label":["Skills"],"points":[{"start":5790,"end":5797,"text":"SAS Base"}]},{"label":["Last company"],"points":[{"start":5473,"end":5500,"text":"Aon Hewitt [Gurgaon, Haryana"}]},{"label":["Skills"],"points":[{"start":4496,"end":4498,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":4473,"end":4679,"text":"Optimised complex PROC SQL queries (using views, common table expressions and indexes) which were pulling deductions / adjustments to be loaded to tables so that they can be included on the client-level file"}]},{"label":["Skills"],"points":[{"start":4466,"end":4468,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":4120,"end":4309,"text":" Extensively used SAS macros to generate datasets by comparing data on YSA database and WC file, and load the adjustments to the YSA or send the adjustments to wired commute to load and sync"}]},{"label":["Total experience"],"points":[{"start":3734,"end":4024,"text":"Description:  The Wired commute is commuter benefit partner of the YSA (Your Spending Account); it offers pre-tax commuter benefits to participants who opt for commuter plans with YSA.  This project required us to code reconciliation logic to sync data both on wired commute and YSA database"}]},{"label":["Skills"],"points":[{"start":3679,"end":3681,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3667,"end":3676,"text":"SAS Macros"}]},{"label":["Skills"],"points":[{"start":3657,"end":3664,"text":"SAS Base"}]},{"label":["Total experience"],"points":[{"start":2771,"end":2932,"text":" Developed data automation code to integrate and transform data from multiple sources to create custom reports, calculate billing metrics, predictions, alerts etc"}]},{"label":["Total experience"],"points":[{"start":2301,"end":2453,"text":"Implemented the entire rollover process for about 250 clients with more than 100 different plans for a total population of nearly 40 million participants"}]},{"label":["Total experience"],"points":[{"start":1944,"end":2168,"text":" Description:  The project deals with managing the data integration and reporting process of YSA. This project requirement has several reporting, predictions, alerts, metrics calculation and data integration code development."}]},{"label":["Skills"],"points":[{"start":1896,"end":1898,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1884,"end":1893,"text":"SAS Macros"}]},{"label":["Skills"],"points":[{"start":1874,"end":1881,"text":"SAS Base"}]},{"label":["Experience in current company"],"points":[{"start":1554,"end":1558,"text":"Wipro"}]},{"label":["Skills"],"points":[{"start":1508,"end":1515,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":1461,"end":1463,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1277,"end":1279,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1264,"end":1273,"text":"SAS Macros"}]},{"label":["Skills"],"points":[{"start":1250,"end":1261,"text":"Advanced SAS"}]},{"label":["Skills"],"points":[{"start":1240,"end":1247,"text":"SAS Base"}]},{"label":["Skills"],"points":[{"start":643,"end":645,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":486,"end":682,"text":"Extensive experience in data modelling, analysing and manipulating large datasets, constructing, deploying and maintaining data-driven systems using SAS and SQL on mainframe z/OS platform and UNIX."}]},{"label":["Skills"],"points":[{"start":472,"end":481,"text":"SAS Macros"}]},{"label":["Skills"],"points":[{"start":411,"end":422,"text":"Advanced SAS"}]},{"label":["Skills"],"points":[{"start":398,"end":405,"text":"SAS Base"}]},{"label":["Total experience"],"points":[{"start":384,"end":481,"text":"Proficient in SAS Base and Advanced SAS programming with superior experience in ODS and SAS Macros"}]},{"label":["Skills"],"points":[{"start":351,"end":358,"text":"SAS Base"}]},{"label":["Experience in current company"],"points":[{"start":284,"end":288,"text":"Wipro"}]},{"label":["Skills"],"points":[{"start":203,"end":205,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":187,"end":252,"text":"Data analytics (SQL & SAS) professional with 5 years of experience"}]},{"label":["Phone"],"points":[{"start":149,"end":158,"text":"9205059544"}]},{"label":["Email"],"points":[{"start":121,"end":142,"text":"aliya.tariq9@gmail.com"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"ALIYA TARIQ"}]}],"extras":null,"metadata":{"first_done_at":1631180441000,"last_updated_at":1631180441000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "RESUME\nPayal Gupta\t\t\t\t\t\t\nContact: +91-9536309932\nE-mail: guptapayal047@gmail.com\n\n\nCareer Objective\nTo work in learning and challenging environment, utilizing my skills and knowledge to be the best of my abilities and contribute positively to my personal growth as well as growth of the organization.\n\nProfessional Summary\nOrganization\t: Xceedance Infotech Pvt Ltd. \nRole\t\t: Analyst Programmer L1\nDuration\t: July 2018 to Present (1Yr.)\n\n· Good Knowledge and Proficiency on SQL \n· Knowledge of Development SQL Scripts\n· Knowledge of SQL Server Data Tools.\n· Knowledge of tracking the errors in scripts & packages\n· Good Knowledge and working experience on Cloud Platforms (Azure and AWS)\n· Knowledge and work experience of AZURE SQL and Integration of AZURE SQL with Local Server.\n· Knowledge and implementation of AZURE DATA LAKE\n· Knowledge and implementation of Hadoop cluster in AZURE\n· Knowledge and implementation of DATA LAKE IN AWS \n· Use different application in AWS like (AWS GLUE, Athena DB, RedShift, AmazaonS3,Quicksight)\n\n\nAcademic Qualification\n\tCOURSES\n\tINSTITUTE\n\tBOARD/ UNIVERSITY\n\tYEAR OF PASSING\n\tPERCENTAGE\n\n\tMCA\n\tShri Ram Murti Smarak College of Eng. & Tech. Bareilly\n\tAKTU\n\t2018\n\t80%\n\n\tBCA\n\tBareilly College, Bareilly\n\tM.J.P.R.U\n\t2016\n\t65.21%\n\n\tXII\n\tMother Athena School\n\tC.B.S.E\n\t2012\n\t59.2%\n\n\tX\n\tMother Athena School\n\tC.B.S.E\n\t2010\n\t72\n\n\n\nTechnical Skills\nProgramming Languages\t: Core Java, Android, Python \nDatabases Languages\t\t: SQL Server\nPlatforms\t\t\t: Cloud Platform (Azure, AWS)\n\nProjects Undertaken\nProject Name\t\t\t: EDW Projects\nRoles and Responsibilities\t: SQL Developer, Issues Solving                 \n                                                         \n.\n                                                                                                                                                                                           Description\t\t\t: To Develop the SQL scripts and Backtracking the issues in Data\nProject Name\t\t\t: MSL (Medical Stop Loss (EDW Project)\nKey Capabilities\t\t: Development of SQL Scripts and Mapping of MSL Database Columns.\nRoles and Responsibilities\t: Analysis and understanding of Frontend Application.\n\t\t\t\t: Analysis of MSL database and tables.\n \t\t\t\t: Mapping of MSL DB from Frontend columns.\n\t\t\t\t: Development of SQL Scripts to load the data in EDW.\n\nProject Name\t\t\t: Email Automation (Using Azure cloud platform)\nKey Capabilities\t\t: Fetch the data from Email Body and finally visualize the data in SQL Report\nRoles and Responsibilities\t: Load the Email data in Cloud Azure Storage.\n                                                : Use of Logic App in Azure to automate the emails.\n\t\t\t\t: Insert the data from Cloud to SQL using external tables \n \t\t\t\t: Automate the Stored Procedure \n\t\t\t\t: When the Logic app runs in azure data will be in SSRS Reports.\n\nProject Name\t\t\t: Email Automation(Using Cloud Azure)\nKey Capabilities\t\t: Fetch the data from Email Body and finally visualize the data in  SSRS .\nRoles and Responsibilities\t: Load the Email data in Cloud Azure Storage.\n                                                : Use of Logic App in Azure to automate the emails.\n\t\t\t\t: Insert the data from Cloud to SQL using external tables \n \t\t\t\t: Automate the Stored Procedure \n\t\t\t\t: When the Logic app runs in azure data will be in SSRS Reports.\n\t\t\t\nProject Name\t\t\t: Data lake Implementation in AWS\nKey Capabilities\t\t: Unstructured Data analysis \nRoles and Responsibilities\t: Load the data in AWS Storage.\n                                                : Use of DB in AWS like Athena.\n\t\t\t\t: Insert the data from AWS Storage and create table in Athena DB\n\nProject Name\t\t\t: Data lake Implementation in Azure\nKey Capabilities\t\t: Unstructured Data analysis \nRoles and Responsibilities\t: Load the data in Azure storage.\n                                                : Use of Hadoop Cluster in Azure.\n\t\t\t\t: Insert the data from Azure and querying the data in Hive.\n\n\t\t\t\t\n\t\t\t\n\n\t\t\t\n\n\t\t\t\n\t\t\t\t\nAchievements\n· Awarded with Medal as a rank holder in MCA.\n· Won second prize in web application development \n· Won Second Prize in Singing Competition.\n\nPersonal Details\nFather’s Name\t\t: \tDr. Pankaj Gupta\nDate of birth\t\t\t: \t7-April-1995\nPassport Number\t\t:\tR7382588\nMarital Status\t\t\t: \tUnmarried\nGender\t\t\t: \tFemale\nLanguage Known\t\t: \tEnglish, Hindi\nNationality\t\t\t: \tIndian\n\nDeclaration\nI do hereby declare that the above-mentioned information is correct up to my knowledge and I bear the responsibility for the correctness of the above-mentioned particulars.\nDate:\nPlace:\t\t\t\t\t\t\t             \t                                        Payal Gupta","annotation":[{"label":["Name"],"points":[{"start":4595,"end":4605,"text":"Payal Gupta"}]},{"label":["10 %"],"points":[{"start":1317,"end":1358,"text":"X\n\tMother Athena School\n\tC.B.S.E\n\t2010\n\t72"}]},{"label":["12 %"],"points":[{"start":1267,"end":1313,"text":"XII\n\tMother Athena School\n\tC.B.S.E\n\t2012\n\t59.2%"}]},{"label":["Grad. score"],"points":[{"start":1208,"end":1263,"text":"BCA\n\tBareilly College, Bareilly\n\tM.J.P.R.U\n\t2016\n\t65.21%"}]},{"label":["Highest degree"],"points":[{"start":1129,"end":1204,"text":"MCA\n\tShri Ram Murti Smarak College of Eng. & Tech. Bareilly\n\tAKTU\n\t2018\n\t80%"}]},{"label":["Total experience"],"points":[{"start":942,"end":1032,"text":"Use different application in AWS like (AWS GLUE, Athena DB, RedShift, AmazaonS3,Quicksight)"}]},{"label":["Total experience"],"points":[{"start":689,"end":777,"text":"Knowledge and work experience of AZURE SQL and Integration of AZURE SQL with Local Server"}]},{"label":["Experience in current company"],"points":[{"start":338,"end":363,"text":"Xceedance Infotech Pvt Ltd"}]},{"label":["Total experience"],"points":[{"start":100,"end":298,"text":"To work in learning and challenging environment, utilizing my skills and knowledge to be the best of my abilities and contribute positively to my personal growth as well as growth of the organization"}]},{"label":["Email"],"points":[{"start":57,"end":79,"text":"guptapayal047@gmail.com"}]},{"label":["Phone"],"points":[{"start":38,"end":47,"text":"9536309932"}]},{"label":["Name"],"points":[{"start":7,"end":17,"text":"Payal Gupta"}]}],"extras":null,"metadata":{"first_done_at":1631182079000,"last_updated_at":1631182079000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Payal Gupta\nContact: +91-9536309932 Mail: guptapayal047@gmail.com\n\nOBJECTIVE\n\nTo work in learning and challenging environment, utilizing my skills and knowledge to be the best of my abilities and contribute positively to my personal growth as well as growth of the organization.\n\nPROFESSIONAL SYNOPSIS\n\n· MCA with 1 years of experience in SQL Developer with different types of projects execution related to data. \n· Efficient in SQL SSDT and Business Intelligence concepts with emphasis on dimensional Modeling & Data Integration.\n· Strong SQL and PL/SQL programming skills, Proficient in writing stored procedures, packages\n\n· Knowledge of SQL Server Data Tools and Work Experience in SSIS and SSRS.\n\n· Working Experience in Insurance Domain.\n· Exposure to Cloud Platforms like Azure and AWS (Integration of Azure SQL and implementing the AZURE DATA LAKE and AWS DATA LAKE.\n\n· Possess strong interpersonal, communication and analytical skills with demonstrated abilities in customer relationship management.\n\n· Ability to work on semi structured, unstructured and structured data and analyses on that.\n\nAREA OF EXPOSURE\n\nKey Result Area \n\nTechnical\n\nLanguages \n                          : Core Java ,Android, Python Basic\nTools         \n\n\n: PL-SQL Developer, SQL Developer, Microsoft SSIS, SSRS.\nData Bases\n\n\n: SQL Server 2008R2/14/17.\nWork Experience\nJuly ’2018 to 2019 with Xceedance, Gurgaon as Analyst Programmer L1\nProjects\nTitle\n\n\n:\nEnterprise data warehouse  \nClient\n\n\n:\nBerkshire Hathaway Specialty Insurance (BHSI)\nLanguage/Platform    \n:            SQL Server, SSIS, SSRS\nProject Description \n\n\nAccording to this project the Client have different regions and different sources (Application, Excel Files) by which we can see all the information regarding an insurance policy. We make different packages in SSIS to load the data from application and sources into database. So, it’s the process of daily package runs then data will load into our staging table to ODS then from ODS to EDW. In this whole process it requires SQL scripts to load the data from different sources and finally stored it in Enterprise data warehouse.\nAfter the data will we in Exact state as we can store the data then from that data the reports are generated as a final visualization of data in SSRS.\nAccountabilities\n1) Attended client meetings to understand the client requirements for creating mapping between source and target data models.\n2) Coordinate all the technical activities of the technical team and send for review of the client at periodic intervals.\n3) Provide resolution of technical issues that arise during implementation stages.\n4) Prepare report for cause analysis of issues raised by client.\n5) Provide status report to the client at various stages.\n\n6) Making modifications in the development as suggested by client.\n\n7) SSIS (SQL Server Integration Services) – Microsoft SQL Server Integration Services tool was used to import     the data from different sources to the SQL server and finally stored all the data in Enterprise Data Warehouse.\n8) Also develop the scripts in SQL Server to perform the actions of data loading from source to database using SSIS packages. So, we have different ETL’s under which the SSIS packages runs and perform the data migration operations from source to database.\nCore member of the team that executed the project\nTitle\n\n\n:\nMedical Stop Loss (Health Insurance)\nClient\n\n\n:\nBerkshire Hathaway Specialty Insurance\nLanguage/Platform    \n:            SQL Server, SSIS, SSRS\nDescription\n\n:\nThis project is based on a separate Product line of insurance which bis known as MEDICAL STOP LOSS (MSL). So, underwriters have an application which is known as DAVID YOUNG SYSTEM (DY SYSTEM).\nWhen any new policy first arrived in business, underwriter write the policy and all the related information in DY system. DY system is a source for MSL policies. Then our work will be started to first map all the fields of DY system from MSL Database. The aim of this project is to load the MSL data in ENETRPRISE DATA WAREHOUSE. So, we have to write the scripts in SQL server in which we have the columns of EDW and MSL DB to load the MSL data in EDW as according to the columns in EDW. So, we develop SSIS packages under which we write the stored procedures and scripts and run the whole package to start the loading process from source to warehouse.\n\nAccountabilities\n· Involved and attended all the meetings and training sessions to understand the application and business requirements.\n· After taking the complete understanding of application, started working on mapping of data from application to database.\n· Mapping of Enterprise Data Warehouse columns mapping with the columns in MSL database so that we can easily load the data from MSL database to EDW.\n· Designed, Developed and Deployed SQL SCRIPTS in MS SQL Server environment.\n\n· Generated the requirement documents and the mapping document to complete the understanding of all the mapping work and related information.\n· Designed SSIS Packages to extract, transfer and load (ETL) data from application to SQL Server. \n· Designed, reviewed, and created the stored procedures and scripts and take the proper understanding of all the views and its definition.\n\n·  Involved in the whole process of project from understanding the client requirements and interaction with the documentation regarding the updates in the project.\nSCHOLASTICS\n\n· 10th from C.B.S.E with 70% marks.\n· 12th from C.B.S.E with 60% marks.\n· MCA from Shri Ram Murti Smarak College of Engineering and Technology with 80%.\n                                                                PERSONAL MINUTIAE\n\nDate of Birth           \n: 07/04/1995\nCurrent Address      \n:139, Sector 23, Gurugram\nE-mail                       \n: guptapayal047@gmail.com\nContact No             \n: +91-9536309932\nMarital Status          \n: Single\nGender                  \n: Female\nNationality           \n: Indian\nLanguages Known    \n: English, Hindi. (Read / Write / Speak)\nHobbies                \n: Traveling, reading books and singing.","annotation":null,"extras":null,"metadata":{"first_done_at":1631182657000,"last_updated_at":1631182657000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Payal Gupta \nContact: +91-9536309932 Mail: guptapayal047@gmail.com \n\n \n\n \n\nOBJECTIVE \n\n \nTo work in learning and challenging environment, utilizing my skills and knowledge to be \nthe best of my abilities and contribute positively to my personal growth as well as growth \nof the organization. \n \nPROFESSIONAL SYNOPSIS \n\n \n● 1.5 years of experience as SQL Developer with different types of projects \n\nexecution related to data.  \n● Efficient in SQL SSDT and Business Intelligence concepts with emphasis on \n\ndimensional Modeling & Data Integration. \n● Strong SQL and PL/SQL programming skills, Proficient in writing stored procedures, \n\npackages. \n● Knowledge of SQL Server Data Tools and Work Experience in SSIS and SSRS. \n● Hands on experience of cloud platforms like Azure and AWS (Integration of Azure \n\nSQL and implementing the AZURE DATA LAKE and AWS DATA LAKE. \n● Possess strong interpersonal, communication and analytical skills with demonstrated \n\nabilities in customer relationship management. \n● Ability to work on semi structured, unstructured and structured data and its analyses. \n \nSkills \n\nLanguages Core Java, Android, Python Basics \n\nTools          PL-SQL Developer, SQL Developer, Microsoft SSIS, SSRS \n\nDatabase SQL Server 2008R2/14/17 \n\nDomain Insurance \n\n \n\nExperience \n\n \n\n July’2018 to current with Xceedance, Gurgaon, as Analyst Programmer \n\nL1(Developer) \n\nProjects \n\n1. Enterprise data warehouse   \nPlatform: SQL Server, SSIS, SSRS \nDescription: \nIn this project, the Client has different regions and different sources (Application, Excel \nFiles) through which the information regarding an insurance policy can be seen. \nWe make different packages in SSIS to collect and load data different sources into \n\ndatabase. We run different packages which load into our staging table of another \nenvironment and further to other environment tables. Developed SQL scripts loads data \nfrom different sources and stores it in Enterprise data warehouse in required state. \nThereafter, reports are generated as a final visualization of data in SSRS. \n \nAccountabilities: \n Client communication for understanding requirements and thus creating mapping \n\nbetween source and target data models. \n Coordinating technical activities and periodic client reviews and providing change fix. \n Resolve technical issues during implementation stages. \n Root cause analysis and analysis reports of issues raised by client. \n Status reporting to the client at various stages. \n\n\n\n SSIS (SQL Server Integration Services) – Using Microsoft SQL Server Integration \nServices tool to import data from different sources to the SQL server and storing all \nthe data in Enterprise Data Warehouse. \n\n Develop scripts in SQL Server SSIS packages. So, we have different ETL’s under which \nthe SSIS packages runs and perform the data migration operations from source to \ndatabase. \n\n Core team member responsible for execution of project. \n \n2. Medical Stop Loss (Health Insurance) \nPlatform: SQL Server, SSIS, SSRS \nDescription:  \n\nThis project is based on a separate Product line of insurance for which underwriters has a \ndifferent application. When any new policy first arrived in business, underwriter write the \npolicy and all the related information in application system which is a source for these pol\nicies. Then our work will be started to first map all the fields of application from database\n. The aim of this project is to load the insurance data in ENETRPRISE DATA WAREHOUSE. \nSo, we develop the scripts in SQL server in which we have the columns of warehouse and \n\nDB to load the data in warehouse as according to the columns in warehouse. So, we deve\nlop SSIS packages under which we write the stored procedures and scripts and run the w\nhole package to start the loading process from source to warehouse. \n\n \n3. Email Automation (Using Azure)  \nPlatform: Microsoft Azure Platform \nDescription: Load the Email data in Cloud Azure Storage. Use of Logic App in Azure to \nautomate the emails. Insert the data from Cloud to SQL using external tables. Automate \nthe Stored Procedure. When the Logic app runs in azure data will be in SSRS Reports. \n \n\n   \n4. Data Lake Implementation (Using AWS)  \nPlatform: Amazon Web Services (AWS) \nDescription: Load the data in AWS Storage. Use of DB in AWS like Athena. Insert the \n\ndata from AWS Storage and create table in Athena DB \n \n\nAccountabilities: \n● Involvement in all the meetings and sessions to understand the application and \n\nbusiness requirements and for mapping of data from application to database. \n● Mapping of Enterprise Data Warehouse columns with database columns to easily \n\nload the data from database to EDW. \n\n● Designed, Developed and Deployed SQL SCRIPTS in MS SQL Server environment. \n● Generated the requirement documents and the mapping document to complete the \n\nunderstanding of all the mapping work and related information. \n● Designed SSIS Packages to extract, transfer and load (ETL) data from application \n\nto SQL Server.  \n● Designed, reviewed, and created the stored procedures and scripts and take the \n\nproper understanding of all the views and its definition. \n \nSCHOLASTICS \n\n \n● 10th from C.B.S.E with 70% marks. \n● 12th from C.B.S.E with 59.2% marks. \n● BCA from Bareilly College with 65% marks. \n● MCA from Shri Ram Murti Smarak College of Engineering and Technology with 80%.","annotation":[{"label":["Highest degree"],"points":[{"start":5288,"end":5364,"text":"MCA from Shri Ram Murti Smarak College of Engineering and Technology with 80%"}]},{"label":["Grad. score"],"points":[{"start":5243,"end":5282,"text":"BCA from Bareilly College with 65% marks"}]},{"label":["12 %"],"points":[{"start":5203,"end":5238,"text":" 12th from C.B.S.E with 59.2% marks."}]},{"label":["Highest degree"],"points":[{"start":5167,"end":5198,"text":"10th from C.B.S.E with 70% marks"}]},{"label":["Skills"],"points":[{"start":4991,"end":4993,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4914,"end":4917,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":4733,"end":4735,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4715,"end":4717,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":4403,"end":4557,"text":"Involvement in all the meetings and sessions to understand the application and \n\nbusiness requirements and for mapping of data from application to database"}]},{"label":["Skills"],"points":[{"start":4139,"end":4142,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":4031,"end":4033,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":3857,"end":4151,"text":"Platform: Microsoft Azure Platform \nDescription: Load the Email data in Cloud Azure Storage. Use of Logic App in Azure to \nautomate the emails. Insert the data from Cloud to SQL using external tables. Automate \nthe Stored Procedure. When the Logic app runs in azure data will be in SSRS Reports."}]},{"label":["Skills"],"points":[{"start":3666,"end":3669,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3516,"end":3518,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":3027,"end":3814,"text":"This project is based on a separate Product line of insurance for which underwriters has a \ndifferent application. When any new policy first arrived in business, underwriter write the \npolicy and all the related information in application system which is a source for these pol\nicies. Then our work will be started to first map all the fields of application from database\n. The aim of this project is to load the insurance data in ENETRPRISE DATA WAREHOUSE. \nSo, we develop the scripts in SQL server in which we have the columns of warehouse and \n\nDB to load the data in warehouse as according to the columns in warehouse. So, we deve\nlop SSIS packages under which we write the stored procedures and scripts and run the w\nhole package to start the loading process from source to warehouse"}]},{"label":["Skills"],"points":[{"start":3005,"end":3008,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":2999,"end":3002,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2987,"end":2989,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2787,"end":2790,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2727,"end":2730,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2716,"end":2718,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2697,"end":2871,"text":"Develop scripts in SQL Server SSIS packages. So, we have different ETL’s under which \nthe SSIS packages runs and perform the data migration operations from source to \ndatabase"}]},{"label":["Skills"],"points":[{"start":2626,"end":2628,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2543,"end":2545,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2492,"end":2494,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2486,"end":2690,"text":"SSIS (SQL Server Integration Services) – Using Microsoft SQL Server Integration \nServices tool to import data from different sources to the SQL server and storing all \nthe data in Enterprise Data Warehouse"}]},{"label":["Skills"],"points":[{"start":2486,"end":2489,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2057,"end":2060,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":1877,"end":1879,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1677,"end":1680,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":1473,"end":2060,"text":"In this project, the Client has different regions and different sources (Application, Excel \nFiles) through which the information regarding an insurance policy can be seen. \nWe make different packages in SSIS to collect and load data different sources into \n\ndatabase. We run different packages which load into our staging table of another \nenvironment and further to other environment tables. Developed SQL scripts loads data \nfrom different sources and stores it in Enterprise data warehouse in required state. \nThereafter, reports are generated as a final visualization of data in SSRS"}]},{"label":["Skills"],"points":[{"start":1453,"end":1456,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":1447,"end":1450,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1435,"end":1437,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1230,"end":1232,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1214,"end":1217,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":1208,"end":1211,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1183,"end":1185,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1168,"end":1170,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1165,"end":1170,"text":"PL-SQL"}]},{"label":["Skills"],"points":[{"start":806,"end":808,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":724,"end":863,"text":"Hands on experience of cloud platforms like Azure and AWS (Integration of Azure \n\nSQL and implementing the AZURE DATA LAKE and AWS DATA LAKE"}]},{"label":["Skills"],"points":[{"start":715,"end":718,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":706,"end":709,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":661,"end":663,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":568,"end":570,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":557,"end":559,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":550,"end":642,"text":"Strong SQL and PL/SQL programming skills, Proficient in writing stored procedures, \n\npackages"}]},{"label":["Skills"],"points":[{"start":443,"end":445,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":350,"end":352,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":323,"end":423,"text":"1.5 years of experience as SQL Developer with different types of projects \n\nexecution related to data"}]},{"label":["Total experience"],"points":[{"start":89,"end":290,"text":"To work in learning and challenging environment, utilizing my skills and knowledge to be \nthe best of my abilities and contribute positively to my personal growth as well as growth \nof the organization."}]},{"label":["Email"],"points":[{"start":43,"end":65,"text":"guptapayal047@gmail.com"}]},{"label":["Phone"],"points":[{"start":26,"end":35,"text":"9536309932"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Payal Gupta"}]}],"extras":null,"metadata":{"first_done_at":1631171008000,"last_updated_at":1631171008000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Sinu kumari \nNew Delhi   +91-7256918483,7701991725\nsinudubey@gmail.com  \n\n\tSeeking a responsible career where my abilities can be highly utilized in a growth oriented and professional environment. To achieve organizational goals and reach the pinnacle of success in sprit of team work by utilizing my educational background and skills.\n\n\nWork HISTORY\n\tfrom: NOV 2017 – To: currently working here as\n analyst, globallogic technologies ltd (gurgaon)\nMore than a year experience of working in Analytics industry. Working as analyst  for a google project of E-Commerce sites or Shopping sites. Providing my knowledge and skills to the fullest to my organization. \n\nJOB DESCRIPTION\n\n· Analyzing the content of data pool and processing it as per the framework given by the client (GOOGLE).\n\n· Managing the team of 30 raters as their POC handling the task of assigning work of them and managing their performance indicator using the Google Sheet Dashboard, \n\n· Computer skills with experience Microsoft SQL server management studio Creating( tables, views, index in SQL.\n· Experience in  Database Design and Programming(Stored Procedures) \n             using SQL server 2012\n\n\n\n\n\n\nEducation\n\t2013-2017 \nb.tech, NETAJI SUBASH INSTITUTE OF TECHNOLOGY PATNA\nAKU university- ELECTRINICS & COMMUNICATION\n\n\t2011-2013 \n12th, J.D WOMENS COLLEGE (PATNA)\nBSEB BOARD\n\n\n\t2010\n10TH project girls high school (chandan)\nBSEB BOARD\n\n\n\nSkills\n\tSOFT SKILLS\n· Risk Management Processes & Analysis\n· Project & Data Management\n· Conflict Resolution\n· Good trainer & Adaptability\n· Problem handling & Decision making\n· Team Management & Team work \n· Ability to work under pressure\n\tTECHNICAL SKILLS\n· SQL/PLSQL\n· MS Excel (VLOOKUP,HLOOKUP,PIVOT TABLE) GOOGLE SHEET\n· JAVA\n· HTML & CSS\n· WEB DESIGNING\n· J SCRIPT\n· Tableau (desktop)\n\n\n\n\t\n\t\n\n\n\n\n2","annotation":[{"label":["Skills"],"points":[{"start":1785,"end":1800,"text":"Tableau (desktop"}]},{"label":["Skills"],"points":[{"start":1774,"end":1781,"text":"J SCRIPT"}]},{"label":["Skills"],"points":[{"start":1752,"end":1754,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1745,"end":1748,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1738,"end":1741,"text":"JAVA"}]},{"label":["Skills"],"points":[{"start":1678,"end":1680,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1676,"end":1680,"text":"PLSQL"}]},{"label":["Skills"],"points":[{"start":1672,"end":1674,"text":"SQL"}]},{"label":["10 %"],"points":[{"start":1357,"end":1407,"text":"10TH project girls high school (chandan)\nBSEB BOARD"}]},{"label":["12 %"],"points":[{"start":1305,"end":1347,"text":"12th, J.D WOMENS COLLEGE (PATNA)\nBSEB BOARD"}]},{"label":["Highest degree"],"points":[{"start":1196,"end":1290,"text":"b.tech, NETAJI SUBASH INSTITUTE OF TECHNOLOGY PATNA\nAKU university- ELECTRINICS & COMMUNICATION"}]},{"label":["Skills"],"points":[{"start":1152,"end":1154,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1059,"end":1061,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":996,"end":998,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":954,"end":1061,"text":"Computer skills with experience Microsoft SQL server management studio Creating( tables, views, index in SQL"}]},{"label":["Total experience"],"points":[{"start":787,"end":947,"text":"Managing the team of 30 raters as their POC handling the task of assigning work of them and managing their performance indicator using the Google Sheet Dashboard"}]},{"label":["Total experience"],"points":[{"start":680,"end":780,"text":"Analyzing the content of data pool and processing it as per the framework given by the client (GOOGLE"}]},{"label":["designation"],"points":[{"start":521,"end":527,"text":"analyst"}]},{"label":["Total experience"],"points":[{"start":448,"end":656,"text":"More than a year experience of working in Analytics industry. Working as analyst  for a google project of E-Commerce sites or Shopping sites. Providing my knowledge and skills to the fullest to my organization"}]},{"label":["Experience in current company"],"points":[{"start":409,"end":445,"text":"globallogic technologies ltd (gurgaon"}]},{"label":["designation"],"points":[{"start":400,"end":406,"text":"analyst"}]},{"label":["Total experience"],"points":[{"start":75,"end":334,"text":"Seeking a responsible career where my abilities can be highly utilized in a growth oriented and professional environment. To achieve organizational goals and reach the pinnacle of success in sprit of team work by utilizing my educational background and skills."}]},{"label":["Email"],"points":[{"start":51,"end":69,"text":"sinudubey@gmail.com"}]},{"label":["Phone"],"points":[{"start":40,"end":49,"text":"7701991725"}]},{"label":["Phone"],"points":[{"start":29,"end":38,"text":"7256918483"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Sinu kumari"}]}],"extras":null,"metadata":{"first_done_at":1631178918000,"last_updated_at":1631178918000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Neeraj Sinha\nPalam, New Delhi (India) | +91-9582830569 | nsneerajsinha32@gmail.com\n\nObjective\nSeeking a responsible career opportunity to fully utilize my training and professional skills, while making a significant contribution to the success of the organization.\nProfile Summary\n· Solutions driven Analyst having 17 months of experience in requirements analysis, secondary research, knowledge base development, reviewing information, documentation, mentoring probationers and providing training on multiple domains.\n· By being a Software Trainee for 4 months, I am also having an experience in contributing my efforts to technical team on real time projects by coding, testing and documentation.\t\n\nExperience\n\nAnalyst at GlobalLogic                                                                        Mar, 2018 – Sep, 2019\n\n· Requirements analysis\n· Perform Secondary and Boolean research\n· Collate authentic sources to populate information in a work tool.\n· Build and develop a knowledge base of Google search engine covering multiple domains.\n· Review tasks to ensure the accuracy and preciseness of added information.\n· Perform required tasks by keeping the rule of thumbs of relevant domain guidelines in mind.\n· Timely update the knowledge base when needed \n· Understand, evaluate and respond to queries over email.\n· Provide training to probationers on multiple domains and guide them until their probation period.\n· Keep tracking the quality and excellence of probationers.\n· Appear for assessment examinations from time to time.\n· Attend team meetings to know individual and team progress.\n· Ensure set deadlines and targets are met\n· Responsible for achieving both productivity and quality goals.\n· Work on multiple domains simultaneously \n· Provide daily production report to team lead\n\n\nSoftware Trainee at Orane Consulting Pvt Ltd                                   Mar, 2017 – Jul, 2017 \n\n· Requirements gathering and analysis\n· Requirement specification document creation\n· System and software design preparation from requirement specifications \n· Experience in making UML (structural and behavioral), DFD and ER diagrams.\n· Good understanding of waterfall and agile methodologies\n· Design and implement software modules by coding in collaboration with other team members.  \n· Test developed code against the requirements which involves unit, integration, system, acceptance and non-functional testing.\n· Maintenance and modify applications from time to time to fix bugs.\n\n\nTechnical skills\t\nBasic idea about below mentioned skills:\n· Programming languages : C, C ++, Java, HTML, CSS\n· Database : MySQL\n· Operating system : Windows, Linux\n· MS Office : MS Word, Excel, PowerPoint\n· Tools : Turbo C, Eclipse, Rational Rose, Hume\n\nSoft skills: Interpersonal skills, Adaptability, Team work, Creativity, Problem solving.\n   \nEducation\n· MCA from IITM college of GGSIPU in 2017.\n· BSc (Hons) Electronics from Sri Venkateswara College of Delhi University in 2014.\n· 10+2 from KV No-1 in 2011.\n· Matriculation from KV No-1 in 2009.\n\n\nProjects\n· HR On-boarding: This project comprises an interface between a candidate and an organisation. Here the candidate can interact with the HR and socialize with other peers through this interface. The project aimed to build a relationship between a candidate and server which further leads to services that are provided by the organisation. It also tracks various issues of newly joined employees and assists them accordingly.  \n· Knowledge Graph: HUME is a project maintained by the Knowledge Graph Team all over the world. As a part of ICO (Indian Content Operations) I contribute my knowledge and expertise as an Analyst, towards this innovative and interesting Project. \nIt focuses towards the integration of world’s knowledge at one place where it is available to the public domain. A search for a single entity will get you through the entire world behind that. It is a network of real world entities along with their information.\n\nAchievements\n· Times of India merit scholarship.\n· ESSA (Educational Scholarship Scheme for Serving Army Personnel) scholarship.\n· Secured 3rd position in graduation.\n· Got promoted to Analyst position from Associate Analyst.\n· Appreciation from team lead for meeting team targets within stipulated time.\n· Top 10 performers in the entire process in two quarters.","annotation":[{"label":["Total experience"],"points":[{"start":4041,"end":4116,"text":"ESSA (Educational Scholarship Scheme for Serving Army Personnel) scholarship"}]},{"label":["Skills"],"points":[{"start":3602,"end":3602,"text":"C"}]},{"label":["Skills"],"points":[{"start":3591,"end":3591,"text":"C"}]},{"label":["Total experience"],"points":[{"start":3057,"end":3476,"text":"HR On-boarding: This project comprises an interface between a candidate and an organisation. Here the candidate can interact with the HR and socialize with other peers through this interface. The project aimed to build a relationship between a candidate and server which further leads to services that are provided by the organisation. It also tracks various issues of newly joined employees and assists them accordingly"}]},{"label":["10 %"],"points":[{"start":3008,"end":3041,"text":"Matriculation from KV No-1 in 2009"}]},{"label":["12 %"],"points":[{"start":2979,"end":3003,"text":"10+2 from KV No-1 in 2011"}]},{"label":["Skills"],"points":[{"start":2940,"end":2940,"text":"C"}]},{"label":["Grad. score"],"points":[{"start":2895,"end":2974,"text":"BSc (Hons) Electronics from Sri Venkateswara College of Delhi University in 2014"}]},{"label":["Skills"],"points":[{"start":2853,"end":2853,"text":"C"}]},{"label":["Highest degree"],"points":[{"start":2852,"end":2890,"text":"MCA from IITM college of GGSIPU in 2017"}]},{"label":["Skills"],"points":[{"start":2807,"end":2807,"text":"C"}]},{"label":["Skills"],"points":[{"start":2714,"end":2714,"text":"C"}]},{"label":["Skills"],"points":[{"start":2680,"end":2684,"text":"Excel"}]},{"label":["Skills"],"points":[{"start":2615,"end":2619,"text":"MySQL"}]},{"label":["Skills"],"points":[{"start":2598,"end":2600,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":2598,"end":2598,"text":"C"}]},{"label":["Skills"],"points":[{"start":2592,"end":2595,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":2586,"end":2589,"text":"Java"}]},{"label":["Skills"],"points":[{"start":2580,"end":2584,"text":"C ++,"}]},{"label":["Skills"],"points":[{"start":2580,"end":2580,"text":"C"}]},{"label":["Skills"],"points":[{"start":2577,"end":2577,"text":"C"}]},{"label":["Total experience"],"points":[{"start":2423,"end":2487,"text":"Maintenance and modify applications from time to time to fix bugs"}]},{"label":["Total experience"],"points":[{"start":1946,"end":1988,"text":"Requirement specification document creation"}]},{"label":["Skills"],"points":[{"start":1829,"end":1829,"text":"C"}]},{"label":["Last company"],"points":[{"start":1823,"end":1846,"text":"Orane Consulting Pvt Ltd"}]},{"label":["designation"],"points":[{"start":1803,"end":1819,"text":"Software Trainee "}]},{"label":["Total experience"],"points":[{"start":1328,"end":1423,"text":"Provide training to probationers on multiple domains and guide them until their probation period"}]},{"label":["Total experience"],"points":[{"start":1128,"end":1217,"text":"Perform required tasks by keeping the rule of thumbs of relevant domain guidelines in mind"}]},{"label":["Total experience"],"points":[{"start":1052,"end":1123,"text":"Review tasks to ensure the accuracy and preciseness of added information"}]},{"label":["Total experience"],"points":[{"start":964,"end":1047,"text":"Build and develop a knowledge base of Google search engine covering multiple domains"}]},{"label":["Total experience"],"points":[{"start":896,"end":959,"text":"Collate authentic sources to populate information in a work tool"}]},{"label":["Skills"],"points":[{"start":896,"end":896,"text":"C"}]},{"label":["Experience in current company"],"points":[{"start":712,"end":733,"text":"Analyst at GlobalLogic"}]},{"label":["designation"],"points":[{"start":531,"end":547,"text":"Software Trainee "}]},{"label":["Total experience"],"points":[{"start":520,"end":695,"text":"By being a Software Trainee for 4 months, I am also having an experience in contributing my efforts to technical team on real time projects by coding, testing and documentation"}]},{"label":["Total experience"],"points":[{"start":283,"end":515,"text":"Solutions driven Analyst having 17 months of experience in requirements analysis, secondary research, knowledge base development, reviewing information, documentation, mentoring probationers and providing training on multiple domains"}]},{"label":["Total experience"],"points":[{"start":94,"end":263,"text":"Seeking a responsible career opportunity to fully utilize my training and professional skills, while making a significant contribution to the success of the organization."}]},{"label":["Email"],"points":[{"start":57,"end":81,"text":"nsneerajsinha32@gmail.com"}]},{"label":["Phone"],"points":[{"start":44,"end":53,"text":"9582830569"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Neeraj Sinha"}]}],"extras":null,"metadata":{"first_done_at":1631168000000,"last_updated_at":1631168000000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Priya Pandey 8860674535\nPriya201519pandey@gmail.com Pune, Maharashtra\n\n\n  Experience Summary\t\n· Working as an Analyst (SQL and SSIS Developer).\n· 1.5 years of IT experience.\n· 2.3 years of experience in Crowd Compute.\n· Extensive SQL Development experience in E-Commerce and Finance industries with a strong understanding of data & analytics.\n· Extensive Knowledge of MSBI.\n· Extensive Experience in SSIS (ETL Development)\n· Extensive Experience in T-SQL.\n\n\tSkills Summary\n\n\tDomain\n\tFinance and Banking Applications , Shopping Portal: E-Commerce\n\n\tProgramming Languages\n\tT-SQL\n\n\tOperating System / ERP Version\n\tWindows 7,8,8.1,10\n\n\tTools / DB / Packages\n\tSQL Server Data Tool, MS SQL Server 2008/2012, SSIS.\n\n\n\n  Professional Certiﬁcations/ Trainings\t\nAttended various trainings on MSBI(SSRS,SSIS,SSAS)\n\n\tWork Experience :\n\n\tCompany – Global Logic\n\n\n\n\t1.Project Name\n\tOver-Merge\n\tTeam Size\n\t7\n\n\tStart Date\n\tFeb 2018\n\tEnd Date\n\tMarch 2019\n\n\t\nProject Description\n\tGoogle is an American Multinational Technology Company and the main objective of this project is fetching data from merchant site using SSIS and analyzes them to put in diﬀerent categories according to client requirement.\n\n\t\n\n\nRole & Contribution\n\t· Created SSIS package\n· Created new tables, written stored procedures.\n· Extensively used Joins and sub-Queries to simplify complex queries involving multiple tables.\n· Worked closely with client to understand the requirements and speciﬁcations for any new applications.\n· Responsible for coaching new team- members.\n\n\tTechnology & Tools\n\tMS Excel, SQL Server, SSIS,SQL Server Data Tool\n\n\tKey Achievements\n\t· Accessing Data from merchant site (ﬁles) to SQL server\n\n\n\n\t2. Project Name\n\tBillBoard\n\tTeam Size\n\t8\n\n\tStart Date\n\tSeptember 2017\n\tEnd Date\n\tJanuary 2018\n\n\t\nProject Description\n\tThis is a Banking Project. The main objective of this project is to provide design and support to stockholders more than 2000+ servers and 150 applications for this bank.\n\n\t\n\n\n\n\nRole & Contribution\n\t· Created SSIS package to fetch data from Diﬀerent-Diﬀerent Files.\n· Created new tables, written stored procedures\n· Developed source to target speciﬁcations for Data Transformation Services.\n· Extensively used Joins and sub-Queries to simplify complex queries involving multiple tables and also optimized the procedures and triggers to be used in production.\n\n\n\n\tTechnology & Tools\n\tMS Excel, SQL Server, SQL Server Data Tool(SSIS)\n\n\n\n\n\t3.Project Name\n\tProduct Cluster Reports\n\tTeam Size\n\t6\n\n\tStart Date\n\tJuly 2015\n\tEnd Date\n\tAug 2017\n\n\t\nProject Description\n\tThis is a web-based Dashboard and Reports provide high level business Intelligence and help to management to understand which Products are ready to go on shopping portal.\n\n\t\nRole & Contribution\n\t· Interacted with MIS, Finance team for requirement gathering.\n· Prepare Reports and automate for MIS team using Crowd Compute.\n· Write Code for accessing Data on Crowd Compute Editor.\n\n\tTechnology & Tools\n\tMS Excel, Crowd Compute\n\n\tKey Achievements\n\tWrite Code for accessing Data on Crowd Compute.\n\n\n\n\tEducational Qualiﬁcation :\n\n\tMCA\n\tCompleted MCA from Banasthali Univercity in Year 2015 with First Class (74.5%).\n\n\tBSC (IT)\n\tCompleted BSC From Banasthali Univercity in Year 2012 with First Class (69.8%).\n\n\t12th\n\tCompleted 12th From D.A.V in Year 2009 with First Class (76.5%).\n\n\t10th\n\tCompleted 10th From D.A.V in Year 2007 with First Class (79.6%).","annotation":[{"label":["10 %"],"points":[{"start":3335,"end":3403,"text":"10th\n\tCompleted 10th From D.A.V in Year 2007 with First Class (79.6%)"}]},{"label":["12 %"],"points":[{"start":3262,"end":3330,"text":"12th\n\tCompleted 12th From D.A.V in Year 2009 with First Class (76.5%)"}]},{"label":["Grad. score"],"points":[{"start":3170,"end":3257,"text":"BSC (IT)\n\tCompleted BSC From Banasthali Univercity in Year 2012 with First Class (69.8%)"}]},{"label":["Highest degree"],"points":[{"start":3083,"end":3165,"text":"MCA\n\tCompleted MCA from Banasthali Univercity in Year 2015 with First Class (74.5%)"}]},{"label":["Skills"],"points":[{"start":2958,"end":2965,"text":"MS Excel"}]},{"label":["Total experience"],"points":[{"start":2556,"end":2725,"text":"This is a web-based Dashboard and Reports provide high level business Intelligence and help to management to understand which Products are ready to go on shopping portal."}]},{"label":["Skills"],"points":[{"start":2423,"end":2426,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2402,"end":2404,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2390,"end":2392,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2380,"end":2387,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":2006,"end":2009,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":1797,"end":1965,"text":"This is a Banking Project. The main objective of this project is to provide design and support to stockholders more than 2000+ servers and 150 applications for this bank"}]},{"label":["Skills"],"points":[{"start":1664,"end":1666,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1577,"end":1579,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1572,"end":1575,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1560,"end":1562,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1550,"end":1557,"text":"MS Excel"}]},{"label":["Total experience"],"points":[{"start":1235,"end":1376,"text":"Created new tables, written stored procedures.\n· Extensively used Joins and sub-Queries to simplify complex queries involving multiple tables."}]},{"label":["Skills"],"points":[{"start":1220,"end":1223,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1098,"end":1101,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":962,"end":1181,"text":"Google is an American Multinational Technology Company and the main objective of this project is fetching data from merchant site using SSIS and analyzes them to put in diﬀerent categories according to client requirement"}]},{"label":["Skills"],"points":[{"start":792,"end":795,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":702,"end":705,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":680,"end":682,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":655,"end":657,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":573,"end":575,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":571,"end":575,"text":"T-SQL"}]},{"label":["Skills"],"points":[{"start":451,"end":453,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":449,"end":453,"text":"T-SQL"}]},{"label":["Skills"],"points":[{"start":400,"end":403,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":230,"end":232,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":220,"end":340,"text":"Extensive SQL Development experience in E-Commerce and Finance industries with a strong understanding of data & analytics"}]},{"label":["Skills"],"points":[{"start":127,"end":130,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":119,"end":121,"text":"SQL"}]},{"label":["Email"],"points":[{"start":24,"end":50,"text":"Priya201519pandey@gmail.com"}]},{"label":["Phone"],"points":[{"start":13,"end":22,"text":"8860674535"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Priya Pandey"}]}],"extras":null,"metadata":{"first_done_at":1631178788000,"last_updated_at":1631178788000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Ankita Swarnkar\nMobile\t\t:  +91 8962473573 \nEmail ID \t:  Ankita.swarnkr@gmail.com\nMSSQL and Sybase Database Administrator \n\nCareer Objectives\nTo take challenging, high-end domain-oriented projects and to excel in the field of Information Technology as an MSSQL and Sybase Database Administrator by contributing continuously towards organizational growth by providing seamless database support and to utilize every opportunity to achieve both personal and professional development. \n\nProfessional Summary\n· Around 2.2 years of experience as a DBA providing 24x7 production and Non-Production Maintenance & Support for MSSQL and Sybase.\n· I have supported for both MSSQL and Sybase issues on-call for 24*7.\n· Backups-Confirming that backups have been made and successfully saved to a secure location, also backups jobs are running successfully to given data domain\n· Monitor all backup and log history cleanup\n· Disk Space-Verifying the free space on each drive on all servers. If there is significant variance in free space from the day before, research the cause of the free space fluctuation and resolve if necessary. Often, log files will grow because of monthly jobs. \n· Jobs / Maintenance Plans-Check for the failed jobs, investigate the root cause and resolve the issue. Worked on Checking for the job execution duration and if any significant changes find the root cause and resolve the issue.\n· Expertise in making reports for all cleanup jobs are running fine, temp tables, logs, history, backup files etc.\n· Server-Confirming all servers/databases are up and running fine, with proper health checks.\n· Performance-Regularly monitoring and identifying blocking issues. Checking Performance counters on all production servers and verifying that all counters are within the normal range\n· Check the fragmentation and rebuild/ reorganize the indexes. Making sure all Stats Update, Index Rebuild jobs are completed without any issue.\n· Logs-Taking a look at both SQL Server logs and Windows logs. Check the centralized error logs if any.\n· Security-Checking the error logs for failed logins. Reviewing the security logs and check the logins, service accounts for expire date  \n· High-Availability for MSSQL-High Availability or Disaster Recovery Logs – Checking all our high availability and/or disaster recovery process logs.\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfessional Experience\nProject 1: FEDEX \nDescription\t\t:    \tMaintenance and Support of MSSQL servers and SYBASE databases\nDuration       \t\t:    \t1.1 Years (From MAY 2018 to till the date)\nEnvironment\t\t:\tMSSQL—2005,2008,2008 R2, 2012 and 2016\n                                                    SYBASE—ASE 12.5.0 and ASE 15.5.0\t\nMSSQL:\n\n· I have handled all databases day to day issues as jobs, space, logs, connectivity and login failures.\n· I have patched the server with latest service pack and required cumulative updates.\n· Worked several times to repair the consistency and allocation errors for databases with proper approved change window.\n· I have migrated the databases from one SQL server to another successfully and logins as well.\n· I have recovered the database from suspect mode.\n· Worked with application team for scripts running and troubleshooting errors while their issues.\n· Worked extensively in database backups and restoration\n· Worked for application team for attaching and de-attaching the databases when they have issue.\n· I have worked in changing the compatibilities with application team for theirs’ to SQL\n· I have worked in securities and access.\n· Worked in Index rebuild and CDC concepts as in a critical database.\n· Worked in bringing back up the share point critical cluster servers when went down due to many network, data domain, storage and windows issue.\n· Worked in installing the OEM agent in MSSQL server for monitoring\n· Worked in Always on server, configured Always On, trouble shooed the issues when Always On went out of sync\n· Worked in Adding new databases to the Always on cluster\n· I could work in a fast-paced environment, Good team player and can work independently. Helped the database developers on technical issues\n· I have Knowledge of Analysis Services & Reporting Services, SQL Server Clustering, Log Shipping and Replication – Snapshot, Merge and Transactional\n· Provided 24*7 production support for the database and application issues\n· Experienced in resolving deadlock and blocking issues for concurrent users\n· Created Database and Database Objects like Tables, Stored Procedures, Views, Triggers, Rules, Defaults, user defined data types and functions.\n· Worked in decommission of proper SQL server from the Window server.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSYBASE:\n\n· I have handled day to day all databases activities for ASE and backup server\n· Worked in different scenarios of backups and restores.\n· I have worked in synchronizing the database between the backup tool and control files.\n· Worked in generation of control files for the orphan databases with the help of sbacktrack tool.\n· Worked with application team for scripts running and error troubleshooting.\n· Worked in access and securities for the users and databases.\n· Worked in replication server and troubleshooted the various received alerts.\n· Worked in resuming the connection between source and destination replication server.\n· Worked in lock and unlocking if the accounts\n· Worked in issues when the Sybase server unresponsive and getting login failure alerts.\n· Worked in the backup failure issue due to wait time lock issue.\n· Worked in the file system usage scenarios.\n· I have worked for various thread alerts in Sybase servers.\n· Worked in segment utilization alerts for both system and user databases\n· I have handled the whole track alone for 9 months and being on-call have supported the track 24*7.\n\n\nProject 2: WORKING LINKS EMPLOYMENT LIMITED\t\t\t\t\t\nDescription\t\t: \tMaintenance and Support of MSSQL Servers \nEnvironment\t\t:\tSQL server 2005, 2008, 2008 R2, 2012 and 2016\nDuration        \t\t:\t1.1Years (March 2017 to April 2018)\n\t\nMSSQL\n· Worked on sending backup report for critical servers and managing the drive spaces every day. \n· We worked to verify backups and test on a regular basis to ensure the overall process works as expected\n· Worked in making billing report for all the MSSQL servers which needs to send to the customer.\n· Worked in Job scheduling, access and securities.\n· Worked in patching both cluster MSSQL servers and standalone server.\n· Installed SQL server 2016 in mew windows server.\n· Worked as primary on-call for application's script running and database connection issue and other troubleshooting\n· Worked during migrations of MSSQL server to other organization.\n· Worked in backup and restorations\n· I have handled different log shipping servers and troubleshooted the issues.\n· Worked in issues where application is facing slowness.\n\n\nQuality Management Process \n· Documentation - Preparing documents like Work Instructions, SOP, action plans \n· Quality –Providing incident management and change management related data to management. \n· Incident Management and Service delivery: Following all client specific approval processes for routine DBA activities. Maintaining all incident management data and provide management for decision making\n\n\n\n\n\n\nCertifications\n\tNo\n\tName of Institute \n\tCertificate\n\tYear\n\n\t1\n\tMicrosoft Corporation\n\tPerusing MCA (Microsoft Certified Associate)- 70764\n\t2019\n\n\n\nEducation \n\tDegree\n\tUniversity\n\tScore in %\n\tYear\n\n\tB. E\n\tShri Shankaracharya Technical Campus (C.G)\n\t82.17%\n\t2015\n\n\t12th\n\tState Board\n\t89.16%\n\t2011\n\n\t10th\n\tState Board\n\t89.23%\n\t2009\n\n\n\n\nTraining\nMSSQL Database Administrator, Manesar (Classroom Training and On Job Training for six months)\n\nPersonal Details\nDate of Birth    \t\t:  29th January’1994\nPan card No                    : GARPS4939H\nAddress            \t\t:  House No-94, Ward No-09, Kumhari, Dist-Durg, Chhattisgarh\nLanguage Known \t:  English and Hindi\n \nDeclaration\nI hereby declare that all the above information submitted by me is true and correct to the best of my knowledge\t\nPlace\t:  New Delhi\nDate\t:\t\t\nAnkita Swarnkar","annotation":[{"label":["Name"],"points":[{"start":8060,"end":8074,"text":"Ankita Swarnkar"}]},{"label":["Skills"],"points":[{"start":7590,"end":7594,"text":"MSSQL"}]},{"label":["10 %"],"points":[{"start":7545,"end":7575,"text":"10th\n\tState Board\n\t89.23%\n\t2009"}]},{"label":["12 %"],"points":[{"start":7511,"end":7541,"text":"12th\n\tState Board\n\t89.16%\n\t2011"}]},{"label":["Grad. score"],"points":[{"start":7446,"end":7507,"text":"B. E\n\tShri Shankaracharya Technical Campus (C.G)\n\t82.17%\n\t2015"}]},{"label":["Highest degree"],"points":[{"start":7334,"end":7390,"text":"Perusing MCA (Microsoft Certified Associate)- 70764\n\t2019"}]},{"label":["Skills"],"points":[{"start":6626,"end":6630,"text":"MSSQL"}]},{"label":["Skills"],"points":[{"start":6391,"end":6395,"text":"MSSQL"}]},{"label":["Skills"],"points":[{"start":6255,"end":6259,"text":"MSSQL"}]},{"label":["Skills"],"points":[{"start":6000,"end":6004,"text":"MSSQL"}]},{"label":["Skills"],"points":[{"start":5907,"end":5910,"text":"2005"}]},{"label":["Skills"],"points":[{"start":5866,"end":5870,"text":"MSSQL"}]},{"label":["Total experience"],"points":[{"start":5599,"end":5669,"text":"Worked in segment utilization alerts for both system and user databases"}]},{"label":["Total experience"],"points":[{"start":4417,"end":4557,"text":"Created Database and Database Objects like Tables, Stored Procedures, Views, Triggers, Rules, Defaults, user defined data types and functions"}]},{"label":["Skills"],"points":[{"start":3777,"end":3781,"text":"MSSQL"}]},{"label":["Total experience"],"points":[{"start":3593,"end":3734,"text":"Worked in bringing back up the share point critical cluster servers when went down due to many network, data domain, storage and windows issue"}]},{"label":["Total experience"],"points":[{"start":3392,"end":3477,"text":"I have worked in changing the compatibilities with application team for theirs’ to SQL"}]},{"label":["Total experience"],"points":[{"start":3238,"end":3291,"text":"Worked extensively in database backups and restoration"}]},{"label":["Total experience"],"points":[{"start":3140,"end":3233,"text":"Worked with application team for scripts running and troubleshooting errors while their issues"}]},{"label":["Total experience"],"points":[{"start":2872,"end":2988,"text":"Worked several times to repair the consistency and allocation errors for databases with proper approved change window"}]},{"label":["Total experience"],"points":[{"start":2786,"end":2868,"text":"I have patched the server with latest service pack and required cumulative updates."}]},{"label":["Total experience"],"points":[{"start":2682,"end":2781,"text":"I have handled all databases day to day issues as jobs, space, logs, connectivity and login failures"}]},{"label":["Skills"],"points":[{"start":2672,"end":2676,"text":"MSSQL"}]},{"label":["Skills"],"points":[{"start":2553,"end":2556,"text":"2005"}]},{"label":["Skills"],"points":[{"start":2547,"end":2551,"text":"MSSQL"}]},{"label":["Skills"],"points":[{"start":2431,"end":2435,"text":"MSSQL"}]},{"label":["Skills"],"points":[{"start":2204,"end":2208,"text":"MSSQL"}]},{"label":["Total experience"],"points":[{"start":1794,"end":1935,"text":"Check the fragmentation and rebuild/ reorganize the indexes. Making sure all Stats Update, Index Rebuild jobs are completed without any issue."}]},{"label":["Total experience"],"points":[{"start":1173,"end":1396,"text":"Jobs / Maintenance Plans-Check for the failed jobs, investigate the root cause and resolve the issue. Worked on Checking for the job execution duration and if any significant changes find the root cause and resolve the issue"}]},{"label":["Total experience"],"points":[{"start":909,"end":1167,"text":"Disk Space-Verifying the free space on each drive on all servers. If there is significant variance in free space from the day before, research the cause of the free space fluctuation and resolve if necessary. Often, log files will grow because of monthly jobs"}]},{"label":["Total experience"],"points":[{"start":706,"end":860,"text":"Backups-Confirming that backups have been made and successfully saved to a secure location, also backups jobs are running successfully to given data domain"}]},{"label":["Skills"],"points":[{"start":662,"end":666,"text":"MSSQL"}]},{"label":["Total experience"],"points":[{"start":635,"end":701,"text":" I have supported for both MSSQL and Sybase issues on-call for 24*7"}]},{"label":["Skills"],"points":[{"start":616,"end":620,"text":"MSSQL"}]},{"label":["Total experience"],"points":[{"start":505,"end":631,"text":"Around 2.2 years of experience as a DBA providing 24x7 production and Non-Production Maintenance & Support for MSSQL and Sybase"}]},{"label":["designation"],"points":[{"start":254,"end":292,"text":"MSSQL and Sybase Database Administrator"}]},{"label":["Skills"],"points":[{"start":254,"end":258,"text":"MSSQL"}]},{"label":["Total experience"],"points":[{"start":141,"end":477,"text":"To take challenging, high-end domain-oriented projects and to excel in the field of Information Technology as an MSSQL and Sybase Database Administrator by contributing continuously towards organizational growth by providing seamless database support and to utilize every opportunity to achieve both personal and professional development"}]},{"label":["designation"],"points":[{"start":81,"end":119,"text":"MSSQL and Sybase Database Administrator"}]},{"label":["Skills"],"points":[{"start":81,"end":85,"text":"MSSQL"}]},{"label":["Email"],"points":[{"start":56,"end":79,"text":"Ankita.swarnkr@gmail.com"}]},{"label":["Phone"],"points":[{"start":31,"end":40,"text":"8962473573"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"Ankita Swarnkar"}]}],"extras":null,"metadata":{"first_done_at":1631169472000,"last_updated_at":1631169472000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "DEEPANJALI JAIN \n\n \n\nEmail \n\ndeepanjalijain148@gmail.com \n \n\n \n\nContact No. \n\n+91-9983854182 \n\n \n\n \n\nCurrent Location \n\nNoida, Uttar Pradesh \n\n \n\n \nDate of Birth \n\n14th August,1995 \n\n \n\n \n\nLinguistic Proficiency \n\nEnglish  \n\nHindi \n\n \n\n \n\nPermanent Address \n\n21, B-4, Manu Marg, \n\nAlwar - 301001 \n\nRajasthan \n\n \n\nRESUME \n\nOBJECTIVE  \n\nI am looking for a fairly challenging job for Tableau where I can get the opportunity \n\nfor compiling, analyzing, validating and modeling data sets to enhance business \n\noperational performance. I specialize at designing data input structures and statistical \n\nmodels. \n\nWORK EXPERIENCE \n\nCompany: WIPRO HRS India Pvt. Ltd. \n\nDesignation: Analyst \n\nExperience: Since Aug 2017 to Current date \n\nTECHNICAL SKILLS \n\n• Analytical Techniques: MS Excel, SQL, Tableau \n\n• Database: DB2 \n\n• Developer Tools: Tableau, SQL Utility, Mainframe \n\n• Project Management: Agile \n\n• Project Reporting Tool: JIRA \n\n• Languages: C, C++, HTML \n\n• Microsoft Office: MS Word,  MS Excel, MS PowerPoint \n\n• Operating Systems: Windows XP, Windows 7, Windows 10 \n\nPROJECTS  \n\n• Annual Enrollment: This project includes all the Premiums, Prices, Credits, \n\nDeduction Analysis and Report generation for all the participants (employees of \n\nthe Client). This happens every year and since Client tends to start, stop, modify \n\nplan options that should be available to their employees, these reports need to be \n\ngenerated every year. I have also checked how many and when the participants \n\nare terminated from the company and have taken COBRA plans. \n\n• HM Plan Analytics: In this project I created the reports and data visualization \n\nusing Tableau which contained the plan information of participants to check that \n\nif any mid-year life event like Marriage, Birth/Adoption (QSC) has occurred for \n\nthem, then how many of them have  changed the option and how many have \n\nremained consistent. \n\nHANDS ON EXPERIENCE  \n\n• Worked with major clients across USA. The product is based on the Health and \n\nWelfare domain. US government and companies have rules/policies to give the \n\nbenefit plans like Medical, Dental, Vision, Disability, Life, Accidental etc. to \n\ntheir employees. \n\n• Generated ad-hoc reports, sub-reports, drill-down reports, drill-through reports \n\nand parameterized reports to provide visible data for data analysts and business \n\nusing Tableau. \n\n• Performed business analysis and wrote SQL scripts to analyze data and parse to \nExcel. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n  \n\n\n\nEDUCATION   \n\nB.Tech. (Computer Science & Engineering): Institute of Engineering & Technology, Alwar \n\nRajasthan Technical University \n\nYear: 2017                    Aggregate: 72.92% \n\nStd. XII: Chinar Public School, Alwar \n\n Central Board of Secondary Education \n\nYear: 2013                    Aggregate: 77% \n\nStd. X: Chinar Public School, Alwar \n\n Central Board of Secondary Education \n\nYear: 2011                    CGPA: 9.8 \n\nSTRENGTHS  \n\nGood listener, Optimistic, Sincere, Honest, Creative, Have team spirit & dedicated towards work. \n\nHOBBIES  \n\nArt & Craft, Calligraphy, Playing Volleyball & Basketball, Listening to Music. \n\nDECLARATION   \n\nI hereby declare that particulars given herein are true to the best of my knowledge and belief. \n\n \n\nDEEPANJALI JAIN","annotation":[{"label":["Name"],"points":[{"start":3270,"end":3284,"text":"DEEPANJALI JAIN"}]},{"label":["Skills"],"points":[{"start":3155,"end":3155,"text":"C"}]},{"label":["Skills"],"points":[{"start":3085,"end":3085,"text":"C"}]},{"label":["Skills"],"points":[{"start":3078,"end":3078,"text":"C"}]},{"label":["Skills"],"points":[{"start":3006,"end":3006,"text":"C"}]},{"label":["Skills"],"points":[{"start":2937,"end":2937,"text":"C"}]},{"label":["Skills"],"points":[{"start":2868,"end":2868,"text":"C"}]},{"label":["Skills"],"points":[{"start":2837,"end":2837,"text":"C"}]},{"label":["10 %"],"points":[{"start":2834,"end":2945,"text":"X: Chinar Public School, Alwar \n\n Central Board of Secondary Education \n\nYear: 2011                    CGPA: 9.8"}]},{"label":["Skills"],"points":[{"start":2743,"end":2743,"text":"C"}]},{"label":["Skills"],"points":[{"start":2712,"end":2712,"text":"C"}]},{"label":["12 %"],"points":[{"start":2707,"end":2825,"text":"XII: Chinar Public School, Alwar \n\n Central Board of Secondary Education \n\nYear: 2013                    Aggregate: 77%"}]},{"label":["Skills"],"points":[{"start":2539,"end":2539,"text":"C"}]},{"label":["Highest degree"],"points":[{"start":2530,"end":2649,"text":"B.Tech. (Computer Science & Engineering): Institute of Engineering & Technology, Alwar \n\nRajasthan Technical University "}]},{"label":["Skills"],"points":[{"start":2519,"end":2519,"text":"C"}]},{"label":["Skills"],"points":[{"start":2412,"end":2414,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2361,"end":2367,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":2189,"end":2367,"text":"Generated ad-hoc reports, sub-reports, drill-down reports, drill-through reports \n\nand parameterized reports to provide visible data for data analysts and business \n\nusing Tableau"}]},{"label":["Total experience"],"points":[{"start":1928,"end":2182,"text":"Worked with major clients across USA. The product is based on the Health and \n\nWelfare domain. US government and companies have rules/policies to give the \n\nbenefit plans like Medical, Dental, Vision, Disability, Life, Accidental etc. to \n\ntheir employees"}]},{"label":["Skills"],"points":[{"start":1920,"end":1920,"text":"C"}]},{"label":["Skills"],"points":[{"start":1785,"end":1785,"text":"C"}]},{"label":["Skills"],"points":[{"start":1648,"end":1654,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":1560,"end":1899,"text":"HM Plan Analytics: In this project I created the reports and data visualization \n\nusing Tableau which contained the plan information of participants to check that \n\nif any mid-year life event like Marriage, Birth/Adoption (QSC) has occurred for \n\nthem, then how many of them have  changed the option and how many have \n\nremained consistent."}]},{"label":["Skills"],"points":[{"start":1543,"end":1543,"text":"C"}]},{"label":["Skills"],"points":[{"start":1294,"end":1294,"text":"C"}]},{"label":["Skills"],"points":[{"start":1251,"end":1251,"text":"C"}]},{"label":["Skills"],"points":[{"start":1154,"end":1154,"text":"C"}]},{"label":["Total experience"],"points":[{"start":1087,"end":1554,"text":"Annual Enrollment: This project includes all the Premiums, Prices, Credits, \n\nDeduction Analysis and Report generation for all the participants (employees of \n\nthe Client). This happens every year and since Client tends to start, stop, modify \n\nplan options that should be available to their employees, these reports need to be \n\ngenerated every year. I have also checked how many and when the participants \n\nare terminated from the company and have taken COBRA plans."}]},{"label":["Skills"],"points":[{"start":1078,"end":1078,"text":"C"}]},{"label":["Skills"],"points":[{"start":990,"end":997,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":980,"end":986,"text":"MS Word"}]},{"label":["Skills"],"points":[{"start":953,"end":956,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":948,"end":950,"text":"C++"}]},{"label":["Skills"],"points":[{"start":948,"end":948,"text":"C"}]},{"label":["Skills"],"points":[{"start":945,"end":945,"text":"C"}]},{"label":["Skills"],"points":[{"start":844,"end":846,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":835,"end":841,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":788,"end":794,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":783,"end":785,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":773,"end":780,"text":"MS Excel"}]},{"label":["Skills"],"points":[{"start":735,"end":735,"text":"C"}]},{"label":["Skills"],"points":[{"start":731,"end":731,"text":"C"}]},{"label":["Skills"],"points":[{"start":714,"end":714,"text":"C"}]},{"label":["Experience in current company"],"points":[{"start":633,"end":656,"text":"WIPRO HRS India Pvt. Ltd"}]},{"label":["Skills"],"points":[{"start":624,"end":624,"text":"C"}]},{"label":["Skills"],"points":[{"start":619,"end":619,"text":"C"}]},{"label":["Skills"],"points":[{"start":381,"end":387,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":335,"end":602,"text":"I am looking for a fairly challenging job for Tableau where I can get the opportunity \n\nfor compiling, analyzing, validating and modeling data sets to enhance business \n\noperational performance. I specialize at designing data input structures and statistical \n\nmodels."}]},{"label":["Skills"],"points":[{"start":326,"end":326,"text":"C"}]},{"label":["Address"],"points":[{"start":259,"end":306,"text":"21, B-4, Manu Marg, \n\nAlwar - 301001 \n\nRajasthan"}]},{"label":["Skills"],"points":[{"start":101,"end":101,"text":"C"}]},{"label":["Phone"],"points":[{"start":81,"end":91,"text":"-9983854182"}]},{"label":["Skills"],"points":[{"start":64,"end":64,"text":"C"}]},{"label":["Email"],"points":[{"start":29,"end":55,"text":"deepanjalijain148@gmail.com"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"DEEPANJALI JAIN"}]}],"extras":null,"metadata":{"first_done_at":1631182935000,"last_updated_at":1631182935000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Vishal Yadav\n\nCurrent Address: H.no. 377, Sector 12 -A, Gurgaon, Haryana\nPermanent Address: Vill Jhund Sarai, PO Patli Stn, Gurgaon Haryana\n+91-8818070543\nvishalnex8872@gmail.com\n\nProfessional Summary\n\nWith over 2 years of experience in Analytics domain I have proficiency in Data Analytics and Data Visualization. I want to contribute my competent technical, analytical and problem solving abilities to meet the organizational objectives and grow with the organization.\n\nSkills\n\nTableau, SQL Server, Advanced Excel, VBA, Project Management, Requirement Gathering.\n\nWork Experience\n\nWipro HR Services (Nov 2017 – Present)\n· Analyst\n\n· Developing analytical and visual solutions for better business understanding and perspective.\n· Consulting the stakeholders for which metrics need to be shown in the reports or dashboards for the business improvement.\n· Analyzing the complex datasets and giving required insights as per the business requirements.\n· Working closely with Stakeholders to cater their needs for the development of the reports and dashboards.\n· Giving logical and accurate solutions for the different metrics involved in the business.\n· Working on individual projects with no misses on timeliness and accuracy.\n\n\nProjects Undertaken\n--PCS Dashboard\nDashboard which shows the daily, monthly and detailed view of the active work available for the specific business or LOB and what is the current station in terms of volume, TAT and completion of the current inventory available.\n\n-- New Hire Colleague Training Tool\nIt is a tool developed for scheduling the training of the new hires in the organization.\nThe tool has different modules for New Hires, HR, Managers and Leadership.\n\n-- Colleague Performance Scorecard\nIt is a colleague Scorecard built to evaluate colleague performance on different key metrics associated with business like Client Engagement, Production, Quality, Unplanned Absenteeism etc.\nIt is a one stop shop for managers or leaders to evaluate colleagues for their performance, awards or appraisals.\n\n\n-- HPS Dashboard\nThe dashboard is built for a specific business consisting of many teams. Each team has its own module which gives them information of their inflow, pending and closed inventories. Most important is the closing TAT percentage which gives the SLA status.\n\n-- Telephone Optimization Dashboard\nThis dashboard is used for tracking the telephone usage of the whole organization. Basically it gives information about the numbers of users with access, who all are the top users and most importantly what cost is being incurred by the organization.\n\n--QMS Tool\nQuality management System. As the name suggests this tool is used to keep track of all the ongoing reports, dashboards and projects for their QC, development and deployment. It has different modules for Audits, RCA, Projects, Inventory and a dashboard for the report outs.\n--Reports Automation & Tools (Domain Assessment, Quality, Unplanned Leaves Calculator, Business Requirement Based Automations)\n\n· Skill Set\n--Tableau, SQL, Advanced Excel, Joins, Filters, Actions.\n--Live& extract connection, LOD, Table and window calculations, Report automation.\n--Generating insights/building logics of different KPI’s based on data.\n\n\nDWAO (Digital Web Analytics and Optimization) (Jan 2017 – July 2017)\n· Associate Analyst\nWorked on project of Airtel using tools like GA, GTM and for the reports MS Excel was used.\n· Skill Set\n--Advanced excels function\n--Pivot chart,Google spreadsheet\n\n\nEducation\n\nDronacharya College of Engineering\nB.Tech (2012-2016)\n\nExtra-Curricular Activities and Achievements\n\n· Kudos for saving 47 business hours in a month via automation.\n· Stress test pass of all the tableau dashboards in a single go.\n· NCC cadet certificate ‘A’\n· Won 3rd prize in Technofoltz 2013, conducted by CSI student branch DCE.\n· District Level Swimming Champion.","annotation":[{"label":["Highest degree"],"points":[{"start":3531,"end":3547,"text":"B.Tech (2012-2016"}]},{"label":["Skills"],"points":[{"start":3032,"end":3045,"text":"Advanced Excel"}]},{"label":["Skills"],"points":[{"start":3018,"end":3024,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":2603,"end":2874,"text":"Quality management System. As the name suggests this tool is used to keep track of all the ongoing reports, dashboards and projects for their QC, development and deployment. It has different modules for Audits, RCA, Projects, Inventory and a dashboard for the report outs."}]},{"label":["Total experience"],"points":[{"start":2341,"end":2588,"text":"This dashboard is used for tracking the telephone usage of the whole organization. Basically it gives information about the numbers of users with access, who all are the top users and most importantly what cost is being incurred by the organization"}]},{"label":["Total experience"],"points":[{"start":2051,"end":2301,"text":"The dashboard is built for a specific business consisting of many teams. Each team has its own module which gives them information of their inflow, pending and closed inventories. Most important is the closing TAT percentage which gives the SLA status"}]},{"label":["Total experience"],"points":[{"start":1728,"end":1915,"text":"It is a colleague Scorecard built to evaluate colleague performance on different key metrics associated with business like Client Engagement, Production, Quality, Unplanned Absenteeism etc"}]},{"label":["Total experience"],"points":[{"start":1528,"end":1689,"text":"It is a tool developed for scheduling the training of the new hires in the organization.\nThe tool has different modules for New Hires, HR, Managers and Leadership"}]},{"label":["Total experience"],"points":[{"start":1263,"end":1488,"text":"Dashboard which shows the daily, monthly and detailed view of the active work available for the specific business or LOB and what is the current station in terms of volume, TAT and completion of the current inventory available"}]},{"label":["Total experience"],"points":[{"start":951,"end":1054,"text":"Working closely with Stakeholders to cater their needs for the development of the reports and dashboards"}]},{"label":["Total experience"],"points":[{"start":635,"end":726,"text":"Developing analytical and visual solutions for better business understanding and perspective"}]},{"label":["Experience in current company"],"points":[{"start":583,"end":599,"text":"Wipro HR Services"}]},{"label":["Skills"],"points":[{"start":517,"end":519,"text":"VBA"}]},{"label":["Skills"],"points":[{"start":501,"end":514,"text":"Advanced Excel"}]},{"label":["Skills"],"points":[{"start":489,"end":498,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":480,"end":486,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":202,"end":468,"text":"With over 2 years of experience in Analytics domain I have proficiency in Data Analytics and Data Visualization. I want to contribute my competent technical, analytical and problem solving abilities to meet the organizational objectives and grow with the organization"}]},{"label":["Email"],"points":[{"start":155,"end":177,"text":"vishalnex8872@gmail.com"}]},{"label":["Phone"],"points":[{"start":144,"end":153,"text":"8818070543"}]},{"label":["Address"],"points":[{"start":31,"end":71,"text":"H.no. 377, Sector 12 -A, Gurgaon, Haryana"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Vishal Yadav"}]}],"extras":null,"metadata":{"first_done_at":1631169168000,"last_updated_at":1631169168000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "1\n\nDevratan Sharma                                                                                                            Ph:  9315509345\nEmail:  devratan.sharma@gmail.com\t\t\t\t\t\t   9711613493\n\nSUMMARY:\n\n· Over 8+ years’ of experience in Broadcasting and Telecommunication.\n· Experienced in  BASE SAS 9.4 .\n· Strong skills in SQL Server Development, SSRS, SSIS.\n· Strong skills in ORACLE PL SQL.\n· Hands on experience with Reporting  tools ( SAS Visual Analytics.)\n· Profound working knowledge of ETL tools – SSIS , SAS DI STUDIO.\n· Profound working knowledge of Data Warehousing  Concepts.\n\nTECHNICAL SKILLS:\n \nETL Tool:\t\t\t\t SSIS , SAS DI STUDIO. \nRDBMS:\tSQL Server , Oracle PL SQL.\nReporting Tools: \tSSRS , SAS VA .\nLanguages:\tBase SAS, SAS Programming ,SQL , PL/SQL.\n\n\n\nPROFESSIONAL EXPERIENCE:\n\nDish TV India Ltd.  (Noida)                                                                                          Feb’14 to till date\nAnalytics Specialist.\nResponsibilities\n\n· SAS VA to Create / publish / share / modify the dashboard, Chart, Data Query, exploration etc.\n· Prepared data using SQL, SAS for potential Churn Analysis to monitor customer’s suspension for a month.\n· Developing Data Models, Adhoc Reporting, scheduling the reports and administrating the server activities.\n· Developed SAS programs for dataset extraction, cleaning, manipulation, validation, analysis and reporting.\n· Development of SAS codes for Report generation using PROC REPORT, PROC TABULATE, PROC MEANS etc. \n· Importing and exporting Excel, CSV files using LIBNAME, PROC IMPORT, PROC EXPORT.\n· Access SQL  tables using SQL pass through facility.\n· Created ETL jobs in SSIS , SAS DI STUDIO.\n· Involved into various phase to build Data Ware House (DWH).\n· Data validation activities were performed to ensure the accuracy of the project\n· Used different SAS DI transformation to implement.\n· Worked with SQL server 2012, SQL server 2016 to fetch data from different tables, creates Views to restrict the access to certain columns by others.\n\n\nProject 1 :  SAS VA Dashboard Designing \t\t\t(July- 18 to till Date)\n\nBackground \n\nThis project shows all department wise KPI for MTD, FTD,YTD, 30 Days rolling basis and monthly basis. It covers all aspects for side by side comparison using butterfly chart and lins and time series chart and some static fields includes drop down menu.\nResponsibilities\n· Create job in SAS DI/SSIS for daily incremental data for multiple brands.\n· Prepare complete set of stored procedures where it pulls data from SAS DI/SSIS.\n· Prepare SAS dataset and manipulating it in  meaningful data which read by SAS LASR Server\n· Maintaining complete dashboard end to end functioning by using BASE SAS Email Notification.\n· Maintaining end to end users requirement/Enhancement on feedback.\n\nProject 2 :  Management Reporting \t\t\t\t(Mar- 16 to till Date)\n\nBackground \n\nThis project includes all type of departmental reporting and management reporting.\nIt includes reporting on various aspects on  department wise .  This includes many technologies like SQL SERVER ,SSIS , SSRS , BASE SAS , SAS VA, SAS DI to accomplish this goal.\nResponsibilities\n· Prepare base /raw data in SAS and Sql server.\n· Transform data using ETL tools SAS DI and SSIS.\n· Using reporting service like SAS VA and SSRS.\n\n\n\n\n\n\nProject 3 : Analytics Project\t\t\t\t\t(Mar- 19 to till Date)\n\nBackground \nThis project is based on fraud detection by service team in the field; we need to find anomaly\nand fraud analysis using Linear regression and logistic regression technique in SAS \nAnalytics.\n\nResponsibilities\n· Prepare sample and population data in SAS and SQL server.\n· Transform data using ETL tools SAS DI and SSIS.\n\n\n\nJPC Pvt. Ltd (Noida)                                                                                                    July’11 to Oct’13\nSoftware Engineer\nResponsibilities:\n· Responsible for changing the stored procedures being used in the application.\n· Coding, Unit testing and Integration of modules.\n· Creating, maintaining databases & database objects\n· Developing ad-hoc reports using SQL Server for management to decide critical business decisions that will improve the efficiency of the company.\n· Created and maintained user guides/SOPs.\n· Responsible for release Management activities.\n· Creating back up plans and jobs for the Database when required.\n\n\n\nACADEMIC QUALIFICATION:\n\n· Masters of Computer Application from M.D University, Rohtak (2011)\n· Bachelor of Computer Application from M.D University, Rohtak (2007)\n\nPERSONAL PROFILE:\n\nDate of Birth\t\t:\t \t27th July 1986\nAddress\t\t\t:\t\t99 , Shivpuri Mohalla Palwal , Haryana , 121102\n                  \n\n\nDATE: ----------\t\t\t\t\t\t\t\t\nPLACE: --------\t\t\t\t\t       \t\t\tDevratan Sharma","annotation":[{"label":["Name"],"points":[{"start":4712,"end":4726,"text":"Devratan Sharma"}]},{"label":["Grad. score"],"points":[{"start":4453,"end":4519,"text":"Bachelor of Computer Application from M.D University, Rohtak (2007)"}]},{"label":["Highest degree"],"points":[{"start":4384,"end":4448,"text":"Masters of Computer Application from M.D University, Rohtak (2011"}]},{"label":["Skills"],"points":[{"start":4083,"end":4085,"text":"SQL"}]},{"label":["Last company"],"points":[{"start":3691,"end":3710,"text":"JPC Pvt. Ltd (Noida)"}]},{"label":["Skills"],"points":[{"start":3682,"end":3685,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3671,"end":3673,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3626,"end":3628,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3618,"end":3620,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3544,"end":3546,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":3369,"end":3557,"text":"This project is based on fraud detection by service team in the field; we need to find anomaly\nand fraud analysis using Linear regression and logistic regression technique in SAS \nAnalytics"}]},{"label":["Skills"],"points":[{"start":3287,"end":3290,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":3276,"end":3278,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3239,"end":3242,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3228,"end":3230,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3175,"end":3177,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3098,"end":3100,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3090,"end":3092,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3084,"end":3086,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":3072,"end":3075,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":3065,"end":3068,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3053,"end":3055,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2952,"end":3127,"text":"It includes reporting on various aspects on  department wise .  This includes many technologies like SQL SERVER ,SSIS , SSRS , BASE SAS , SAS VA, SAS DI to accomplish this goal"}]},{"label":["Skills"],"points":[{"start":2701,"end":2703,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2615,"end":2617,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2549,"end":2551,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2533,"end":2536,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2526,"end":2528,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":2404,"end":2407,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2397,"end":2399,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":2111,"end":2362,"text":"This project shows all department wise KPI for MTD, FTD,YTD, 30 Days rolling basis and monthly basis. It covers all aspects for side by side comparison using butterfly chart and lins and time series chart and some static fields includes drop down menu."}]},{"label":["Skills"],"points":[{"start":2043,"end":2045,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1908,"end":1910,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1891,"end":1893,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":1878,"end":2025,"text":" Worked with SQL server 2012, SQL server 2016 to fetch data from different tables, creates Views to restrict the access to certain columns by others"}]},{"label":["Skills"],"points":[{"start":1841,"end":1843,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1665,"end":1667,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1658,"end":1661,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1609,"end":1611,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1591,"end":1593,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1415,"end":1417,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1301,"end":1303,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":1291,"end":1395,"text":"Developed SAS programs for dataset extraction, cleaning, manipulation, validation, analysis and reporting"}]},{"label":["Total experience"],"points":[{"start":1183,"end":1287,"text":"Developing Data Models, Adhoc Reporting, scheduling the reports and administrating the server activities."}]},{"label":["Skills"],"points":[{"start":1102,"end":1104,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":1097,"end":1099,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":1077,"end":1178,"text":"Prepared data using SQL, SAS for potential Churn Analysis to monitor customer’s suspension for a month"}]},{"label":["Total experience"],"points":[{"start":980,"end":1072,"text":"SAS VA to Create / publish / share / modify the dashboard, Chart, Data Query, exploration etc"}]},{"label":["Skills"],"points":[{"start":980,"end":982,"text":"SAS"}]},{"label":["Experience in current company"],"points":[{"start":801,"end":827,"text":"Dish TV India Ltd.  (Noida)"}]},{"label":["Skills"],"points":[{"start":767,"end":769,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":764,"end":769,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":758,"end":760,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":741,"end":743,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":736,"end":738,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":711,"end":713,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":704,"end":707,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":681,"end":683,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":678,"end":683,"text":"PL SQL"}]},{"label":["Skills"],"points":[{"start":671,"end":676,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":658,"end":660,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":635,"end":637,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":628,"end":631,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":518,"end":520,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":511,"end":514,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":444,"end":446,"text":"SAS"}]},{"label":["Skills"],"points":[{"start":393,"end":395,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":390,"end":395,"text":"PL SQL"}]},{"label":["Skills"],"points":[{"start":383,"end":388,"text":"ORACLE"}]},{"label":["Skills"],"points":[{"start":358,"end":361,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":352,"end":355,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":328,"end":330,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":299,"end":301,"text":"SAS"}]},{"label":["Total experience"],"points":[{"start":208,"end":273,"text":"Over 8+ years’ of experience in Broadcasting and Telecommunication"}]},{"label":["Phone"],"points":[{"start":184,"end":193,"text":"9711613493"}]},{"label":["Email"],"points":[{"start":150,"end":174,"text":"devratan.sharma@gmail.com"}]},{"label":["Name"],"points":[{"start":3,"end":17,"text":"Devratan Sharma"}]}],"extras":null,"metadata":{"first_done_at":1631170883000,"last_updated_at":1631170883000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "3\n\nDevratan Sharma                                                                                                            Ph:  9315509345\nEmail:  devratan.sharma@gmail.com\t\t\t\t\t\t   9711613493\n\nSUMMARY:\n\n· Over 7+ years’ of experience in Broadcasting and Telecommunication.\n· Experienced in  BASE SAS 9.4 .\n· Strong skills in SQL Server Development, SSRS, SSIS.\n· Strong skills in ORACLE PL SQL.\n· Hands on experience with Reporting  tools ( SAS Visual Analytics.)\n· Profound working knowledge of ETL tools – SSIS , SAS DI STUDIO.\n· Profound working knowledge of Data Warehousing  Concepts.\n\nTECHNICAL SKILLS:\n \nETL Tool:\t\t\t\t SSIS , SAS DI STUDIO. \nRDBMS:\tSQL Server , Oracle PL SQL.\nReporting Tools: \tSSRS , SAS VA .\nLanguages:\tBase SAS, SAS Programming ,SQL , PL/SQL.\n\n\n\nPROFESSIONAL EXPERIENCE:\n\nDish TV India Ltd.  (Noida)                                                                                          Feb’14 to till date\nAnalytics Specialist.\nResponsibilities\n\n· SAS VA to Create / publish / share / modify the dashboard, Chart, Data Query, exploration etc.\n· Prepared data using SQL, SAS for potential Churn Analysis to monitor customer’s suspension for a month.\n· Developing Data Models, Adhoc Reporting, scheduling the reports and administrating the server activities.\n· Developed SAS programs for dataset extraction, cleaning, manipulation, validation, analysis and reporting.\n· Development of SAS codes for Report generation using PROC REPORT, PROC TABULATE, PROC MEANS etc. \n· Importing and exporting Excel, CSV files using LIBNAME, PROC IMPORT, PROC EXPORT.\n· Access SQL  tables using SQL pass through facility.\n· Created ETL jobs in SSIS , SAS DI STUDIO.\n· Involved into various phase to build Data Ware House (DWH).\n· Data validation activities were performed to ensure the accuracy of the project\n· Used different SAS DI transformation to implement.\n· Worked with SQL server 2012, SQL server 2016 to fetch data from different tables, creates Views to restrict the access to certain columns by others.\n\n\nProject 1 :  SAS VA Dashboard Designing \t\t\t(July- 18 to till Date)\n\nBackground \n\nThis project shows all department wise KPI for MTD, FTD,YTD, 30 Days rolling basis and monthly basis. It covers all aspects for side by side comparison using butterfly chart and lins and time series chart and some static fields includes drop down menu.\nResponsibilities\n· Create job in SAS DI/SSIS for daily incremental data for multiple brands.\n· Prepare complete set of stored procedures where it pulls data from SAS DI/SSIS.\n· Prepare SAS dataset and manipulating it in  meaningful data which read by SAS LASR Server\n· Maintaining complete dashboard end to end functioning by using BASE SAS Email Notification.\n· Maintaining end to end users requirement/Enhancement on feedback.\n\nProject 2 :  Management Reporting \t\t\t\t(Mar- 16 to till Date)\n\nBackground \n\nThis project includes all type of departmental reporting and management reporting.\nIt includes reporting on various aspects on  department wise .  This includes many technologies like SQL SERVER ,SSIS , SSRS , BASE SAS , SAS VA, SAS DI to accomplish this goal.\nResponsibilities\n· Prepare base /raw data in SAS and Sql server.\n· Transform data using ETL tools SAS DI and SSIS.\n· Using reporting service like SAS VA and SSRS.\n\n\n\n\n\n\nProject 3 : Analytics Project\t\t\t\t\t(Mar- 19 to till Date)\n\nBackground \nThis project is based on fraud detection by service team in the field; we need to find anomaly\nand fraud analysis using Linear regression and logistic regression technique in SAS \nAnalytics.\n\nResponsibilities\n· Prepare sample and population data in SAS and SQL server.\n· Transform data using ETL tools SAS DI and SSIS.\n\n\n\nJPC Pvt. Ltd (Noida)                                                                                                    July’11 to Oct’13\nSoftware Engineer\nResponsibilities:\n· Responsible for changing the stored procedures being used in the application.\n· Coding, Unit testing and Integration of modules.\n· Creating, maintaining databases & database objects\n· Developing ad-hoc reports using SQL Server for management to decide critical business decisions that will improve the efficiency of the company.\n· Created and maintained user guides/SOPs.\n· Responsible for release Management activities.\n· Creating back up plans and jobs for the Database when required.\n\n\n\nACADEMIC QUALIFICATION:\n\n· Masters of Computer Application from M.D University, Rohtak (2011)\n· Bachelor of Computer Application from M.D University, Rohtak (2007)\n\nPERSONAL PROFILE:\n\nDate of Birth\t\t:\t \t27th July 1986\nAddress\t\t\t:\t\t99 , Shivpuri Mohalla Palwal , Haryana , 121102\n                  \n\n\nDATE: ----------\t\t\t\t\t\t\t\t\nPLACE: --------\t\t\t\t\t       \t\t\tDevratan Sharma","annotation":[{"label":["Name"],"points":[{"start":4712,"end":4726,"text":"Devratan Sharma"}]},{"label":["Skills"],"points":[{"start":4083,"end":4092,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":4083,"end":4085,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":4050,"end":4193,"text":" Developing ad-hoc reports using SQL Server for management to decide critical business decisions that will improve the efficiency of the company"}]},{"label":["Last company"],"points":[{"start":3691,"end":3710,"text":"JPC Pvt. Ltd (Noida)"}]},{"label":["Skills"],"points":[{"start":3682,"end":3685,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3626,"end":3628,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":3369,"end":3557,"text":"This project is based on fraud detection by service team in the field; we need to find anomaly\nand fraud analysis using Linear regression and logistic regression technique in SAS \nAnalytics"}]},{"label":["Skills"],"points":[{"start":3287,"end":3290,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":3239,"end":3242,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3072,"end":3075,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":3065,"end":3068,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3053,"end":3055,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2869,"end":3127,"text":"This project includes all type of departmental reporting and management reporting.\nIt includes reporting on various aspects on  department wise .  This includes many technologies like SQL SERVER ,SSIS , SSRS , BASE SAS , SAS VA, SAS DI to accomplish this goal"}]},{"label":["Skills"],"points":[{"start":2533,"end":2536,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2404,"end":2407,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":2111,"end":2379,"text":"This project shows all department wise KPI for MTD, FTD,YTD, 30 Days rolling basis and monthly basis. It covers all aspects for side by side comparison using butterfly chart and lins and time series chart and some static fields includes drop down menu.\nResponsibilities"}]},{"label":["Skills"],"points":[{"start":1908,"end":1910,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1891,"end":1893,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":1878,"end":2026,"text":" Worked with SQL server 2012, SQL server 2016 to fetch data from different tables, creates Views to restrict the access to certain columns by others."}]},{"label":["Skills"],"points":[{"start":1658,"end":1661,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1609,"end":1611,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1591,"end":1593,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":1183,"end":1286,"text":"Developing Data Models, Adhoc Reporting, scheduling the reports and administrating the server activities"}]},{"label":["Skills"],"points":[{"start":1097,"end":1099,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":979,"end":1072,"text":" SAS VA to Create / publish / share / modify the dashboard, Chart, Data Query, exploration etc"}]},{"label":["designation"],"points":[{"start":938,"end":957,"text":"Analytics Specialist"}]},{"label":["Experience in current company"],"points":[{"start":801,"end":827,"text":"Dish TV India Ltd.  (Noida)"}]},{"label":["Skills"],"points":[{"start":767,"end":769,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":764,"end":769,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":758,"end":760,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":704,"end":707,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":681,"end":683,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":678,"end":683,"text":"PL SQL"}]},{"label":["Skills"],"points":[{"start":671,"end":677,"text":"Oracle "}]},{"label":["Skills"],"points":[{"start":658,"end":667,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":658,"end":660,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":628,"end":631,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":511,"end":514,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":400,"end":463,"text":"Hands on experience with Reporting  tools ( SAS Visual Analytics"}]},{"label":["Skills"],"points":[{"start":393,"end":395,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":390,"end":395,"text":"PL SQL"}]},{"label":["Skills"],"points":[{"start":358,"end":361,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":352,"end":355,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":328,"end":337,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":328,"end":330,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":208,"end":273,"text":"Over 7+ years’ of experience in Broadcasting and Telecommunication"}]},{"label":["Phone"],"points":[{"start":184,"end":193,"text":"9711613493"}]},{"label":["Email"],"points":[{"start":150,"end":174,"text":"devratan.sharma@gmail.com"}]},{"label":["Phone"],"points":[{"start":131,"end":140,"text":"9315509345"}]},{"label":["Name"],"points":[{"start":3,"end":17,"text":"Devratan Sharma"}]}],"extras":null,"metadata":{"first_done_at":1631180294000,"last_updated_at":1631180294000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Kamini Singh\n\n· Kamini02071993@gmail.com :+91-9205128061,8077015089 |\n       : Singhkamini978@gmail.com C-96 Sector - 20 Noida, Uttar Pradesh - 201301 \n\n\n\nTo seek a challenging position in Software industry that needs innovation, creativity, dedication and enables me to continue to work in a challenging and fast paced environment and to reach Senior Management Levels.\n\n\nExperience Summary\n\n· Currently working R1RCM (Accretive Health), Noida\n· 3.8Years of experience in Data Analysis.\n· Creating simple and parameterized reports.\n· Good knowledge of performing ETL operations\n· Domain (E-commerce, Healthcare, Insurance.) \n\n\nWork Experience\n\n\nCompany   :  R1RCM, Noida\nProject        :  ETL Hub, RCM services\nDuration    :  Aug 2018 to Present\n\n\nJob description\n\n· Validated ETL functionality and performed back end testing through extensive use of SQL Queries.\n· Performed data Analysis, identified data dependencies within the source systems to create less data sets.\n· Creating and Managing and maintaining reports, Report Deployment, Schedules and subscription for Report delivery.\n· Used Excel, MS Access and SQL to extract and analyse information.\n· Created and maintained modular test scripts for iterative incremental Testing.\n· Generated QA reports using SQL Queries.\n· Working with SSIS for performing ETL operations.\n· Report Deployment, Schedules and subscription for Report delivery.\n· Experience in Query Optimization and performance tuning of stored procedures and user defines functions\n· Regular discussion with application team for review of complete work and for resolving existing issues.\n· Ensured that all documents and products were following quality Standards.\n· Managed problem tracker and resolved all issues as identified in the System\n\nWork Experience\n\nCompany:   MetLife Global Operation Support Centre Private Limited. Noida\nDuration:   March 2018 to July 2018\n\n\nJob description\n\n· Generating & maintaining day to day Data and updating the management\n· Responsible for end to end reporting.\n· Provide comparative analysis on any changes that happened during a given time period in captured data \n· Design Develop and Support various Daily, Weekly, Monthly and Quarterly Reporting Resolve commission query of advisor and agents as well.\n\n\nPrevious Work Experience\n\nCompany: Liquid Hub Analytics Pvt. Ltd.\nDuration: April 2016 to March 2018\n\nJob description\n\n· I have worked for National Purchase Diary (NPD) client.\n· Data Validation by generating the codes for sanity checks.\n· Data of Amazon, Wal-Mart, Best Buy, Office Depot, Overstock and Various Mexican outlets are analyzed.\n· Doing analysis on percentage share of sale domain wise and which domain name is most preferred for doing online shopping using various functions in Data step as well as in SQL and Excel.\n· Graphical reports representing percentage of month on month sale increase/Decrease new and refurbished products.\n· Report Generation using SQL Guide and Excel formulas.\n· Report Generation using SQL Guide, Citrix Classification Manager and Microsoft Excel.\n\nEducation Details\n\n· B.Tech (Computer Science) from NORTH INDIA ISTITUTE OF TECHNOLOGY Najibabad affiliated from UPTU in 2014.\n· Intermediate from MDKV Inter College Najibabad, U.P in 2010.\n· High School from MDKV Inter College Najibabad, U.P in 2008.\n\nTechnical Skills\n\n· QA testing, File Testing, Report Generation, Data Analysis, ETL, Quality Assurance, SQL Scripts.  \n· Strong communication skills, Working independently, resolves ongoing issues and defects, Comprehensive problem solving abilities\n\nPersonal Details\n\n· Name                    : Kamini Singh\n· Father’s Name      : Mr. Harpal Singh\n· Marital Status\t    : Single\n· Phone no               : 9205128061,8077015089\n· E-mail                   : Kamini02071993@gmail.com\n\nDeclaration\n\n I hereby declare that the above written particulars are true to the best of my knowledge and belief\nPlace: Noida\t\t\t\t\t\t\t\tKamini Singh","annotation":[{"label":["Name"],"points":[{"start":3933,"end":3944,"text":"Kamini Singh"}]},{"label":["Email"],"points":[{"start":3773,"end":3796,"text":"Kamini02071993@gmail.com"}]},{"label":["Phone"],"points":[{"start":3733,"end":3742,"text":"8077015089"}]},{"label":["Phone"],"points":[{"start":3722,"end":3731,"text":"9205128061"}]},{"label":["Name"],"points":[{"start":3612,"end":3623,"text":"Kamini Singh"}]},{"label":["Skills"],"points":[{"start":3419,"end":3421,"text":"SQL"}]},{"label":["10 %"],"points":[{"start":3254,"end":3311,"text":"High School from MDKV Inter College Najibabad, U.P in 2008"}]},{"label":["12 %"],"points":[{"start":3191,"end":3249,"text":"Intermediate from MDKV Inter College Najibabad, U.P in 2010"}]},{"label":["Highest degree"],"points":[{"start":3083,"end":3187,"text":"B.Tech (Computer Science) from NORTH INDIA ISTITUTE OF TECHNOLOGY Najibabad affiliated from UPTU in 2014."}]},{"label":["Skills"],"points":[{"start":3054,"end":3058,"text":"Excel"}]},{"label":["Skills"],"points":[{"start":2999,"end":3001,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2957,"end":2961,"text":"Excel"}]},{"label":["Skills"],"points":[{"start":2943,"end":2945,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2795,"end":2799,"text":"Excel"}]},{"label":["Skills"],"points":[{"start":2787,"end":2789,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2615,"end":2795,"text":"Doing analysis on percentage share of sale domain wise and which domain name is most preferred for doing online shopping using various functions in Data step as well as in SQL and E"}]},{"label":["Last company"],"points":[{"start":2306,"end":2334,"text":"Liquid Hub Analytics Pvt. Ltd"}]},{"label":["Experience in current company"],"points":[{"start":2026,"end":2126,"text":"Provide comparative analysis on any changes that happened during a given time period in captured data"}]},{"label":["Experience in current company"],"points":[{"start":1795,"end":1856,"text":"MetLife Global Operation Support Centre Private Limited. Noida"}]},{"label":["Skills"],"points":[{"start":1267,"end":1269,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1117,"end":1119,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1103,"end":1111,"text":"MS Access"}]},{"label":["Skills"],"points":[{"start":1096,"end":1100,"text":"Excel"}]},{"label":["Total experience"],"points":[{"start":975,"end":1087,"text":"Creating and Managing and maintaining reports, Report Deployment, Schedules and subscription for Report delivery."}]},{"label":["Total experience"],"points":[{"start":867,"end":971,"text":"Performed data Analysis, identified data dependencies within the source systems to create less data sets."}]},{"label":["Skills"],"points":[{"start":852,"end":854,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":768,"end":862,"text":"Validated ETL functionality and performed back end testing through extensive use of SQL Queries"}]},{"label":["Total experience"],"points":[{"start":155,"end":368,"text":"To seek a challenging position in Software industry that needs innovation, creativity, dedication and enables me to continue to work in a challenging and fast paced environment and to reach Senior Management Levels"}]},{"label":["Phone"],"points":[{"start":57,"end":66,"text":"8077015089"}]},{"label":["Phone"],"points":[{"start":46,"end":55,"text":"9205128061"}]},{"label":["Email"],"points":[{"start":16,"end":39,"text":"Kamini02071993@gmail.com"}]},{"label":["Name"],"points":[{"start":0,"end":11,"text":"Kamini Singh"}]}],"extras":null,"metadata":{"first_done_at":1631174991000,"last_updated_at":1631174991000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "EDUCATION\nRICHA MISHRA\nrichamisha55@gmail.com | +91 8208100353 | Bhandup (West), Mumbai-400054\n\n\n\n\n\n\n\n\n\nFather Agnel College of Engineering, Bandra, Mumbai\tMay 2013 - May 2017\nSecured a Bachelor of Engineering in Mechanics. (CGPI 7/10)\t\n\nKendriya Vidyalaya, Colaba, Mumbai\tMay 2012 - May 2013\nSecured 74% in HSC\n\nSecured 75% in SSC\tMay 2011 - May 2012\nPROFESSIONAL EXPERIENCE\nAccenture, Mumbai, India | Associate Software Engineer                                                                             July 2017-  Till Date\n· Used SSIS to create ETL package to validate , Extract, Transform and Load data to end Database.\n· Created Stored Procedures,user defined functions,indexes, Views for handling business logic\n· Involves in designing , developing and testing of the ELT strategy to populate the data from various source sysytem usimg SSIS.\n· Worked on Finance Domain as Business Intelligence Developer \n· Worked on SQL and MSBI tool.\n· Gathered information from Onshore team, converted that information into technical design\n· Performed ETL and Implemented 270 Transformation Rules\n· Created an Internal Reporting for team, ‘Policy Health Checkup’ with SSRS which helped team to check how many policies were loaded in the Policy Admin Server\n· Build Drilldown and Drillthrough reports using SSRS. Created  Parameterized reports and linked reports with thorough knowledge of reporting serving architecture(Table, chart and matrix report)\n· Trained colleagues on MSBI tools\n· Schema Update on weekly basis\n· Worked on special Complex Transformation Rules in the Project referred a BCBTU (Business Class Body Type) from scratch\n· Performed Root Cause Analysis on failures.\n· Certified in Querying-Microsoft SQL Server 2012/2014 Exam-70-461\n· Technologies used: MSBI, SSIS, SSRS, SSAS, Python, SSMS (SQL Server Management Studio)\nMachine Learning Projects\n· Multiple Linear Regression: Hotstar/Netflix: Real World Case study\n·  Logistic Regression: Case study on Telecommunication company to predict about customers who are leaving their company/Network so that they can take appropriate action to keep their customers on their platform.\n· Support Vector Machine: Email SPAM Classifier \n· K-means Clustering: Case study on Online store\n· Decision-Tree: Income Prediction based on multiple factors\n· Data-Preprocessing (Missing value treatment, Feature-Scaling, Label Encoding ) \n\n\nProgramming skills: SQL, SSIS, SSRS, SSAS, Python\n\nEXTRA CURRICULAR ACTIVITIES\n· Elected as Chairperson of NSS (National Social Service)\n· Organized College Festival Euphoria\n· Sponsorship Head and Sales Presenter of technical team (Abadha)\n\nKEY POINTS \n1. Highly motivated and passionate with a creative mind\n1. Interest and knack for technology\n1. Intellectually curious, collaborative and open to new challenges\n1. Positive attitude, attention to detail\n1. Disciplined and consistent worker\n1. Good interpersonal and communication skills","annotation":[{"label":["Total experience"],"points":[{"start":2645,"end":2696,"text":"Highly motivated and passionate with a creative mind"}]},{"label":["Skills"],"points":[{"start":2431,"end":2436,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2425,"end":2428,"text":"SSAS"}]},{"label":["Skills"],"points":[{"start":2419,"end":2422,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":2413,"end":2416,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2408,"end":2410,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1807,"end":1809,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1793,"end":1798,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1787,"end":1790,"text":"SSAS"}]},{"label":["Skills"],"points":[{"start":1781,"end":1784,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":1775,"end":1778,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":1750,"end":1861,"text":"Technologies used: MSBI, SSIS, SSRS, SSAS, Python, SSMS (SQL Server Management Studio)\nMachine Learning Projects"}]},{"label":["Skills"],"points":[{"start":1715,"end":1717,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":1517,"end":1634,"text":"Worked on special Complex Transformation Rules in the Project referred a BCBTU (Business Class Body Type) from scratch"}]},{"label":["Skills"],"points":[{"start":1302,"end":1305,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":1164,"end":1167,"text":"SSRS"}]},{"label":["Total experience"],"points":[{"start":1095,"end":1251,"text":"Created an Internal Reporting for team, ‘Policy Health Checkup’ with SSRS which helped team to check how many policies were loaded in the Policy Admin Server"}]},{"label":["Skills"],"points":[{"start":926,"end":928,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":845,"end":848,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":723,"end":848,"text":"Involves in designing , developing and testing of the ELT strategy to populate the data from various source sysytem usimg SSIS"}]},{"label":["Skills"],"points":[{"start":536,"end":539,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":531,"end":624,"text":"Used SSIS to create ETL package to validate , Extract, Transform and Load data to end Database"}]},{"label":["designation"],"points":[{"start":403,"end":429,"text":"Associate Software Engineer"}]},{"label":["Experience in current company"],"points":[{"start":376,"end":399,"text":"Accenture, Mumbai, India"}]},{"label":["10 %"],"points":[{"start":313,"end":350,"text":"Secured 75% in SSC\tMay 2011 - May 2012"}]},{"label":["12 %"],"points":[{"start":238,"end":310,"text":"Kendriya Vidyalaya, Colaba, Mumbai\tMay 2012 - May 2013\nSecured 74% in HSC"}]},{"label":["Highest degree"],"points":[{"start":104,"end":235,"text":"Father Agnel College of Engineering, Bandra, Mumbai\tMay 2013 - May 2017\nSecured a Bachelor of Engineering in Mechanics. (CGPI 7/10)\t"}]},{"label":["Phone"],"points":[{"start":52,"end":61,"text":"8208100353"}]},{"label":["Email"],"points":[{"start":23,"end":44,"text":"richamisha55@gmail.com"}]},{"label":["Name"],"points":[{"start":10,"end":21,"text":"RICHA MISHRA"}]}],"extras":null,"metadata":{"first_done_at":1631179243000,"last_updated_at":1631179243000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Shruti Goswami\nApplication Development Analyst\nA progressive and a dedicated software developer seeking to learn and grow at professional and\npersonal level hence directing the future endeavors as an asset to an organisation.\n\nshruti14.goswami@gmail.com 9899749529 Delhi, India\n\nWORK EXPERIENCE\n\n12/2019 – Present\n\nApplication Development Analyst\nAccenture\n\nProject - As.Analytics - is an Accenture Internal Project.The Project designs\nvarious metric reports for Accenture Leadership People. Accenture\nLeadership acts as a client in this project.\n\nLoading data from various sources like OLEDB, flat files to\nSQL Server database Using SSIS.\n\nCreating SSIS packages to pull data from SQL Server and\nexported to Excel Spreadsheets and vice Versa.\n\nWorking on various Business Report using macros and excel\nfeatures.\n\n01/2018 – 11/2019\n\nApplication Development Associate\nAccenture\n\nProject - As.Analytics\n\nJoined organisation as a fresher and worked on basics of\nC,SQL,SSIS,CSS,HTML and made projects for self learning.\n\nEvaluated data file submissions and developing/maintaining\nSSIS packages for ETL processes.\n\nCreated POCs on how to import data into Python: (i) from flat\nfiles such as .txts and .csvs; (ii) from files native to other\nsoftware such as Excel spreadsheets,.XLXS files; (iii) from\ndatabases such as SQL2014\n\nEDUCATION\n\n04/2013 – 05/2015\n\nBachelor of Technology\nBanasthali Vidyapith\n\n74%\n\n04/2012 – 03/2013\n\nAll India Senior School Certificate\nExamination ( Class 12)\nBal Bharati Public School\n\n90%\n\n04/2010 – 03/2011\n\nAll India Secondary School Examination(\nClass 10)\nBal Bharati Public School\n\n92%\n\nSKILLS\n\nSQL Server Integration Services (SSIS) SQL 2014\n\nC Python (Programming Language)\n\nVisual Basic for Applications (VBA, Macros\n\nMicrosoft excel ETL SQL Analyzer\n\nACHIEVEMENTS\nPython Basics Certification\nAccenture python certification programme\n\nGit Basics\nAccenture internal training\n\nInspire GEM award (03/2019)\nAccenture\n\nSuccessfully completed Accenture Green Field\nTraining Programme in Sql,C,Excel fundamentals.\n\nLANGUAGES\nEnglish\nFull Professional Proficiency\n\nHindi\nNative or Bilingual Proficiency\n\nINTERESTS\n\nMusic Skating Tennis Painting Zumba\n\nAchievements/Tasks\n\nAchievements/Tasks\n\nmailto:shruti14.goswami@gmail.com","annotation":[{"label":["Email"],"points":[{"start":2221,"end":2246,"text":"shruti14.goswami@gmail.com"}]},{"label":["Skills"],"points":[{"start":2015,"end":2015,"text":"C"}]},{"label":["Skills"],"points":[{"start":1809,"end":1809,"text":"C"}]},{"label":["Skills"],"points":[{"start":1795,"end":1800,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1783,"end":1783,"text":"C"}]},{"label":["Skills"],"points":[{"start":1735,"end":1745,"text":"VBA, Macros"}]},{"label":["Skills"],"points":[{"start":1673,"end":1678,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1671,"end":1671,"text":"C"}]},{"label":["Skills"],"points":[{"start":1572,"end":1572,"text":"C"}]},{"label":["10 %"],"points":[{"start":1532,"end":1606,"text":"All India Secondary School Examination(\nClass 10)\nBal Bharati Public School"}]},{"label":["Skills"],"points":[{"start":1471,"end":1471,"text":"C"}]},{"label":["Skills"],"points":[{"start":1445,"end":1445,"text":"C"}]},{"label":["12 %"],"points":[{"start":1421,"end":1510,"text":"All India Senior School Certificate\nExamination ( Class 12)\nBal Bharati Public School\n\n90%"}]},{"label":["Highest degree"],"points":[{"start":1352,"end":1399,"text":"Bachelor of Technology\nBanasthali Vidyapith\n\n74%"}]},{"label":["Skills"],"points":[{"start":1325,"end":1325,"text":"C"}]},{"label":["Skills"],"points":[{"start":1150,"end":1155,"text":"Python"}]},{"label":["Skills"],"points":[{"start":1120,"end":1120,"text":"C"}]},{"label":["Total experience"],"points":[{"start":1110,"end":1319,"text":"Created POCs on how to import data into Python: (i) from flat\nfiles such as .txts and .csvs; (ii) from files native to other\nsoftware such as Excel spreadsheets,.XLXS files; (iii) from\ndatabases such as SQL2014"}]},{"label":["Skills"],"points":[{"start":1110,"end":1110,"text":"C"}]},{"label":["Skills"],"points":[{"start":970,"end":970,"text":"C"}]},{"label":["Skills"],"points":[{"start":959,"end":959,"text":"C"}]},{"label":["Total experience"],"points":[{"start":902,"end":1106,"text":"Joined organisation as a fresher and worked on basics of\nC,SQL,SSIS,CSS,HTML and made projects for self learning.\n\nEvaluated data file submissions and developing/maintaining\nSSIS packages for ETL processes"}]},{"label":["Skills"],"points":[{"start":641,"end":641,"text":"C"}]},{"label":["Total experience"],"points":[{"start":548,"end":637,"text":"Loading data from various sources like OLEDB, flat files to\nSQL Server database Using SSIS"}]},{"label":["Total experience"],"points":[{"start":358,"end":544,"text":"Project - As.Analytics - is an Accenture Internal Project.The Project designs\nvarious metric reports for Accenture Leadership People. Accenture\nLeadership acts as a client in this project"}]},{"label":["designation"],"points":[{"start":315,"end":345,"text":"Application Development Analyst"}]},{"label":["Skills"],"points":[{"start":292,"end":292,"text":"C"}]},{"label":["Phone"],"points":[{"start":254,"end":263,"text":"9899749529"}]},{"label":["Email"],"points":[{"start":227,"end":252,"text":"shruti14.goswami@gmail.com"}]},{"label":["Total experience"],"points":[{"start":47,"end":223,"text":"A progressive and a dedicated software developer seeking to learn and grow at professional and\npersonal level hence directing the future endeavors as an asset to an organisation"}]},{"label":["designation"],"points":[{"start":15,"end":45,"text":"Application Development Analyst"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Shruti Goswami"}]}],"extras":null,"metadata":{"first_done_at":1631180528000,"last_updated_at":1631180528000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "CAREER OBJECTIVE \n\n \nTo obtain a position that will enable me to use my skills and ability to work well with people to improve myself \n\nas well as organizational progress. \n\n \nPROFILE SUMMARY \n\n \n➢ Total experience of 2 years 10 months in IT services \n\n➢ Having experience as Software Engineer with a demonstrated history of \n\n       working in Public sector and Postal services industry. Skilled in IBM DataStage Tool with   \n\nUnix platforms and Teradata Database.  \n\n➢ Extensively used ETL methodology for Data Extraction, Transformations and Loading  \n\n        process. \n\n➢ Designed and coded the ETL logic using DataStage to enable initial load and incremental  \n\nprocessing from Unix server and Teradata database, error strategy and data clean up,  \n\n              validation and monitoring.  \n\n➢ Conducting unit testing based on identified test scenarios and prepared unit test case  \n\ndocument. \n\n➢ Experience in designing parallel jobs using various stages like Join, Merge, Lookup, Remove \n\n➢ duplicates, Aggregator, Transformer, Sort stage in designer.  \n\n➢ Used Director for validating, running and monitoring of jobs \n\n➢ Intermediate level knowledge of UNIX shell scripting used for automation of processes and scheduling of \n\nDatastage jobs.  \n\n➢ Decent knowledge on Teradata SQL. \n\n➢ Successfully completed Green Field Training in ETL Tool Talend, IBM Cognos and Tableau. \n\n \n\nTECHNICAL/SOFTWARE SKILLS \n\n \n➢ Design and Build Management \n\n➢ Debugging/Problem Solving \n\n➢ Data Warehousing \n\n➢ Extract, Transform and Load (ETL) \n\n➢ ETL tool - IBM Datastage v11.5 \n\n➢ IBM Websphere MQ \n\n➢ UNIX Shell Scripting \n\n➢ Database – Teradata/Oracle \n\n➢ Third Party Tools: Putty, WINSCP, RFH Util \n\n \n\nPROFESSIONAL EXPERIENCE  \n\n \nOrganization : Accenture Solutions Private Ltd. \n\nDuration        : Jan 2017 – Present \n\nCurrent Role : Application Development Analyst \n\n \n Description: \n\nRoyal Mail is a postal service and courier company in the United Kingdom, originally established in 1516. The \n\ncompany's subsidiary, Royal Mail Group Limited, operates the brands Royal Mail and Parcel force \n\nWorldwide. As part of Royal Mail Group, creation of parcel ids and tracking details of parcels and using the \n\nsame in BI reports. I have worked for 3 projects under this account.  \n\n \n\nProject #1: RMG Events \nClient        : UK Royal Mail  \n\nRole              : ETL Developer \n\n              Environment : DataStage Version 11.3, Teradata Assistance Version 14.0.0.1 \nSummary: \n\nRMGTT is a legacy system used by RMG for receiving merchant pre-advice parcel details and hence \n\nderiving reports for business analysis. In order to renew the system and make it faster RMGTT is replaced by \n\nRMGTT event on ER platform which is Accenture reporting platform. This module ensure ER can replace \n\nRMGTT legacy system gracefully and produce reports on ER platform. \n\nResponsibilities: \n\n• Involved in analysing the systems and gathering of requirements with onshore team to start the \n\ndevelopment activities. \n\n  \n\n   \naditya1212anand@gmail.com \n\n              \n\n      \n House No-1786, Sector-28,Faridabad,Haryana-121008 \n\n        \n\n   Aditya   Anand   \n\n  \n\n| 91-783-849-7717 \n\n\n\n \n \n \n\n• Extensively involved in preparation of Design Documents Like LLD’s and Unit Test case documents. \n\n• Performed unit Testing activity for all the jobs in the project. \n\n• Build parallel and sequential jobs using various stages Like execute command, Job activity, User \n\nVariable Activity, Notification Activity, sequencer, Sequential File Stage, Lookup stage, Aggregator, Sort, \n\nTransformer, TD Connector, Datasets etc. \n\n• Involved in Importing & Exporting of job designs. \n\n• Giving production support of the running project and resolving the tickets logged by the user. \n\n• Given hand over KT to support team. \n\n \nProject #2: Container Event \n \n\nClient        : UK Royal Mail  \n\nRole                : ETL Developer \n\nEnvironment : Data Stage Version 11.3, Teradata Assistance Version 14.0.0.1 \n\nSummary: \nFor parcels whose destination are same are placed in a container for making it easy for transportation \n\nand faster delivery. Those type of parcel is called container events. This module makes a report of these \n\ncontainer events. \n\nResponsibilities: \n• Involved in analyzing the systems and gathering of requirements with onshore team to start the \n\ndevelopment activities. \n\n• Extensively involved in preparation of Design Documents Like LLD’s and Unit Test case documents. \n\n• Performed unit Testing activity for all the jobs in the project. \n\n• Build parallel and sequential jobs using various stages Like execute command, Job activity, User \n\nVariable Activity, Notification Activity, sequencer, Sequential File Stage, Lookup stage, Aggregator, Sort, \n\nTransformer, TD Connector, Datasets, Remove duplicates etc. \n\n• Involved in Importing & Exporting of job designs. \n\n• Involved in production deployment and Giving production support of the running project and resolving \n\nthe tickets logged by the user. \n\n• SIT, UAT and Production assistance. \n\n \n\nProject #3: Opps 2 Aggregates  \n\nClient        : UK Royal Mail  \n\nRole                : ETL Developer \n\nEnvironment : Data Stage Version 11.3, Teradata Assistance Version 14.0.0.1 \n\nSummary: \nThere were around 10 Bteq which were dependent on each other and needs to be run in one order. \n\nFirst initial load needs to be done after which rest scripts should run. For these Bteq wrapper Scripts were \n\ncreated to trigger them in order. \n\nResponsibilities: \n• Involved in analysing the system and gathering of requirements with onshore team to start the \n\ndevelopment activities. \n\n• Build Shell scripts and logic of looping which will run automatically in order. \n\n• Scheduled these wrapper scripts to run after every hour. \n\n• Monitored the run time and performance analysis of the scripts. \n\n \n\nEDUCATIONAL CREDENTIALS \n\n      \n\n          \nPERSONAL VITAE \n\n \n➢ Name                              : Aditya Anand \n\n➢ Date of birth                   : 12,April,1994 \n\n➢ Sex                                   : Male \n\n➢ Marital status                  : Single \n\n➢ Languages known         : English, Hindi. \n\n \n\nDECLARATION: \n\n \nI hereby declare that the above-mentioned information is correct up to my knowledge and I bear the \n\nresponsibility for the correctness of the above-mentioned particulars. \n\n \n\n \n\nAditya Anand \n\n \n\nDegree/ Specialization University          Year \n\nB. TECH \n\n(Electronics and communication) \n           Maharshi Dayanand University           2016 \n\nH.S.C.                            CBSE           2012 \nS.S.C.                            CBSE           2010","annotation":null,"extras":null,"metadata":{"first_done_at":1631178803000,"last_updated_at":1631178803000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Aditya Anand\n\n\tHouse No.1786, Sector28\nFaridabad, Haryana\nPin-121008\n\tEmail: aditya1212anand@gmail.com\nContact No: +91-7838497717\n\n\n\t\t                                                                                    \n\nPROFESSIONAL SUMMARY:\n\nHaving 2.8 years of experience as Software Engineer with a demonstrated history of working in Public sector and Postal services industry. Skilled in IBM DataStage Tool with Unix platforms and Teradata Database. \n\n· 2.6 years of experience in Data warehousing with IBM Web Sphere’s DataStage tool.\n· Extensively used ETL methodology for Data Extraction, Transformations and Loading process.\n· Designed and coded the ETL logic using DataStage to enable initial load and incremental processing from Unix server and Teradata database, error strategy and data clean up, validation and monitoring. \n· Good Knowledge in SQL. \n· Good Knowledge in UNIX commands.\n· Involved in managing the datasets by using orchadmin utility.\n· Conducting unit testing based on identified test scenarios and prepared unit test case document.\n· Comfortable in onsite & offshore model.\n\nTECHNICAL SKILLS: -\n\n\tOperating System\n\tWindows-10, UNIX\n\n\tDatabase\n\tTeradata\n\n\tTool Knowledge (ETL)\n\t DataStage\n\n\tThird party Tools\n\tPutty, SQL Developer, WINSCP, RFH Util\n\n\n\n\n\t\n\n\n\n\n\nQUALIFICATIONS: -\n\n\tQualification\n\tInstitute\n\tBoard\n\tYear of Passing\n\tAggregate % / CGPA\n\n\tB. TECH\n(Electronics and communication)\n\n\tManav Rachna College of Engineering (MRCE)\n\n\tMDU\n\t2016\n\t64.33%\n\n\tHIGHER SECONDARY\n\n\tDynasty International School\n\tCBSE\n\t2012\n\t79.6%\n\n\tSECONDARY\n\tDynasty International School\n\tCBSE\n\t2010\n\t9.0 CGPA\n\n\n\n\n\nWork Experience: -\n\n\tPeriod\n\tCompany\n\tCurrent-Role\n\n\t24 January,2017 to till Date\n\tAccenture Service Pvt. Ltd\n\tApplication Development Analyst\n\n\n\nDescription:\nRoyal Mail is a postal service and courier company in the United Kingdom, originally established in 1516. The company's subsidiary, Royal Mail Group Limited, operates the brands Royal Mail and Parcel force Worldwide. As part of Royal Mail Group, creation of parcel ids and tracking details of parcels and using the same in BI reports. I have worked for 3 projects under this account. \n\nProject #1: RMG Events\nClient\t\t\t:          Royal-Mail (United Kingdom).\nRole\t\t\t:          Associate Software Engineer (DataStage)\nEnvironment\t\t:          Data Stage Version 11.3, Teradata Assistance Version 14.0.0.1\n\nRMGTT is a legacy system used by RMG for receiving merchant pre-advice parcel details and hence deriving reports for business analysis. In order to renew the system and make it faster RMGTT is replaced by RMGTT event on ER platform which is Accenture reporting platform. This module ensure ER can replace RMGTT legacy system gracefully and produce reports on ER platform.\n\nResponsibilities:\n· Involved in analysing the systems and gathering of requirements with onshore team to start the development activities.\n· Extensively involved in preparation of Design Documents Like LLD’s and Unit Test case documents.\n· Performed unit Testing activity for all the jobs in the project.\n· Build parallel and sequential jobs using various stages Like execute command, Job activity, User Variable Activity, Notification Activity, sequencer, Sequential File Stage, Lookup stage, Aggregator, Sort, Transformer, TD Connector, Datasets etc.\n· Involved in Importing & Exporting of job designs.\n· Giving production support of the running project and resolving the tickets logged by the user.\n· Given hand over KT to support team.\n\n\nProject #2: Container Event\n\nClient\t\t\t:          Royal-Mail (United Kingdom)\nRole\t\t\t:          Application Development Analyst (DataStage)\nEnvironment\t\t:          Data Stage Version 11.3, Teradata Assistance Version 14.0.0.1\n\nFor parcels whose destination are same are placed in a container for making it easy for transportation and faster delivery. Those type of parcel is called container events. This module makes a report of these container events\n\nResponsibilities:\n· Involved in analyzing the systems and gathering of requirements with onshore team to start the development activities.\n· Extensively involved in preparation of Design Documents Like LLD’s and Unit Test case documents.\n· Performed unit Testing activity for all the jobs in the project.\n· Build parallel and sequential jobs using various stages Like execute command, Job activity, User Variable Activity, Notification Activity, sequencer, Sequential File Stage, Lookup stage, Aggregator, Sort, Transformer, TD Connector, Datasets, Remove duplicates etc.\n· Involved in Importing & Exporting of job designs.\n· Involved in production deployment and Giving production support of the running project and resolving the tickets logged by the user.\n· SIT, UAT and Production assistance.\n\n\nProject #3: Opps 2 Aggregates \nClient\t\t\t:          Royal-Mail (United Kingdom)\nRole\t\t\t:          Application Development Analyst (DataStage)\nEnvironment\t\t:          Data Stage Version 11.3, Teradata Assistance Version 14.0.0.1\n\nThere were around 10 Bteq which were dependent on each other and needs to be run in one order. First initial load needs to be done after which rest scripts should run. For these Bteq wrapper Scripts were created to trigger them in order.\nResponsibilities:\n· Involved in analysing the system and gathering of requirements with onshore team to start the development activities.\n· Build Shell scripts and logic of looping which will run automatically in order.\n· Scheduled these wrapper scripts to run after every hour.\n· Monitored the run time and performance analysis of the scripts.\n\n\n\nPERSONAL TRAITS: -\n\n\n· Good planning and problem-solving skills.\n· Self-belief, Self-motivation, Self-confidence and ability to grasp things quickly.\n· Consistent hard worker towards improvisation and simplification of any given task.\n· Dependable and reliable in supporting and enabling team effort to produce genuine long – term sustainable development\n· Comprehensive problem-solving abilities.\n\n\nPersonal Details: \n\n\tDate of Birth\n\t12-04-1994\n\n\tNationality\n\tIndian\n\n\tMarital Status\n\tSingle\n\n\n\nINTERESTS: -\n\nTravelling new places, trekking, Keen to learn new things.\n\n\n\nDATE:\t\t\t\t\t\t\t\t\t\t               Aditya Anand\nPLACE: Gurgaon\t\t\t\t\t\t\t                         \n1","annotation":null,"extras":null,"metadata":{"first_done_at":1631178821000,"last_updated_at":1631178821000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "CAREER OBJECTIVE \n\n \nTo obtain a position that will enable me to use my skills and ability to work well with people to improve myself \n\nas well as organizational progress. \n\n \nPROFILE SUMMARY \n\n \n➢ Total experience of 2 years 9 months in IT services \n\n➢ Having experience as Software Engineer with a demonstrated history of \n\n       working in Public sector and Postal services industry. Skilled in IBM DataStage Tool with   \n\nUnix platforms and Teradata Database.  \n\n➢ Extensively used ETL methodology for Data Extraction, Transformations and Loading  \n\n        process. \n\n➢ Designed and coded the ETL logic using DataStage to enable initial load and incremental  \n\nprocessing from Unix server and Teradata database, error strategy and data clean up,  \n\n              validation and monitoring.  \n\n➢ Conducting unit testing based on identified test scenarios and prepared unit test case  \n\ndocument. \n\n➢ Experience in designing parallel jobs using various stages like Join, Merge, Lookup, Remove \n\n➢ duplicates, Aggregator, Transformer, Sort stage in designer.  \n\n➢ Used Director for validating, running and monitoring of jobs \n\n➢ Intermediate level knowledge of UNIX shell scripting used for automation of processes and scheduling of \n\nDatastage jobs.  \n\n➢ Decent knowledge on Teradata SQL. \n\n➢ Successfully completed Green Field Training in ETL Tool Talend, IBM Cognos and Tableau. \n\n \n\nTECHNICAL/SOFTWARE SKILLS \n\n \n➢ Design and Build Management \n\n➢ Debugging/Problem Solving \n\n➢ Data Warehousing \n\n➢ Extract, Transform and Load (ETL) \n\n➢ ETL tool - IBM Datastage v11.5 \n\n➢ IBM Websphere MQ \n\n➢ UNIX Shell Scripting \n\n➢ Database – Teradata/Oracle \n\n➢ Third Party Tools: Putty, WINSCP, RFH Util \n\n \n\nPROFESSIONAL EXPERIENCE  \n\n \nOrganization : Accenture Solutions Private Ltd. \n\nDuration        : Jan 2017 – Present \n\nCurrent Role : Application Development Analyst \n\n \n Description: \n\nRoyal Mail is a postal service and courier company in the United Kingdom, originally established in 1516. The \n\ncompany's subsidiary, Royal Mail Group Limited, operates the brands Royal Mail and Parcel force \n\nWorldwide. As part of Royal Mail Group, creation of parcel ids and tracking details of parcels and using the \n\nsame in BI reports. I have worked for 3 projects under this account.  \n\n \n\nProject #1: RMG Events \nClient        : UK Royal Mail  \n\nRole              : ETL Developer \n\n              Environment : DataStage Version 11.3, Teradata Assistance Version 14.0.0.1 \nSummary: \n\nRMGTT is a legacy system used by RMG for receiving merchant pre-advice parcel details and hence \n\nderiving reports for business analysis. In order to renew the system and make it faster RMGTT is replaced by \n\nRMGTT event on ER platform which is Accenture reporting platform. This module ensure ER can replace \n\nRMGTT legacy system gracefully and produce reports on ER platform. \n\nResponsibilities: \n\n• Involved in analysing the systems and gathering of requirements with onshore team to start the \n\ndevelopment activities. \n\n  \n\n   \naditya1212anand@gmail.com \n\n              \n\n      \n House No-1786, Sector-28,Faridabad,Haryana-121008 \n\n        \n\n   Aditya   Anand   \n\n  \n\n| 91-783-849-7717 \n\n\n\n \n \n \n\n• Extensively involved in preparation of Design Documents Like LLD’s and Unit Test case documents. \n\n• Performed unit Testing activity for all the jobs in the project. \n\n• Build parallel and sequential jobs using various stages Like execute command, Job activity, User \n\nVariable Activity, Notification Activity, sequencer, Sequential File Stage, Lookup stage, Aggregator, Sort, \n\nTransformer, TD Connector, Datasets etc. \n\n• Involved in Importing & Exporting of job designs. \n\n• Giving production support of the running project and resolving the tickets logged by the user. \n\n• Given hand over KT to support team. \n\n \nProject #2: Container Event \n \n\nClient        : UK Royal Mail  \n\nRole                : ETL Developer \n\nEnvironment : Data Stage Version 11.3, Teradata Assistance Version 14.0.0.1 \n\nSummary: \nFor parcels whose destination are same are placed in a container for making it easy for transportation \n\nand faster delivery. Those type of parcel is called container events. This module makes a report of these \n\ncontainer events. \n\nResponsibilities: \n• Involved in analyzing the systems and gathering of requirements with onshore team to start the \n\ndevelopment activities. \n\n• Extensively involved in preparation of Design Documents Like LLD’s and Unit Test case documents. \n\n• Performed unit Testing activity for all the jobs in the project. \n\n• Build parallel and sequential jobs using various stages Like execute command, Job activity, User \n\nVariable Activity, Notification Activity, sequencer, Sequential File Stage, Lookup stage, Aggregator, Sort, \n\nTransformer, TD Connector, Datasets, Remove duplicates etc. \n\n• Involved in Importing & Exporting of job designs. \n\n• Involved in production deployment and Giving production support of the running project and resolving \n\nthe tickets logged by the user. \n\n• SIT, UAT and Production assistance. \n\n \n\nProject #3: Opps 2 Aggregates  \n\nClient        : UK Royal Mail  \n\nRole                : ETL Developer \n\nEnvironment : Data Stage Version 11.3, Teradata Assistance Version 14.0.0.1 \n\nSummary: \nThere were around 10 Bteq which were dependent on each other and needs to be run in one order. \n\nFirst initial load needs to be done after which rest scripts should run. For these Bteq wrapper Scripts were \n\ncreated to trigger them in order. \n\nResponsibilities: \n• Involved in analysing the system and gathering of requirements with onshore team to start the \n\ndevelopment activities. \n\n• Build Shell scripts and logic of looping which will run automatically in order. \n\n• Scheduled these wrapper scripts to run after every hour. \n\n• Monitored the run time and performance analysis of the scripts. \n\n \n\nEDUCATIONAL CREDENTIALS \n\n      \n\n          \nPERSONAL VITAE \n\n \n➢ Name                              : Aditya Anand \n\n➢ Date of birth                   : 12,April,1994 \n\n➢ Sex                                   : Male \n\n➢ Marital status                  : Single \n\n➢ Languages known         : English, Hindi. \n\n \n\nDECLARATION: \n\n \nI hereby declare that the above-mentioned information is correct up to my knowledge and I bear the \n\nresponsibility for the correctness of the above-mentioned particulars. \n\n \n\n \n\nAditya Anand \n\n \n\nDegree/ Specialization University          Year \n\nB. TECH \n\n(Electronics and communication) \n           Maharshi Dayanand University           2016 \n\nH.S.C.                            CBSE           2012 \nS.S.C.                            CBSE           2010","annotation":[{"label":["10 %"],"points":[{"start":6573,"end":6625,"text":"S.S.C.                            CBSE           2010"}]},{"label":["12 %"],"points":[{"start":6518,"end":6570,"text":"H.S.C.                            CBSE           2012"}]},{"label":["Highest degree"],"points":[{"start":6418,"end":6514,"text":"B. TECH \n\n(Electronics and communication) \n           Maharshi Dayanand University           2016"}]},{"label":["Total experience"],"points":[{"start":5503,"end":5621,"text":"Involved in analysing the system and gathering of requirements with onshore team to start the \n\ndevelopment activities."}]},{"label":["Total experience"],"points":[{"start":5238,"end":5477,"text":"There were around 10 Bteq which were dependent on each other and needs to be run in one order. \n\nFirst initial load needs to be done after which rest scripts should run. For these Bteq wrapper Scripts were \n\ncreated to trigger them in order"}]},{"label":["Total experience"],"points":[{"start":4866,"end":4998,"text":"Involved in production deployment and Giving production support of the running project and resolving \n\nthe tickets logged by the user"}]},{"label":["Total experience"],"points":[{"start":4539,"end":4808,"text":"Build parallel and sequential jobs using various stages Like execute command, Job activity, User \n\nVariable Activity, Notification Activity, sequencer, Sequential File Stage, Lookup stage, Aggregator, Sort, \n\nTransformer, TD Connector, Datasets, Remove duplicates etc. \n"}]},{"label":["Total experience"],"points":[{"start":3990,"end":4219,"text":"For parcels whose destination are same are placed in a container for making it easy for transportation \n\nand faster delivery. Those type of parcel is called container events. This module makes a report of these \n\ncontainer events."}]},{"label":["Total experience"],"points":[{"start":3660,"end":3752,"text":"Giving production support of the running project and resolving the tickets logged by the user"}]},{"label":["Total experience"],"points":[{"start":3352,"end":3599,"text":"Build parallel and sequential jobs using various stages Like execute command, Job activity, User \n\nVariable Activity, Notification Activity, sequencer, Sequential File Stage, Lookup stage, Aggregator, Sort, \n\nTransformer, TD Connector, Datasets etc"}]},{"label":["Phone"],"points":[{"start":3153,"end":3167,"text":"91-783-849-7717"}]},{"label":["Name"],"points":[{"start":3128,"end":3141,"text":"Aditya   Anand"}]},{"label":["Email"],"points":[{"start":3011,"end":3035,"text":"aditya1212anand@gmail.com"}]},{"label":["Total experience"],"points":[{"start":2478,"end":2854,"text":"RMGTT is a legacy system used by RMG for receiving merchant pre-advice parcel details and hence \n\nderiving reports for business analysis. In order to renew the system and make it faster RMGTT is replaced by \n\nRMGTT event on ER platform which is Accenture reporting platform. This module ensure ER can replace \n\nRMGTT legacy system gracefully and produce reports on ER platform."}]},{"label":["Total experience"],"points":[{"start":1888,"end":2275,"text":"Royal Mail is a postal service and courier company in the United Kingdom, originally established in 1516. The \n\ncompany's subsidiary, Royal Mail Group Limited, operates the brands Royal Mail and Parcel force \n\nWorldwide. As part of Royal Mail Group, creation of parcel ids and tracking details of parcels and using the \n\nsame in BI reports. I have worked for 3 projects under this account"}]},{"label":["designation"],"points":[{"start":1836,"end":1866,"text":"Application Development Analyst"}]},{"label":["Experience in current company"],"points":[{"start":1747,"end":1777,"text":"Accenture Solutions Private Ltd"}]},{"label":["Total experience"],"points":[{"start":576,"end":793,"text":"Designed and coded the ETL logic using DataStage to enable initial load and incremental  \n\nprocessing from Unix server and Teradata database, error strategy and data clean up,  \n\n              validation and monitoring"}]},{"label":["Total experience"],"points":[{"start":21,"end":169,"text":"To obtain a position that will enable me to use my skills and ability to work well with people to improve myself \n\nas well as organizational progress"}]}],"extras":null,"metadata":{"first_done_at":1631175338000,"last_updated_at":1631175338000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Ayushi Arya\n\n\n\n\t\n\tProfessional Summary\nExperienced Application Development Analyst with over four years of experience in information technology and services industry. Skilled in Talend Data Integration tool and Data Quality analysis. Excellent reputation for proposing innovation, resolving problems and improving customer satisfaction. Consistently rewarded for success in planning and operational improvements.\nWork History\nAccenture DDC4 - Application Development Analyst \nNoida, UP\n06/2015 – Current\n\nBritish Telecom Project (Jun'15-Jan'19)\n· One-to-one Interaction with Client and area wise experts.\n· Functional knowledge of Telecom domain.\n· Identified Data Quality Issues and performed root cause analysis.\n· Put together cleanse process documents.\n· Automated procedures in PL-SQL for deriving the Data Quality percentages. \n· Ability to write complex SQL queries to combine multiple tables for fetching and analyzing the desired data.\n· Worked effectively with cross-functional design teams to create software solutions that elevated client-side experience and significantly improved overall functionality and performance.\n· Migrated the Data Cleanse procedures from PL/SQL to Talend tool to automate the data cleanse procedures using components available in Talend DI.\n· Interfaced with Talend tool functionalities such as Performance tuning and Error Handling. \n· Used TAC (Talend Administration Center) and AMC (Activity Monitoring Console) for scheduling and monitoring of existing Talend jobs.\n· Automated reports and E2E contract cleanse process (Identification of discrepancy->Solution Proposal->Script Creation->Execution->Auto mailer) using Talend DI which in turn helped the project to gain in the Data Quality percentages and reduced costs.\n\n\n\n\nTotal SA Project (Feb'19- Current)\n· Modified existing Talend jobs to correct coding errors, upgrade interfaces and improve overall performance.\n· Prepared detailed reports daily on updates to project specifications, progress, identified conflicts and team activities.\n· Documented the field mappings and transformation flow of complicated Talend jobs using Excel processes which is being used by business/team members for reference.\n· Contributed in timely and successful Go-live of two affiliates as of now (TEP UK and TEP CANADA).\n\t\n\t\n\tayushi.2611@gmail.com\n775 599 4946\nNoida, UP 201304 \n· linkedin.com/in/ayushiarya261193\nSkills\n· Talend Data Integration Tool\n· Talend Data quality\n· Data Analysis\n· Data Profiling\n· Oracle PL/SQL programming\n· SQL Query\n· Microsoft Word\n· Microsoft Excel\n· Microsoft PowerPoint\n· C++\n· Teamwork/Collaboration\nEducation\n2015\nKalinga Institute of Industrial Technology\nBhubaneswar, Odisha\nB. Tech: Electronics and Tele-Communication Engineering \nCertification\nAutomation Prime (AI and Data Analytics) – myWizard Platform\n\n\nAwards\nAPEX award- Accenture, Aug 2017\nAPEX award- Accenture, Jan 2018\n\nInterests\nInterior Designing\nCooking\nYoga & Workout","annotation":[{"label":["Highest degree"],"points":[{"start":2693,"end":2762,"text":"B. Tech: Electronics and Tele-Communication Engineering \nCertification"}]},{"label":["Skills"],"points":[{"start":2586,"end":2588,"text":"C++"}]},{"label":["Skills"],"points":[{"start":2555,"end":2559,"text":"Excel"}]},{"label":["Phone"],"points":[{"start":2327,"end":2338,"text":"775 599 4946"}]},{"label":["Email"],"points":[{"start":2305,"end":2325,"text":"ayushi.2611@gmail.com"}]},{"label":["Total experience"],"points":[{"start":2202,"end":2296,"text":"Contributed in timely and successful Go-live of two affiliates as of now (TEP UK and TEP CANADA"}]},{"label":["Skills"],"points":[{"start":2124,"end":2128,"text":"Excel"}]},{"label":["Total experience"],"points":[{"start":2037,"end":2197,"text":"Documented the field mappings and transformation flow of complicated Talend jobs using Excel processes which is being used by business/team members for reference"}]},{"label":["Total experience"],"points":[{"start":1511,"end":1759,"text":"Automated reports and E2E contract cleanse process (Identification of discrepancy->Solution Proposal->Script Creation->Execution->Auto mailer) using Talend DI which in turn helped the project to gain in the Data Quality percentages and reduced costs"}]},{"label":["Total experience"],"points":[{"start":1135,"end":1277,"text":"Migrated the Data Cleanse procedures from PL/SQL to Talend tool to automate the data cleanse procedures using components available in Talend DI"}]},{"label":["Total experience"],"points":[{"start":946,"end":1131,"text":" Worked effectively with cross-functional design teams to create software solutions that elevated client-side experience and significantly improved overall functionality and performance."}]},{"label":["Experience in current company"],"points":[{"start":443,"end":484,"text":"Application Development Analyst \nNoida, UP"}]},{"label":["Skills"],"points":[{"start":234,"end":238,"text":"Excel"}]},{"label":["Total experience"],"points":[{"start":39,"end":424,"text":"Experienced Application Development Analyst with over four years of experience in information technology and services industry. Skilled in Talend Data Integration tool and Data Quality analysis. Excellent reputation for proposing innovation, resolving problems and improving customer satisfaction. Consistently rewarded for success in planning and operational improvements.\nWork History"}]},{"label":["Name"],"points":[{"start":0,"end":10,"text":"Ayushi Arya"}]}],"extras":null,"metadata":{"first_done_at":1631178516000,"last_updated_at":1631178516000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "(\nManisha Yadav\n: \n+91-\n9411975927\n:\n \nmanisha007.yadav@gmail.com\nCORE COMPETENCIES\nRPA (Robotic Process Implementation )\nUiPath\nAutomation Anywhere\nSSIS\nApplication Maintenance\nClient Relationship Management\nEffective communication & interpersonal skills\nExcellent analytical and organizational skill\nService Delivery\n) (\nSQL SERVER and SSIS \nProfessional \nPreferred Industry:\n \nIT\nPreferred Location: \nDelhi NCR/ \nAny location\nSeeking to pursue a challenging career in software development, Opportunities to apply, utilize & sharpen my software implementing, managing & development skills for customized solutions while contributing positively towards the organization. I can always try and adhere to the benchmark of this industry and constantly innovate to add value to the organization.\nPROFILE SUMMARY\nCompetent professional with \nThree and half year \nof experience in \ndomain like hospitality and project management applications using Microsoft technologies.\nCurrently working with \nAccenture\n Services Pvt. Ltd., Gurgaon as \nApplication Development \nSenior \nAnalyst.\nJob involves requirement gathering, enhancements, and support to the applications.\nAlso, to automate the repetitive issue to save manual effort and time.\nWork area primarily includes rectifying issues arising in the application on day to day basis, doing all the backend activities and technology.\nExpertise in writing \nT-SQL Queries\n, Dynamic-queries, sub-queries and complex joins for generating \nComplex Stored\n \nProcedures, Triggers\n, \nUser-defined Functions\n, Views and Cursors.\n) (\nPlease insert a passport size photograph\n)\nORGANIZATIONAL EXPERIENCE\n\n\nSince Dec’17 till Nov’19 with Accenture, Gurugram as Application Development Analyst\n\n1. Participated in different phases of Project like analysis, design, development, testing \nOf enterprise applications and have knowledge of end to end of Software Cycle.\n1. Create new SP, functions, triggers as per new enhancements.\n1. Created RPA structure and team along with production support, designed and developed RPA solutions to accelerate Business processes.\n1. Implemented End to End Robotic Process Automation (RPA) for 2 processes in Hospitality sector using ARP (Accenture Robotics Process). \n1. Created end to end automation solutions for clients as per requirement which involves feasibility study, designing architecture, development, testing and deployment of automation.\n\n\nSince July’16 to Dec’2017 with Accenture, Gurugram as Software Engineering Associate\n\n1. Requirement and problem analysis at the front end.\n1. Fixing operational issues faced by Hotels,\n1. Coordinating the project plan; thereby ensuring that the project plan is kept updated and the agreed milestones are adhered to,\n1. Proactive enhancement for the better functionality of the application, and\n1. Support the Full Hilton OnQ (Front Desk, Accounts, DBM, Housekeeping, Night Audit).\n1. Modify stored procedure, views, functions and triggers as per new requirements.\n\n\nACADEMIC DETAILS\n\n1. Graduate in Bachelor in Technology from Banasthali University Jaipur in 2016 with 74.82%.\n1. Sr. Secondary School Examination (Science) from CBSE in 2012.\n1. Secondary School Examination (Science) from CBSE in 2010. \n\nIT SKILLS\n\nProgramming Languages:\tC#, ASP .NET, SQL, C, C++, OOPS, Java (Core)\nDatabase:\t\t\tMS SQL Server, Oracle\nTools: \tBMC, Service now, ARP (Accenture Robotics Process), UiPath, Automation Anywhere, MS SQL Server Integration\nServices (SSIS)\nApplication Software:\t\tMSSQL 2008, 2012, Visual Studio 2010, 2012\n\n\nPERSONAL DETAILS\n\nDate of Birth:\t\t\t20th Sep 1994\nAddress:\t\t\tHouse No. 135, Gali No.2 New Meenakshipuram Amhera Road, Meerut Cantt\nStrength: \t                    \tConfidence, Positive Attitude, Committed and Disciplined\nLanguage:\t\t \tEnglish and Hindi\nNationality:                             \tIndian","annotation":[{"label":["Skills"],"points":[{"start":3724,"end":3724,"text":"C"}]},{"label":["Skills"],"points":[{"start":3693,"end":3693,"text":"C"}]},{"label":["Skills"],"points":[{"start":3655,"end":3655,"text":"C"}]},{"label":["Skills"],"points":[{"start":3488,"end":3490,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3457,"end":3460,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3424,"end":3426,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3421,"end":3426,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":3342,"end":3342,"text":"C"}]},{"label":["Skills"],"points":[{"start":3325,"end":3330,"text":"Oracle"}]},{"label":["Skills"],"points":[{"start":3313,"end":3315,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3310,"end":3315,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":3292,"end":3292,"text":"C"}]},{"label":["Skills"],"points":[{"start":3275,"end":3277,"text":"C++"}]},{"label":["Skills"],"points":[{"start":3275,"end":3275,"text":"C"}]},{"label":["Skills"],"points":[{"start":3272,"end":3272,"text":"C"}]},{"label":["Skills"],"points":[{"start":3267,"end":3269,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3257,"end":3259,"text":"ASP"}]},{"label":["Skills"],"points":[{"start":3253,"end":3254,"text":"C#"}]},{"label":["Skills"],"points":[{"start":3253,"end":3253,"text":"C"}]},{"label":["Skills"],"points":[{"start":3203,"end":3203,"text":"C"}]},{"label":["10 %"],"points":[{"start":3159,"end":3215,"text":"Secondary School Examination (Science) from CBSE in 2010."}]},{"label":["Skills"],"points":[{"start":3142,"end":3142,"text":"C"}]},{"label":["12 %"],"points":[{"start":3094,"end":3154,"text":"Sr. Secondary School Examination (Science) from CBSE in 2012."}]},{"label":["Highest degree"],"points":[{"start":3001,"end":3088,"text":"Graduate in Bachelor in Technology from Banasthali University Jaipur in 2016 with 74.82%"}]},{"label":["Skills"],"points":[{"start":2987,"end":2987,"text":"C"}]},{"label":["Skills"],"points":[{"start":2981,"end":2981,"text":"C"}]},{"label":["Skills"],"points":[{"start":2602,"end":2602,"text":"C"}]},{"label":["Total experience"],"points":[{"start":2231,"end":2409,"text":"Created end to end automation solutions for clients as per requirement which involves feasibility study, designing architecture, development, testing and deployment of automation."}]},{"label":["Skills"],"points":[{"start":2231,"end":2231,"text":"C"}]},{"label":["Skills"],"points":[{"start":1957,"end":1957,"text":"C"}]},{"label":["Skills"],"points":[{"start":1894,"end":1894,"text":"C"}]},{"label":["Skills"],"points":[{"start":1884,"end":1884,"text":"C"}]},{"label":["Total experience"],"points":[{"start":1723,"end":1888,"text":"Participated in different phases of Project like analysis, design, development, testing \nOf enterprise applications and have knowledge of end to end of Software Cycle"}]},{"label":["designation"],"points":[{"start":1687,"end":1709,"text":"Application Development"}]},{"label":["Skills"],"points":[{"start":1629,"end":1629,"text":"C"}]},{"label":["Skills"],"points":[{"start":1550,"end":1550,"text":"C"}]},{"label":["Skills"],"points":[{"start":1474,"end":1474,"text":"C"}]},{"label":["Skills"],"points":[{"start":1397,"end":1399,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1395,"end":1399,"text":"T-SQL"}]},{"label":["Total experience"],"points":[{"start":1075,"end":1370,"text":"Job involves requirement gathering, enhancements, and support to the applications.\nAlso, to automate the repetitive issue to save manual effort and time.\nWork area primarily includes rectifying issues arising in the application on day to day basis, doing all the backend activities and technology"}]},{"label":["designation"],"points":[{"start":1033,"end":1055,"text":"Application Development"}]},{"label":["Experience in current company"],"points":[{"start":1001,"end":1027,"text":"Services Pvt. Ltd., Gurgaon"}]},{"label":["Skills"],"points":[{"start":966,"end":966,"text":"C"}]},{"label":["Total experience"],"points":[{"start":876,"end":987,"text":"domain like hospitality and project management applications using Microsoft technologies.\nCurrently working with"}]},{"label":["Skills"],"points":[{"start":808,"end":808,"text":"C"}]},{"label":["Total experience"],"points":[{"start":429,"end":789,"text":"Seeking to pursue a challenging career in software development, Opportunities to apply, utilize & sharpen my software implementing, managing & development skills for customized solutions while contributing positively towards the organization. I can always try and adhere to the benchmark of this industry and constantly innovate to add value to the organization"}]},{"label":["Skills"],"points":[{"start":411,"end":411,"text":"C"}]},{"label":["Skills"],"points":[{"start":338,"end":341,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":323,"end":325,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":178,"end":178,"text":"C"}]},{"label":["Total experience"],"points":[{"start":154,"end":317,"text":"Application Maintenance\nClient Relationship Management\nEffective communication & interpersonal skills\nExcellent analytical and organizational skill\nService Delivery"}]},{"label":["Skills"],"points":[{"start":149,"end":152,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":84,"end":127,"text":"RPA (Robotic Process Implementation )\nUiPath"}]},{"label":["Skills"],"points":[{"start":79,"end":79,"text":"C"}]},{"label":["Skills"],"points":[{"start":71,"end":71,"text":"C"}]},{"label":["Skills"],"points":[{"start":66,"end":66,"text":"C"}]},{"label":["Email"],"points":[{"start":39,"end":64,"text":"manisha007.yadav@gmail.com"}]},{"label":["Phone"],"points":[{"start":24,"end":33,"text":"9411975927"}]},{"label":["Name"],"points":[{"start":2,"end":14,"text":"Manisha Yadav"}]}],"extras":null,"metadata":{"first_done_at":1631179546000,"last_updated_at":1631179546000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Narender Kumar                             \n\n               Manufacturing Processes and Automation Engineering        \n\n               Netaji Subhas Institute of Technology, New Delhi             \n\n                 knarender239@yahoo.com,  +91-9555314113                         \n\n \nDegree          University                           Institute                Year                   %                   CGPA            \nB.E.          University of Delhi      NSIT                2018                   62.5%                7   \n\nPROFESSIONAL EXPERIENCE \nAavas Financiers Ltd. Jaipur | Asst. Manager – IT                  (since Oct. 2018) \n\n• Working in Data Warehouse Team. Works on ETL Tool mainly for reporting purpose for \nanalysis of historical data. \n\n• Reduces Manual MIS Work by 90 % of various departments by automating it. \n\n                                                                       INTERNSHIPS \nMinda Kosei Aluminium Wheel Pvt. Ltd., Haryana | Production Department          (June 2016-July 2016)  \n\n• Got overview of the plant and process flow of all processes from production line to paint line. \n\nKalpana Industries Ltd., Rajasthan | Production Department                                   (June 2017-July 2017) \n\n• Learn whole process flow from moulding LV coil to testing of the manufactured Transformer. \n\nPROJECTS \n\n         Major              Low Cost Lathe Tool Dynamometer | Asst. Prof. Dr. Andriya Narsimhulu \n• Used two-octagonal orthogonal stainless steel rings as sensing element and 8, 350 \n\nohm strain gauges to measure deflection on the sensing element while performing \nturning operation on Lathe. Cost is decreased by 75% as compared to market. \n\n        Minor               Bluetooth Controlled | Asso. Prof. Dr. Vijyant Agarwal \n• Bluetooth Module HC-05 acts as receiver and android phone transmits signals. \n• Motor driver L293D used for connection of two motors with Arduino \n\n                                 Temperature Controller | Asst. Prof. Jyoti Yadav \n• Temperature sensor LM-35 acts as a controller. Set it at 35℃, as temperature goes \n\nbeyond it, the buzzer beeps, as a part of Transducer lab \n\nPOSITION OF RESPONSIBILITY \nAsst. Manager – IT                                                                                                               (since Oct. 2018) \n\n- Equally contribute (2 members in my team) in MIS automation across various departments. \nBH-3 Mess Secretary                   (Aug 17- May 18) \n\n- Gathered online and offline feedback, suggestions on menu through email and what’s app group of \n250 students for better food quality. \n\nEXTRA CURRICULAR ACTIVITIES \n        Skills                HQL, MySQL, R, Data Mining, Data Visualisation, MS Excel, Digital Marketing \n\n        Softwares         Hadoop(Sprinkle), R, MySQL, Weka, iNZight, MS Office Suit \n\n- Consistently awarded academic scholarship in School, also got scholarship under RMDF scheme. \n- Keen in Analytics, Research, Stock Market, Gyming and General Knowledge \n- Actively participate in Sports, Van-Mahotsav, Swachh Bharat Campaign in College","annotation":[{"label":["Total experience"],"points":[{"start":1448,"end":1686,"text":"Used two-octagonal orthogonal stainless steel rings as sensing element and 8, 350 \n\nohm strain gauges to measure deflection on the sensing element while performing \nturning operation on Lathe. Cost is decreased by 75% as compared to market"}]},{"label":["Experience in current company"],"points":[{"start":920,"end":965,"text":"Minda Kosei Aluminium Wheel Pvt. Ltd., Haryana"}]},{"label":["Total experience"],"points":[{"start":644,"end":754,"text":"Working in Data Warehouse Team. Works on ETL Tool mainly for reporting purpose for \nanalysis of historical data"}]},{"label":["Highest degree"],"points":[{"start":421,"end":524,"text":"B.E.          University of Delhi      NSIT                2018                   62.5%                7"}]},{"label":["Phone"],"points":[{"start":244,"end":253,"text":"9555314113"}]},{"label":["Email"],"points":[{"start":215,"end":236,"text":"knarender239@yahoo.com"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Narender Kumar"}]}],"extras":null,"metadata":{"first_done_at":1631183268000,"last_updated_at":1631183268000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Swechchha Singh Gangwar E-mail:singhswechchha34@gmail.com \nMSBI  and Power BI Developer Mumbai, India | \n\nPhone (Personal): 9452764910 \n \n \n\n \nCAREER OBJECTIVE: \n\n----------------------------------------------------- \nI would like to use my skills and knowledge in a position where I can innovate & create, learn further and be a \n\nbetter professional as well as a better person. I would like to contribute to this world by preventing the day \n\nto day problems with the ease of technology through my work and adroit personality. \n\n \n\nPROFESSIONAL SUMMARY: \n\n----------------------------------------------------- \n\nA dynamic professional with 1.3 years of experience with TATA Consultancy Services. \n\n \n• Experienced in delivering high quality visualization and converting data into meaningful information. \n• Experienced in Data modelling for small demos. \n• Expertise in Power BI, data visualization and implementation. \n• Experienced in SQL with strong problem-solving and debugging skills to find root cause and solution. \n• Experienced in Data Warehouse concepts. \n• Involved in troubleshooting, resolving and escalating data related issues to improve data quality. \n• Knowledge of performance tuning and Query Optimization. \n• Experienced in importing/exporting data between different sources using SSIS. \n• Enthusiastic team player with good communication skills. \n\n \n\nTECHNICAL SKILL: \n\n----------------------------------------------------- \n\n \n\nTechnology Power BI,SSIS,MS SQL SERVER,JAVA,HTML,CSS \n\nRole MSBI Developer \n\nDatabase Azure SQL Database \n\nLanguage SQL, DAX \n\nOperating System Windows Family \n\nMethodologies Agile, Waterfall \n\nDomain Experience Supply Chain \n\n\n\n \n\nPROJECT: \n----------------------------------------------------- \n\n \nOrganization: TATA Consultancy Services Limited \n\nProject Client: Procter and Gamble \n\nRegion: India \n\nDuration: Oct, 2018 – Current \n\nRole: MSBI and Power BI Developer \n\n \nClient Description: \nP&G is one of the largest and among the fastest growing consumer goods companies in India. \n\nIts presence pans across the Beauty & Grooming segment, the Household Care segment as well as the \n\nHealth & Well Being segment, with trusted brands that are household names across India. \n\n \nDevelopment Activities: \n\n \n• To analyse the requirements and get the outstanding queries clarified by interacting with concerned \n\nteams to develop customize reports. \n\n• Designing and developing dashboard in Power BI using DAX. \n\n \n\n• To implement complex reports (Tabular, Matrix, Drill Down, Drill through) using Power Bi Desktop. To \n\ngenerate computed table, complex measure and custom columns in Power BI using DAX. \n\n• Creating fact and dimension tables. \n\n• Creating and scheduling SSIS jobs and Power BI reports. \n\n• Integrated custom visual based on business requirements using Power Bi Desktop. \n\n• Development of complex SQL queries using stored procedures, CTE, temporary table to support Power BI \n\nand SSRS report. \n\n• Creating packages to extract data from various source. Implementing various CR depending on the \n\ncustomer requirements. \n\n• Contributed in the development of knowledge transfer documentation. \n\n \nSupport Activities: \n\n \n• Provided continued maintenance and development of bug fixes for existing and new Power BI reports. \n\n• Monitoring SSIS, SQL and Power Bi jobs. \n\n• As per requirements rendering reports and back end data in the form of excel and .csv format using \nSQL queries \n \n\n \n\n \nACHIEVEMENTS: \n\n------------------------------------------------------ \n \n\n• Developed around 30 dashboards for PepsiCo demo in just 2 weeks and corresponding database design \nand working on many POCs along with the current engagement. \n\n• Selected for internship of 6 months from IIT Kanpur. \n\n\n\n \n\nSCHOLASTIC RECORDS: \n\n------------------------------------------------------ \n \n\n \n\nEDUCATION \n\n \n\nINSTITUTE \n\n \nYEAR OF \nPASSING \n\n \nPERCENT- \nAGE/CGPA \n\nMCA Maulana Azad National \nInstitute Of Techonology \n\nBhopal \n\n \n2018 \n\n \n8.7 \n\nBCA Dr.Virendra Swarup Institute \nOf Computer Studies \n\n2015 77% \n\n \n\nIntermediate \nShivaji Inter College  \n\n2012 \n\n \n\n83% \n \n\nSSC Subhash Girls Inter College \n \n\n2010 \n \n\n81 \n\n \nPERSONAL PROFILE: \n------------------------------------------------------ \n\nDate of Birth: 10th January, 1996 \n\nGender: Female \n\nMarital Status: Single \n\nNationality: Indian \n\nLanguages Known: English and Hindi \n\n \nINTERESTS: \n\n------------------------------------------------------ \n\n• Cooking \n\n \n\n \n \n\nPlace: Mumbai, India                                                                                                          Swechchha Singh Gangwar","annotation":[{"label":["Name"],"points":[{"start":4603,"end":4617,"text":"Swechchha Singh"}]},{"label":["10 %"],"points":[{"start":4120,"end":4167,"text":"SSC Subhash Girls Inter College \n \n\n2010 \n \n\n81 "}]},{"label":["12 %"],"points":[{"start":4063,"end":4115,"text":"Intermediate \nShivaji Inter College  \n\n2012 \n\n \n\n83% "}]},{"label":["Grad. score"],"points":[{"start":3993,"end":4056,"text":"BCA Dr.Virendra Swarup Institute \nOf Computer Studies \n\n2015 77%"}]},{"label":["Highest degree"],"points":[{"start":3913,"end":3990,"text":"MCA Maulana Azad National \nInstitute Of Techonology \n\nBhopal \n\n \n2018 \n\n \n8.7 "}]},{"label":["Total experience"],"points":[{"start":3535,"end":3691,"text":"Developed around 30 dashboards for PepsiCo demo in just 2 weeks and corresponding database design \nand working on many POCs along with the current engagement"}]},{"label":["Skills"],"points":[{"start":3437,"end":3439,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3310,"end":3312,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3304,"end":3307,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":3271,"end":3278,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2935,"end":2942,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2866,"end":2868,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2737,"end":2744,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2723,"end":2726,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2650,"end":2652,"text":"DAX"}]},{"label":["Skills"],"points":[{"start":2635,"end":2642,"text":"Power BI"}]},{"label":["Total experience"],"points":[{"start":2469,"end":2653,"text":"To implement complex reports (Tabular, Matrix, Drill Down, Drill through) using Power Bi Desktop. To \n\ngenerate computed table, complex measure and custom columns in Power BI using DAX."}]},{"label":["Skills"],"points":[{"start":2457,"end":2459,"text":"DAX"}]},{"label":["Skills"],"points":[{"start":2442,"end":2449,"text":"Power BI"}]},{"label":["Total experience"],"points":[{"start":1947,"end":2226,"text":"P&G is one of the largest and among the fastest growing consumer goods companies in India. \n\nIts presence pans across the Beauty & Grooming segment, the Household Care segment as well as the \n\nHealth & Well Being segment, with trusted brands that are household names across India."}]},{"label":["Skills"],"points":[{"start":1903,"end":1910,"text":"Power BI"}]},{"label":["Experience in current company"],"points":[{"start":1767,"end":1791,"text":"TATA Consultancy Services"}]},{"label":["Skills"],"points":[{"start":1574,"end":1576,"text":"DAX"}]},{"label":["Skills"],"points":[{"start":1569,"end":1571,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1545,"end":1547,"text":"SQL"}]},{"label":["designation"],"points":[{"start":1513,"end":1526,"text":"MSBI Developer"}]},{"label":["Skills"],"points":[{"start":1502,"end":1504,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":1497,"end":1500,"text":"HTML"}]},{"label":["Skills"],"points":[{"start":1492,"end":1495,"text":"JAVA"}]},{"label":["Skills"],"points":[{"start":1481,"end":1483,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1478,"end":1483,"text":"MS SQL"}]},{"label":["Skills"],"points":[{"start":1473,"end":1476,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1464,"end":1471,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":1304,"end":1307,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":1071,"end":1167,"text":"Involved in troubleshooting, resolving and escalating data related issues to improve data quality"}]},{"label":["Skills"],"points":[{"start":939,"end":941,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":924,"end":1022,"text":"Experienced in SQL with strong problem-solving and debugging skills to find root cause and solution"}]},{"label":["Skills"],"points":[{"start":872,"end":879,"text":"Power BI"}]},{"label":["Total experience"],"points":[{"start":809,"end":854,"text":"Experienced in Data modelling for small demos."}]},{"label":["Total experience"],"points":[{"start":704,"end":803,"text":"Experienced in delivering high quality visualization and converting data into meaningful information"}]},{"label":["Experience in current company"],"points":[{"start":671,"end":695,"text":"TATA Consultancy Services"}]},{"label":["Total experience"],"points":[{"start":218,"end":528,"text":"I would like to use my skills and knowledge in a position where I can innovate & create, learn further and be a \n\nbetter professional as well as a better person. I would like to contribute to this world by preventing the day \n\nto day problems with the ease of technology through my work and adroit personality. "}]},{"label":["Phone"],"points":[{"start":124,"end":133,"text":"9452764910"}]},{"label":["Skills"],"points":[{"start":69,"end":76,"text":"Power BI"}]},{"label":["designation"],"points":[{"start":59,"end":86,"text":"MSBI  and Power BI Developer"}]},{"label":["Email"],"points":[{"start":31,"end":56,"text":"singhswechchha34@gmail.com"}]},{"label":["Name"],"points":[{"start":0,"end":14,"text":"Swechchha Singh"}]}],"extras":null,"metadata":{"first_done_at":1631169849000,"last_updated_at":1631169849000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "KRUTIKA DESHPANDE\n\n\t\n\tFemale, Indian, 24 Years, English, Hindi\nContact No: 9560702955\nEmail Id: krutika.desh94@gmail.com\n\n\n\nTitle:\n\nSoftware Developer \n\nPrimary Skills: \n\nETL, T-Sql, Tableau\n\nSecondary Skills:\n\nDATABASE\t          : SQL Server \nETL Tool\t          : INFORMATICA  \nReporting Tool\t: Crystal Report \nTechnology\t\t: Data warehouse \nData Visualization\t: Tableau\nVersion Control Tool\t: Git\n\nCurrent Working Location: \n\nGurgaon (INDIA).\n \nExperience Summary: \n\n1. ETL Developer – Sunlife Financials Gurgaon, from July 2016 to present \n2. Worked as intern in WOXA technologies for 6 months\n\nEducation: \n\n\tYear\n\tQualification\n\tInstitution\n\tBoard / University\n\tSpecialization\n\t%\n\n\t2016\n\tB.Tech\n\tManav Rachna College of Engineering, Faridabad\n\tMDU,Rohtak\n\tComputer Science\n\t72.4\n\n\t2012\n\tHSC\n\tHoly Child School, Faridabad\n\tCBSE\n\tMathematics, Science\n\t83.8\n\n\t2010\n\tSSC\n\tHoly Child School, Faridabad\n\tCBSE\n\tMathematics, Science\n\t89.3\n\n\n\nWork Experience: \nTechnical Skills \nTSQL \n· Strong SQL Server Fundamentals and T-SQL Skills (SQL Server 2014)\n\n\n· Proficiency in writing complex stored procedures, Joins, Function etc to support data integration, analysis, and various business processes. \n· Proficiency in writing dynamic SQL query \n· Knowledge about index. \n· Conduct peer-review on existing stored procedures/functions and perform optimization. \n\nETL \n· Designed effective packages for daily Extraction, Transformation and Loading data from heterogeneous sources like Flat files, excel, XML and SQL server database. \n· Transformed and staging data to Data Mart. \n· Implemented Join (Normal and Master),Router ,Expression ,Union, Pre Source SQL , Post Target Load SQL in INFORMATICA \n· Created Meta data around ETL processing for monitoring and troubleshooting processing steps. \n· Experience implementing slowly change dimension Type 2 and Type 3. \n· Experience in building Package deployment and package Configuration. \n· experienced in Agile Development process for diverse requirements \n\n\nProject Details: \n\nProject: Statement (CRM and E-Delivery) \nEnvironment: SQL Server 2008/2012 and INFORMATICA \nDescription: Sun life Financials \nDealer business needed to make a number of changes in order to address the compliance requirements identified in the CSA National Instrument 31-103.Annual Dealer Statements, as well as to quarterly Dealer Statements were to be produced. Earlier Dealer Statements were currently extracted, formatted and printed in house by SLF. The Dealer Statements contained a number of minor deficiencies that were to be addressed in order to improve the statement content and generation process. SLF was to deliver redesigned, MFDA compliant Dealer Statements to clients every three months, using XML extracted from Univeris. Beginning with the 2016 annual Dealer Statement, SLF also needed to provide an \"Account charges and compensation\" section as well as an \"Account investment performance\" section \nThe main activities carried out are: \n1. Analysis of the requirements, Design the HLD \n2. Informatica Packages and SQL Codes \n\nProject: FACTCA Reporting \nEnvironment: SQL Server 2008/2012 and CRYSTAL Reports \nDescription: To align with the Common Reporting Standards (CRS) regulatory changes taking effect July 1st 2017, Univeris was updating the Enterprise Wealth Management System (EWMS) with new screens, fields and functionality. This functionality aims to increase the ability for the platform to collect data related to foreign clients with reportable accounts. Due to this, Sun Life Financial Investment Services Incorporated (SLFISI) had to undertake several enhancements in order to ensure a seamless transition onto the updated platform. \nThe main activities carried out are: \n1. Analysis of the requirements \n2. Crystal Report Development \n\nProject: Mutual fund recommendation with market and historic analysis \nEnvironment: Tableau\nDescription : Architect, designer and developer, Python, Machine Learning, Sentiment Analysis · We have used machine learning to recommend funds based on client profile and provide a dash board which would give analysis about the recommended funds based on sentiment analysis of the news feeds and \nhistoric performance of the same \nThe main activities carried out are: \n1. Understanding Machine Learning and its utilities in Financial Domain \n2. Building a recommender system for mutual Funds and sentiment analysis of the recommended funds \n3. Displaying data into Tableau as dashboard \n\nPersonal Information: \nAddress: House No: 835, Sector 28, Faridabad \nDate of Birth: 20-Mar-1994 \nSex: FEMALE \n\nPlace: Faridabad                                                                                                                                   Signature\nKrutika Deshpande","annotation":[{"label":["Skills"],"points":[{"start":4444,"end":4451,"text":" Tableau"}]},{"label":["Total experience"],"points":[{"start":3879,"end":4175,"text":"escription : Architect, designer and developer, Python, Machine Learning, Sentiment Analysis · We have used machine learning to recommend funds based on client profile and provide a dash board which would give analysis about the recommended funds based on sentiment analysis of the news feeds and "}]},{"label":["Skills"],"points":[{"start":3869,"end":3876,"text":" Tableau"}]},{"label":["Skills"],"points":[{"start":3101,"end":3110,"text":"SQL Server"}]},{"label":["Total experience"],"points":[{"start":3088,"end":3717,"text":"Environment: SQL Server 2008/2012 and CRYSTAL Reports \nDescription: To align with the Common Reporting Standards (CRS) regulatory changes taking effect July 1st 2017, Univeris was updating the Enterprise Wealth Management System (EWMS) with new screens, fields and functionality. This functionality aims to increase the ability for the platform to collect data related to foreign clients with reportable accounts. Due to this, Sun Life Financial Investment Services Incorporated (SLFISI) had to undertake several enhancements in order to ensure a seamless transition onto the updated platform. \nThe main activities carried out are"}]},{"label":["Total experience"],"points":[{"start":2143,"end":2969,"text":"Dealer business needed to make a number of changes in order to address the compliance requirements identified in the CSA National Instrument 31-103.Annual Dealer Statements, as well as to quarterly Dealer Statements were to be produced. Earlier Dealer Statements were currently extracted, formatted and printed in house by SLF. The Dealer Statements contained a number of minor deficiencies that were to be addressed in order to improve the statement content and generation process. SLF was to deliver redesigned, MFDA compliant Dealer Statements to clients every three months, using XML extracted from Univeris. Beginning with the 2016 annual Dealer Statement, SLF also needed to provide an \"Account charges and compensation\" section as well as an \"Account investment performance\" section \nThe main activities carried out are:"}]},{"label":["Skills"],"points":[{"start":2071,"end":2080,"text":"SQL Server"}]},{"label":["Total experience"],"points":[{"start":1571,"end":1686,"text":"Implemented Join (Normal and Master),Router ,Expression ,Union, Pre Source SQL , Post Target Load SQL in INFORMATICA"}]},{"label":["Total experience"],"points":[{"start":1360,"end":1519,"text":"Designed effective packages for daily Extraction, Transformation and Loading data from heterogeneous sources like Flat files, excel, XML and SQL server database"}]},{"label":["Total experience"],"points":[{"start":1265,"end":1348,"text":"Conduct peer-review on existing stored procedures/functions and perform optimization"}]},{"label":["Total experience"],"points":[{"start":1051,"end":1189,"text":"Proficiency in writing complex stored procedures, Joins, Function etc to support data integration, analysis, and various business processes"}]},{"label":["Skills"],"points":[{"start":1030,"end":1039,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":988,"end":997,"text":"SQL Server"}]},{"label":["10 %"],"points":[{"start":866,"end":932,"text":"SSC\n\tHoly Child School, Faridabad\n\tCBSE\n\tMathematics, Science\n\t89.3"}]},{"label":["12 %"],"points":[{"start":790,"end":856,"text":"HSC\n\tHoly Child School, Faridabad\n\tCBSE\n\tMathematics, Science\n\t83.8"}]},{"label":["Highest degree"],"points":[{"start":691,"end":780,"text":"B.Tech\n\tManav Rachna College of Engineering, Faridabad\n\tMDU,Rohtak\n\tComputer Science\n\t72.4"}]},{"label":["Experience in current company"],"points":[{"start":487,"end":512,"text":"Sunlife Financials Gurgaon"}]},{"label":["designation"],"points":[{"start":471,"end":483,"text":"ETL Developer"}]},{"label":["Skills"],"points":[{"start":362,"end":369,"text":" Tableau"}]},{"label":["Skills"],"points":[{"start":232,"end":241,"text":"SQL Server"}]},{"label":["Skills"],"points":[{"start":182,"end":189,"text":" Tableau"}]},{"label":["Skills"],"points":[{"start":176,"end":180,"text":"T-Sql"}]},{"label":["Email"],"points":[{"start":96,"end":119,"text":"krutika.desh94@gmail.com"}]},{"label":["Phone"],"points":[{"start":75,"end":84,"text":"9560702955"}]},{"label":["Name"],"points":[{"start":0,"end":16,"text":"KRUTIKA DESHPANDE"}]}],"extras":null,"metadata":{"first_done_at":1631179045000,"last_updated_at":1631179045000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Address: A.-03, Kingfisher Residency,   \n\n                Sector-2A UIT, Bhiwadi,  \n\n                Rajasthan-301019 \n\n \n  Mob: 8287833947  \nEmail: thakurabhishek09@gmail.com \n\n \n \n\n \n\nSkills: \n \n\n Machine Learning  \n Tableau \n\n ETL  \n\n Data Validation & Cleansing \n\n Software Development Life \nCycle  \n\n Well experienced with \nProgramming and Software \nTools like SQL, Oracle 9i, \nSybase, MS Access, Excel. \n\n \n\n    Achievements: \n Multiple appreciations by \n\nteam for excellent client \n\ndelivery \n\n Won award for individual \ncontribution \n\n \n\n     \n\n      Key Skills and   \n\n    Competencies: \n Remarkable analytical and \n\nlogical skills. \n\n Ability to establish priorities \nand work under limited \n\nsupervision. \n\n Can communicate information \nand ideas to others in an \n\nunderstandable manner. \n\n \n\n    Extra-Curricular     \n\n    Activity: \n \n\n Actively participating in \nactivities of NGO \n\n Part of college TECHNO-\n\nCULTURAL FEST \n\nOrganizing committee. \n\n Participated in various events \n\nlike quiz, debate. \n\n \n\n \n\nAbhishek Pratap Singh a Certified Data \nScientist who has 1+ year record of exceeding set targets.  \nHighly developed skills in problem identification and implementation of effective \n\nsolutions. Comfortable with analyzing and understanding data, working under \n\ntime pressure and presenting myself in a professional manner. Excellent inter-\n\npersonal communication and social skills. A friendly, mature and flexible \n\nindividual with a proven entrepreneurial approach towards objectives and tasks. \n \n\nDUTIES: \n\n Executing data mining, information extraction and classification upon \nstructured & un-structured data using Python \n\n Creation of models using the concept of machine learning. \n\n Defect Handling- Resolve production issue(s) and changes order by \nmodifying backend code when required. \n\n Responsible for Unit (Unit Test plan) & Regression testing. Test/debugging \nJobs to assure that there should be no negative effect of changes made in the \n\nsystem. \n\n Verification and Validation- responsible for expected result creation and \nvalidating and verifying the result \n\n Good Knowledge of Tableau as well. \n\n Training /mentoring of new hires associates for understanding process based \nrequirements & building mapping logics. Also, Quality peer review of work \nbefore deploying. \n\n \n\nPROJECTS: \n\n Pattern Recognition- \n       Role Description: Using concept of machine learning made a model with   \n       89%  accuracy which recognizes the images. \n\nSkills Used: Machine Learning, Python    \n\n Breast Cancer Diagnosis- \n       Role Description: Using concept of machine learning made a model with     \n       92%  accuracy.  \n\nSkills Used: Machine Learning, Python       \n\n Newell Brands-  \nRole Description: Extracting Data from Sybase with the help of SQL Queries \nand fetch them in Excel to verify the data loaded on the server matches with raw \n\ndata.  \nSkills Used: SQL    \n\n Next Desktop Generation- \nRole Description: Making Process flows with the help of Microsoft Visio of \ndifferent word documents so that they can be easily programmed and with the \n\nhelp of SQL Queries fetching the data needed to test those process flows. \nSkills Used: Microsoft Visio and SQL \n\n Implementation of  new client: Rockwell Collins- \nRole Description: Working as a Pilot in team for conversion of client raw data \nin a format which can be loaded into system using Python. Creation of \n\nCalculation Worksheet in Crystal Report with the help of Python and xml \nprogramming. Loading data on the server with the help of Informatica tools \n\n(ETL tools). \nSkills Used: Python, XML, SQL, Informatica and Crystal Report    \n\n \n\nWORKED AS:  \nASSOCIATE BUSINESS ANALYST     Conduent (Xerox)      January’18- Till Date \n\n \n\nACADEMIC QUALIFICATIONS:  \n\n         INSTITUTE/UNIVERSITY YEAR             PERCENTAGE \n\nInderprastha Engineering College, Ghaziabad 2013 – 2017            74.2 \n\nB.Tech in Computer Science  \n\nSt. Xavier’s Sec. School, Bhiwadi 2013                        73.4 \n\nIntermediate  \n\nSt. Xavier’s Sec. School, Bhiwadi 2011                        81.7 \n\nHigh School   \n\nLanguage: Python","annotation":[{"label":["Skills"],"points":[{"start":4141,"end":4146,"text":"Python"}]},{"label":["10 %"],"points":[{"start":4046,"end":4125,"text":"St. Xavier’s Sec. School, Bhiwadi 2011                        81.7 \n\nHigh School"}]},{"label":["12 %"],"points":[{"start":3961,"end":4041,"text":"St. Xavier’s Sec. School, Bhiwadi 2013                        73.4 \n\nIntermediate"}]},{"label":["Highest degree"],"points":[{"start":3857,"end":3957,"text":"Inderprastha Engineering College, Ghaziabad 2013 – 2017            74.2 \n\nB.Tech in Computer Science "}]},{"label":["Skills"],"points":[{"start":3632,"end":3634,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3619,"end":3624,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3499,"end":3504,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3420,"end":3425,"text":"Python"}]},{"label":["Total experience"],"points":[{"start":3240,"end":3588,"text":"Implementation of  new client: Rockwell Collins- \nRole Description: Working as a Pilot in team for conversion of client raw data \nin a format which can be loaded into system using Python. Creation of \n\nCalculation Worksheet in Crystal Report with the help of Python and xml \nprogramming. Loading data on the server with the help of Informatica tools"}]},{"label":["Skills"],"points":[{"start":3232,"end":3234,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3132,"end":3134,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2970,"end":3234,"text":"Role Description: Making Process flows with the help of Microsoft Visio of \ndifferent word documents so that they can be easily programmed and with the \n\nhelp of SQL Queries fetching the data needed to test those process flows. \nSkills Used: Microsoft Visio and SQL"}]},{"label":["Skills"],"points":[{"start":2933,"end":2935,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2847,"end":2851,"text":"Excel"}]},{"label":["Skills"],"points":[{"start":2816,"end":2818,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2753,"end":2936,"text":"Role Description: Extracting Data from Sybase with the help of SQL Queries \nand fetch them in Excel to verify the data loaded on the server matches with raw \n\ndata.  \nSkills Used: SQL "}]},{"label":["Skills"],"points":[{"start":2719,"end":2724,"text":"Python"}]},{"label":["Skills"],"points":[{"start":2541,"end":2546,"text":"Python"}]},{"label":["Total experience"],"points":[{"start":2167,"end":2334,"text":"Training /mentoring of new hires associates for understanding process based \nrequirements & building mapping logics. Also, Quality peer review of work \nbefore deploying"}]},{"label":["Phone"],"points":[{"start":2146,"end":2152,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":1736,"end":1838,"text":"Defect Handling- Resolve production issue(s) and changes order by \nmodifying backend code when required"}]},{"label":["Skills"],"points":[{"start":1663,"end":1668,"text":"Python"}]},{"label":["Total experience"],"points":[{"start":1554,"end":1668,"text":"Executing data mining, information extraction and classification upon \nstructured & un-structured data using Python"}]},{"label":["Skills"],"points":[{"start":1364,"end":1368,"text":"Excel"}]},{"label":["Total experience"],"points":[{"start":1039,"end":1378,"text":"Abhishek Pratap Singh a Certified Data \nScientist who has 1+ year record of exceeding set targets.  \nHighly developed skills in problem identification and implementation of effective \n\nsolutions. Comfortable with analyzing and understanding data, working under \n\ntime pressure and presenting myself in a professional manner. Excellent inter"}]},{"label":["Skills"],"points":[{"start":409,"end":413,"text":"Excel"}]},{"label":["Skills"],"points":[{"start":398,"end":406,"text":"MS Access"}]},{"label":["Skills"],"points":[{"start":378,"end":386,"text":"Oracle 9i"}]},{"label":["Skills"],"points":[{"start":373,"end":375,"text":"SQL"}]},{"label":["Phone"],"points":[{"start":222,"end":228,"text":"Tableau"}]},{"label":["Email"],"points":[{"start":149,"end":174,"text":"thakurabhishek09@gmail.com"}]},{"label":["Phone"],"points":[{"start":129,"end":138,"text":"8287833947"}]},{"label":["Address"],"points":[{"start":11,"end":116,"text":"-03, Kingfisher Residency,   \n\n                Sector-2A UIT, Bhiwadi,  \n\n                Rajasthan-301019"}]}],"extras":null,"metadata":{"first_done_at":1631183052000,"last_updated_at":1631183052000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Current Address: 641-A/24 DLF Colony, Rohtak, Haryana\nContact: +91-9050316151   \t \t \t \t \t \t \t \nEmail: jgarima2308@gmail.com                \n \n                                                                         GARIMA JUNEJA\nObjective \n\nTo seek a position in an organization where I can contribute towards the goal of the organization using my skills in a professionally competitive environment that provides me scope for improving and learning to grow as an individual and as a professional. \n \nWork Experience  \n\nConduent, Gurgaon \nAssociate Analyst \t \t \t \t \t \t \t \t \t  \tJanuary 2018 – present \n· Setup and configuration of tables and parameters for Data \tManagement of client data using SQL queries. \n· Worked on executing and creating batch jobs using SAS in BlueZone Mainframe and IBM Mainframe ABD2. \n· Performed analysis on specific client requirements to do web configuration going through the testing and configuration stages of a Software Development Life Cycle while accommodating feature enhancements. \n· Responsible for Deployment of Production Development of a web portal’s design features and enhancements in monthly releases. \n· Worked on debugging and issue tracking for bugs and defects in the web portal using tools like HPQC, TFS. \n \nTechnical Skills \n\n· Languages known - C, C++, SQL \n· Testing Tools - PLSQL, JIRA, HPQC, TFS\n· Operating system - Windows 7, Windows 8 \n· Well versed with MS office tools. \n \n\tInternship\n\t \n\n\n\nWeb Aspiration, Rohtak\nSoftware Developer \t \t \t \t \t \t \t \t       \t      Feb, 2017 - Dec, 2017 \n· Worked on asp.NET, C#.NET, ADO.NET, SQL Server 2008 R2. \n\n\tProjects Undergone\n\t\n\n\n\n· Web Aspiration Projects \n1. Hotel Management\n· It’s a Hotel Management website based on HTML, CSS and asp.NET .\n· To create the complete UI and the database architecture, creating the Application completely dynamic with its modules.\n\n2. Web Aspiration(http:// webaspiration.website/)\n· This is a web application for maintaining all the records of any organization like employee management, customer management, expense management, project management, EOD and Attendance module.\n· Create or modify different modules being a part of my team & managing database of the project accordingly.\n\n3. Educozone(An Educational Listing Directory)(http://educozone.webaspiration.website/)\n· This is a web application for targeting educational directories like college directory/ school directory/ institute directory which help us visitors or users to explore colleges/schools or institute based on their locations or desired courses or desired universities and affiliations.\n· To create the complete UI and the database architecture, creating the Application completely dynamic with its modules.\n\n· Conduent Projects\n1. Honeywell\nConfigured ATE (Automated Test Execution) for this client using SQL and Excel scripts.\t\n2. Rapid/U-point Implementation\nThis is a web configuration Tool for customizing and branding web for various clients like Scotts, Wiley, Adobe, CWT, L3C, Broadridge etc.\n3. Gold Implementation\nIt is the dummy client skeleton which we design for multiple clients (implemented events setup).\n4. DTCC Implementation\nCurrently working on implementation of DTCC. Implementing Group Code, events and Calc.\n\n \n\tEducation Credentials\n\t \n\n\n \n\tYear \n\tExamination \n\tInstitution/School \n\tPercentage \n\n\t2017 \n\tB. Tech, Computer Science \n\tVaish College of Engg. affiliated to MDU \n\t79% \n\n\t2013 \n\tClass XII, Science \n\tDelhi Public School, Rohtak  \n\t85% \n\n\t2011 \n\tClass X \n\tShiksha Bharti School, Rohatk  \n\t95% \n\n\n \n\n\tAdditional \n\t Trainings \n\n\n\n· Business Etiquettes training.\n· MS Excel Training.\n· Email Etiquettes.\n\nAchievements & Extra Curricular Activities \n\n· Worked as Co-ordinator in JHANKAR-2013(MDU Zonal Youth Fest) & Alumini Meet in college.\n· Participated and secured positions in Collage, Poster Making and Rangoli competition at college level.\n· Participated in Collage Making in JHANKAR-2013 (MDU Zonal Youth Fest).\n· Participated and secured positions in Sanskriti Gyan Pariksha & Painting competition at school level.\n· Participated in Mehndi Competition at school level. \n\n\tStrengths\n\t \n\n\n\n· Ability in handling multiple opportunities, with a genuine interest in technical development.\n· Keen communicator with good interpersonal skills and ability to grasp new concepts to utilize them in a productive manner.\n\nPersonal Dossier \n\n· Date of birth: 23rd August, 1995\n· Father’s Name: Mr. Mohinder Kumar \n· Areas of interest: Handmade crafts, Art, Travelling \n· Linguistic Competencies: Fluent in English & Hindi \n· Permanent Address: 641-A/24 DLF Colony, Rohtak, Haryana","annotation":[{"label":["Skills"],"points":[{"start":4588,"end":4588,"text":"C"}]},{"label":["Skills"],"points":[{"start":4513,"end":4513,"text":"C"}]},{"label":["Total experience"],"points":[{"start":4134,"end":4225,"text":"Ability in handling multiple opportunities, with a genuine interest in technical development"}]},{"label":["Skills"],"points":[{"start":4084,"end":4084,"text":"C"}]},{"label":["Skills"],"points":[{"start":3900,"end":3900,"text":"C"}]},{"label":["Total experience"],"points":[{"start":3884,"end":3952,"text":"Participated in Collage Making in JHANKAR-2013 (MDU Zonal Youth Fest)"}]},{"label":["Skills"],"points":[{"start":3817,"end":3817,"text":"C"}]},{"label":["Skills"],"points":[{"start":3699,"end":3699,"text":"C"}]},{"label":["Total experience"],"points":[{"start":3689,"end":3774,"text":"Worked as Co-ordinator in JHANKAR-2013(MDU Zonal Youth Fest) & Alumini Meet in college"}]},{"label":["Skills"],"points":[{"start":3663,"end":3663,"text":"C"}]},{"label":["Skills"],"points":[{"start":3602,"end":3609,"text":"MS Excel"}]},{"label":["10 %"],"points":[{"start":3486,"end":3532,"text":"Class X \n\tShiksha Bharti School, Rohatk  \n\t95% "}]},{"label":["Skills"],"points":[{"start":3486,"end":3486,"text":"C"}]},{"label":["12 %"],"points":[{"start":3420,"end":3475,"text":"Class XII, Science \n\tDelhi Public School, Rohtak  \n\t85% "}]},{"label":["Skills"],"points":[{"start":3420,"end":3420,"text":"C"}]},{"label":["Skills"],"points":[{"start":3369,"end":3369,"text":"C"}]},{"label":["Skills"],"points":[{"start":3344,"end":3344,"text":"C"}]},{"label":["Highest degree"],"points":[{"start":3335,"end":3407,"text":"B. Tech, Computer Science \n\tVaish College of Engg. affiliated to MDU \n\t79"}]},{"label":["Skills"],"points":[{"start":3252,"end":3252,"text":"C"}]},{"label":["Skills"],"points":[{"start":3232,"end":3232,"text":"C"}]},{"label":["Skills"],"points":[{"start":3215,"end":3215,"text":"C"}]},{"label":["Skills"],"points":[{"start":3193,"end":3193,"text":"C"}]},{"label":["Skills"],"points":[{"start":3192,"end":3192,"text":"C"}]},{"label":["Skills"],"points":[{"start":3151,"end":3151,"text":"C"}]},{"label":["Skills"],"points":[{"start":3134,"end":3134,"text":"C"}]},{"label":["Skills"],"points":[{"start":3133,"end":3133,"text":"C"}]},{"label":["Skills"],"points":[{"start":2989,"end":2989,"text":"C"}]},{"label":["Skills"],"points":[{"start":2982,"end":2982,"text":"C"}]},{"label":["Total experience"],"points":[{"start":2869,"end":3029,"text":"This is a web configuration Tool for customizing and branding web for various clients like Scotts, Wiley, Adobe, CWT, L3C, Broadridge etc.\n3. Gold Implementation"}]},{"label":["Skills"],"points":[{"start":2813,"end":2815,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2749,"end":2749,"text":"C"}]},{"label":["Skills"],"points":[{"start":2718,"end":2718,"text":"C"}]},{"label":["Total experience"],"points":[{"start":2222,"end":2546,"text":"Educozone(An Educational Listing Directory)(http://educozone.webaspiration.website/)\n· This is a web application for targeting educational directories like college directory/ school directory/ institute directory which help us visitors or users to explore colleges/schools or institute based on their locations or desired cou"}]},{"label":["Skills"],"points":[{"start":2111,"end":2111,"text":"C"}]},{"label":["Total experience"],"points":[{"start":1917,"end":2106,"text":"This is a web application for maintaining all the records of any organization like employee management, customer management, expense management, project management, EOD and Attendance module"}]},{"label":["Skills"],"points":[{"start":1736,"end":1739,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1725,"end":1725,"text":"C"}]},{"label":["Skills"],"points":[{"start":1582,"end":1584,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1576,"end":1579,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1567,"end":1570,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1565,"end":1566,"text":"C#"}]},{"label":["Skills"],"points":[{"start":1565,"end":1565,"text":"C"}]},{"label":["Skills"],"points":[{"start":1559,"end":1562,"text":".NET"}]},{"label":["Skills"],"points":[{"start":1343,"end":1343,"text":"C"}]},{"label":["Skills"],"points":[{"start":1329,"end":1331,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1327,"end":1331,"text":"PLSQL"}]},{"label":["Skills"],"points":[{"start":1304,"end":1306,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1299,"end":1301,"text":"C++"}]},{"label":["Skills"],"points":[{"start":1299,"end":1299,"text":"C"}]},{"label":["Skills"],"points":[{"start":1296,"end":1296,"text":"C"}]},{"label":["Skills"],"points":[{"start":1246,"end":1246,"text":"C"}]},{"label":["Total experience"],"points":[{"start":1020,"end":1142,"text":"Responsible for Deployment of Production Development of a web portal’s design features and enhancements in monthly releases"}]},{"label":["Skills"],"points":[{"start":969,"end":969,"text":"C"}]},{"label":["Total experience"],"points":[{"start":812,"end":1014,"text":"Performed analysis on specific client requirements to do web configuration going through the testing and configuration stages of a Software Development Life Cycle while accommodating feature enhancements"}]},{"label":["Skills"],"points":[{"start":693,"end":695,"text":"SQL"}]},{"label":["designation"],"points":[{"start":538,"end":554,"text":"Associate Analyst"}]},{"label":["Experience in current company"],"points":[{"start":519,"end":535,"text":"Conduent, Gurgaon"}]},{"label":["Skills"],"points":[{"start":519,"end":519,"text":"C"}]},{"label":["Total experience"],"points":[{"start":241,"end":494,"text":"To seek a position in an organization where I can contribute towards the goal of the organization using my skills in a professionally competitive environment that provides me scope for improving and learning to grow as an individual and as a professional"}]},{"label":["Name"],"points":[{"start":215,"end":227,"text":"GARIMA JUNEJA"}]},{"label":["Email"],"points":[{"start":102,"end":122,"text":"jgarima2308@gmail.com"}]},{"label":["Phone"],"points":[{"start":67,"end":76,"text":"9050316151"}]},{"label":["Skills"],"points":[{"start":54,"end":54,"text":"C"}]},{"label":["Skills"],"points":[{"start":30,"end":30,"text":"C"}]},{"label":["Skills"],"points":[{"start":0,"end":0,"text":"C"}]}],"extras":null,"metadata":{"first_done_at":1631168982000,"last_updated_at":1631168982000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Md. Aftab\nS5-786 Jamia Nagar\t\t\t\t\t\tMobile: +91 7838337079\nJogabai Extension Batla House Okhla Delhi\t\t\tE-Mail: aftabmonu@gmail.com\nProfessional Summary:-\n\nHaving 3 years of Professional experience in IT industry as Business Analyst. I have been involved in extensive experience of managing projects through all phases of project Life cycle Including Analyzing, implementation and maintaining Business Intelligence Solution using ITIL methodology and Agile methodology.\n\nTechnical Expertise:-\n\nI have vast experience in business analysis profile of 3 years. At present, I am working for Microsoft (client), where my role is to analyze, provide solutions and document the new requirements (change request) needed for the project. I am using various tools and technology to perform all the operation assigned to me like SQL, Agile methodology, SNOW and ITIL protocol for analysis purpose and Power BI for presenting the desired documents to client.\n\nProfessional Experience:-\n\nTime Span: - Dec 2018 till Present [10 Months]\nCompany: - Liquid hub Analytic PVT Ltd, Gurgaon [A Capgemini Invent Company]\nClient: -        Microsoft\nRoles and Responsibilities:\n· Rich experience in business analysis and client interaction.\n· Experience in SQL as the ability to analyze complex data structures from standard systems.\n· 3 years of experience in Reporting using Power BI tool and Business Data Analysis.\n· Strong Analytical, troubleshooting and Problem-Solving skills.\n· Advanced knowledge of MS Excel.\n· Excellent knowledge connecting Microsoft Power BI Desktop to various data sources. \n· Work directly with business units to define and prototype Power BI Dashboards.\n· Extracting, transforming and loading data from multiple sources into Power BI applications and publishing the reports.\n· Expertise and proven experience in development of reports, dashboard structure ambiguous business problems and recommend visualization solutions.\n· Experience in creating calculated measures and columns with DAX in MS Power BI Desktop.\n· Ability to self- serve, investigate, get the required data and expertise in data visualization/ presentation.\n· Ability to work with remote teams and across time zones to manage stakeholder expectations.\n· Collaborate and partner with Business Analyst and Project Manager to understand business requirements. \n· Experience working with business stakeholders to elicit and document business requirements and processes.\n· Ability to engage at executive level staff, influence the business and clients alike.\n· Ability to stand back from the detailed data and cast a critical eye to expose new leaner logical approaches to warehousing processes and governance.\n· An inquisitive mindset and desire to understand both business requirements, and the data that underpin them.\n· Understanding of Project Planning methodology.\n· Demonstrable business acumen with strong business analysis and influencing to ensure completion of tasks.\n· Excellent understanding of internal systems and departmental procedures.\n· Progressive and forward thinking with the ability to identify industry/technology trends.\n· Strong team player, with the ability to contribute and challenge yourself and the team.\n· Strong people management skills with the ability to drive and obtain the best from others.\n\nTime Span: - JAN 2018 – Aug 2018 [7 Months]\nCompany: - Tek Travel PVT Ltd, Gurgaon.\nRoles and Responsibilities:\n\n· Worked on SQL Queries and fetch out the logs in the XML and JSON format and analysis the flow of booking process in the logs which contain all the action and details of the bookings. \n· Maintaining the hierarchy of tickets according the priority level and always takes priority for those cases which affect the business loss.\n· Provide the proficient resolution to our agents and operation team on their reported issues. \n· Analyse application problems, recommend and develop solutions.\n· Knowledge of Different Travel Domain Products like B2B, B2C, B2B2B, API, White Label.\n· Test the new features of application as well exiting features.\n· Making interaction coordinate with suppliers and vendors and escalating the related issue which also effect the business revenue.\n· Conduct team viewer session of the clients for better resolution of issues.\n\nTime Span: - MAR 2015 – NOV 2016 [1 Years 8 months]\nCompany: - V R VIRTUAL PVT Ltd, C R Park New Delhi.\nRoles and Responsibilities:\n\n· Build and maintain SQL scripts, indexes, and SQL queries for data analysis and extraction.\n· Provide data base coding to support business applications using SQL Queries.\n· Having Experience in Database as analysis, developing procedure, trigger and Function for Business Applications.\n· Generate SQL reports and Manual Testing of Web and Mobile Applications.\n· Identified data issues and provided recommendations for resolution to ensure optimal performance.\n· Documented and maintained Database Application specifications. \n· Monitored and provided front and back line support of daily processes.\n\nQualification Details: -\n\n· Three year diploma in Software Engineer from NIIT.\n· B.A from Mahatma Gandhi University.\n· 12th from BSEB Patna\n· 10th from BSEB Patna.\n\nAcademic Achievements: -\n\n· Ranked 2nd on 100 meter running competition.\n· Selected for District Under 19 Cricket Team.\n· Distinction Marks in Math, English and chemistry.\n\nTechnical Skills: -\n\n· Concepts: OOPS & Data Structures.\n· Web Technologies/Scripting: SQL, HTML, JSON, XML.\n· Tools: Microsoft SNOW, Manage Engine, Postman, Ticketing Tools.\n· Operating System: Microsoft Windows Operating System.\n\nCertification: -\n\n· Oracle Database 10g: Introduction to SQL.\n· Oracle Database 10g : PL/SQL Fundamentals.\n· Diploma in Computer Application.\n\nExtra Curricular Activities: -\n\n· Participates in online programming contests\n· Listening to Music, Reading books, Playing Cricket.\n\nPersonal Details: -\n\n· Father’s Name : Md Abid Hussain\n· Mother’s Name: Kuresha Khatoon\n· Languages        : English, Hindi\n· Date Of Birth   : 03/08/1991\n· Permanent Address : H.No 135 Bhartiya Nagar Ward No 26 Saharsa Bihar.","annotation":[{"label":["10 %"],"points":[{"start":5138,"end":5157,"text":"10th from BSEB Patna"}]},{"label":["12 %"],"points":[{"start":5115,"end":5134,"text":"12th from BSEB Patna"}]},{"label":["Highest degree"],"points":[{"start":5077,"end":5111,"text":"B.A from Mahatma Gandhi University."}]},{"label":["Total experience"],"points":[{"start":4684,"end":4753,"text":"Generate SQL reports and Manual Testing of Web and Mobile Applications"}]},{"label":["Last company"],"points":[{"start":4325,"end":4343,"text":"V R VIRTUAL PVT Ltd"}]},{"label":["Total experience"],"points":[{"start":3597,"end":3734,"text":"Maintaining the hierarchy of tickets according the priority level and always takes priority for those cases which affect the business loss"}]},{"label":["Total experience"],"points":[{"start":3411,"end":3591,"text":"Worked on SQL Queries and fetch out the logs in the XML and JSON format and analysis the flow of booking process in the logs which contain all the action and details of the bookings"}]},{"label":["Total experience"],"points":[{"start":2947,"end":3017,"text":"Excellent understanding of internal systems and departmental procedures"}]},{"label":["Total experience"],"points":[{"start":2527,"end":2674,"text":"Ability to stand back from the detailed data and cast a critical eye to expose new leaner logical approaches to warehousing processes and governance"}]},{"label":["Total experience"],"points":[{"start":1781,"end":1924,"text":"Expertise and proven experience in development of reports, dashboard structure ambiguous business problems and recommend visualization solutions"}]},{"label":["Total experience"],"points":[{"start":1216,"end":1304,"text":"Experience in SQL as the ability to analyze complex data structures from standard systems"}]},{"label":["Total experience"],"points":[{"start":1152,"end":1211,"text":" Rich experience in business analysis and client interaction"}]},{"label":["Experience in current company"],"points":[{"start":1029,"end":1065,"text":" Liquid hub Analytic PVT Ltd, Gurgaon"}]},{"label":["Total experience"],"points":[{"start":491,"end":941,"text":"I have vast experience in business analysis profile of 3 years. At present, I am working for Microsoft (client), where my role is to analyze, provide solutions and document the new requirements (change request) needed for the project. I am using various tools and technology to perform all the operation assigned to me like SQL, Agile methodology, SNOW and ITIL protocol for analysis purpose and Power BI for presenting the desired documents to client"}]},{"label":["Total experience"],"points":[{"start":153,"end":464,"text":"Having 3 years of Professional experience in IT industry as Business Analyst. I have been involved in extensive experience of managing projects through all phases of project Life cycle Including Analyzing, implementation and maintaining Business Intelligence Solution using ITIL methodology and Agile methodology"}]},{"label":["Email"],"points":[{"start":109,"end":127,"text":"aftabmonu@gmail.com"}]},{"label":["Address"],"points":[{"start":57,"end":96,"text":"Jogabai Extension Batla House Okhla Delh"}]},{"label":["Phone"],"points":[{"start":46,"end":55,"text":"7838337079"}]},{"label":["Name"],"points":[{"start":0,"end":8,"text":"Md. Aftab"}]}],"extras":null,"metadata":{"first_done_at":1631169074000,"last_updated_at":1631169074000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Laxmi Ramshankar Kanojia  \nMob No.: 8652446360                                                                                   Email: laxmikanojia1011@gmail.com \n\n \n\n \n\nCareer Objective: To work hard and to be part of reputed organization where I can show my talent and potential \n\n \n\nProfile:  \n\n \n\n• Currently working at Capgemini Pvt. Ltd, Mumbai as Associate Consultant since July 2016. \n\n• In the last 2 years, have gained hands on experience in SQL Server, Tableau, Power BI, and SSIS. \n\n• Skilled at Development of Mappings according to the ETL Specifications. \n\n• Self-driven and self-motivated person with great communication and presentation skills. \n\n• Comfortable working as a member of integrated team as well as independently.  \n \n\n    Competencies: \n\n \n\nOperating Systems Windows XP, Windows 7/8 \n\nDatabases SQL Server 2016 \n\nETL and Reporting Tools SSIS, Tableau, Power BI, DWH Concepts \n\nSoftware SQL Server Management Studio 2016, \n\nMicrosoft Visual Studio 2016 \n\nVersion Control TFS \n\n \n\nExperience:  \n\n \n\nWorking as an Associate Consultant in CAPGEMNI TECHNOLOGY SERVICES INDIA LIMITED, Mumbai \n\nsince 2016. \n\n \n\nProject Experience:  \n\n \n\nProject 1: \n\n   \n\nProject Name/Client  Affinity Gaming, USA \n\n Domain  Gaming \n\n Role  SQL ,ETL and Report Developer \n\n Duration  May 2017 to Dec 2018. \n\n Environment  SQL 2016, SSIS 2016 Professional, and Tableau \n\n \n\nRoles and Responsibilities: \n\n \n\n• Involved in Requirement Analysis. \n\n• Created/updated SSIS packages using Sql server 2016 Integration services. Tested and managed master packages.  \n\n• Involved in creating database objects such as Tables, Views, writing Stored Procedures, UDFS. \n\n• Involved in all phases of the project (Documentation, Designing, Unit testing and Defect fixing) \n\n• Training new team members through KT sessions. \n\n• Design/Managing and Testing SSRS Reports. \n\n• Created Tableau Dashboards for reporting. \n\n• Managed TFS for reports, packages, SQL queries and Documents. \n\n• Monitored ETL Jobs running on daily basis and validated it on time to time. \n \n\n \n\n \n\nmailto:sayali_ayarkar2000@yahoo.com\n\n\n \n\nProject 2: \n\n   \n\nProject Name/Client Schlumberger, USA \n\n Domain  Energy and Utilities \n\n Role  SQL and Power BI Developer \n\n Duration  Jan 2019 to Present. \n\n Environment  SQL 2016 and Power BI \n\n \n\nRoles and Responsibilities: \n\n \n\n• Involved in Requirement Analysis to design reports based on RSD. \n\n• Created Power Bi Reports and Dashboards using Cube as the source. \n\n• Used different visuals such as Table, Bar charts, Column charts, TreeMap, Slicer, Maps, Cards, Line chart, \nCombination charts, etc. \n\n• Created new Measures using DAX expressions. \n\n• Worked with DAX functions like Aggregate, Mathematical, etc. \n\n• Involved in all phases of the project (Documentation, Designing, Unit testing and Defect fixing) \n\n \n\nEducational Details: Bachelor of Engineering in Electronics from Mumbai University. \n\n \n\n    Personal Details: \n\n \n\nName Laxmi Kanojia \n\nDesignation Associate Consultant \n\nBirth Date 11-11-1993 \n\nLocation Mumbai \n\nNationality Indian \n\nMarital Status Single \n\nGender Female \n\nAddress \n\n28, Dr. Peter Dias Road, Sarkari bawdi, \n\nBandra (W), Mumbai - 400050. \n\n \n\n \n\nKey Strengths: \n\n \n\n•    Hardworking and confident \n\n•    Positive Attitude \n\n•    Ability to collaborate with team members. \n\n \n\nHobbies: \n\n \n\n•    Playing badminton, carrom and cricket \n\n•     Long walks \n\n \n\n \n\n          Laxmi Kanojia","annotation":[{"label":["Address"],"points":[{"start":3115,"end":3183,"text":"28, Dr. Peter Dias Road, Sarkari bawdi, \n\nBandra (W), Mumbai - 400050"}]},{"label":["designation"],"points":[{"start":2979,"end":2998,"text":"Associate Consultant"}]},{"label":["Highest degree"],"points":[{"start":2851,"end":2911,"text":"Bachelor of Engineering in Electronics from Mumbai University"}]},{"label":["Total experience"],"points":[{"start":2728,"end":2823,"text":"Involved in all phases of the project (Documentation, Designing, Unit testing and Defect fixing)"}]},{"label":["Total experience"],"points":[{"start":2477,"end":2608,"text":" Used different visuals such as Table, Bar charts, Column charts, TreeMap, Slicer, Maps, Cards, Line chart, \nCombination charts, etc"}]},{"label":["Skills"],"points":[{"start":2290,"end":2297,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2277,"end":2279,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":2208,"end":2215,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":2200,"end":2202,"text":"SQL"}]},{"label":["Email"],"points":[{"start":2069,"end":2096,"text":"sayali_ayarkar2000@yahoo.com"}]},{"label":["Total experience"],"points":[{"start":1976,"end":2049,"text":"Monitored ETL Jobs running on daily basis and validated it on time to time"}]},{"label":["Skills"],"points":[{"start":1945,"end":1947,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1872,"end":1878,"text":"Tableau"}]},{"label":["Total experience"],"points":[{"start":1666,"end":1761,"text":"Involved in all phases of the project (Documentation, Designing, Unit testing and Defect fixing)"}]},{"label":["Skills"],"points":[{"start":1469,"end":1472,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":1453,"end":1560,"text":"Created/updated SSIS packages using Sql server 2016 Integration services. Tested and managed master packages"}]},{"label":["Skills"],"points":[{"start":1367,"end":1373,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":1339,"end":1342,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":1329,"end":1331,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":1248,"end":1250,"text":"SQL"}]},{"label":["designation"],"points":[{"start":1041,"end":1060,"text":"Associate Consultant"}]},{"label":["Skills"],"points":[{"start":916,"end":918,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":882,"end":889,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":873,"end":879,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":867,"end":870,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":825,"end":827,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":498,"end":567,"text":"Skilled at Development of Mappings according to the ETL Specifications"}]},{"label":["Skills"],"points":[{"start":488,"end":491,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":474,"end":481,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":465,"end":471,"text":"Tableau"}]},{"label":["Skills"],"points":[{"start":453,"end":455,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":397,"end":491,"text":"In the last 2 years, have gained hands on experience in SQL Server, Tableau, Power BI, and SSIS"}]},{"label":["designation"],"points":[{"start":355,"end":374,"text":"Associate Consultant"}]},{"label":["Experience in current company"],"points":[{"start":325,"end":350,"text":"Capgemini Pvt. Ltd, Mumbai"}]},{"label":["Total experience"],"points":[{"start":171,"end":280,"text":"Career Objective: To work hard and to be part of reputed organization where I can show my talent and potential"}]},{"label":["Email"],"points":[{"start":136,"end":161,"text":"laxmikanojia1011@gmail.com"}]},{"label":["Phone"],"points":[{"start":36,"end":45,"text":"8652446360"}]},{"label":["Name"],"points":[{"start":0,"end":15,"text":"Laxmi Ramshankar"}]}],"extras":null,"metadata":{"first_done_at":1631170547000,"last_updated_at":1631170547000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "ANMOL AGARWAL  \n\n \n\nContact: +91-9958594438                                                        E-mail: anmol.agarwal012@gmail.com \n\nPROFESSIONAL SUMMARY \n\n1.7 years of Experience in Consulting & providing custom solutions to Pharmaceutical companies in \n\nDrug Safety and Surveillance. Experience in writing database objects (Procedures, Functions, \n\nPackages, etc.) and reports development and testing using SAP Business Objects Web Intelligence \n\nand Universe Designer. \n\nCAREER OBJECTIVE \n\nSeeking an opportunity in an organization where I can work on the leading areas of technology to \n\nachieve high career growth through a continuous learning process to keep myself dynamic, visionary \n\nand competitive. \n\nWORK EXPERIENCE \n\nForesight, an IQVIA Company \n\n▪ Currently Working as Associate Consultant since January 2019 \n▪ Worked as a Trainee from July 2018 to January 2019 \n▪ Worked as an Intern from March 2018 to July 2018 \n\nProjects: \n\n1. Develop Report for an EU Based Pharmaceutical Company \nThis project is to develop a new report based on SAP Business Objects Web Intelligence, as \n\nper the business specific requirements. The report has various Line Listings are developed. In \n\naddition to it, various Validation Checks are implemented. \n\n2. Interface Implementation for an EU Based Pharmaceutical Company \nThis project was to implement a Custom Interface between Argus Safety and Medidata Rave \n\nCoder. This custom interface was required to support business process for central coding \n\nreview, and consistency in coding across Safety and clinical systems. \n\n3. Argus Upgrade for an EU Based Pharmaceutical Company \nThis project involves upgrading the Drug Safety System from Argus 7.0.2.4 to Argus 8.1.2.1. \n\nThe Safety Group has multiple Business Objects Universes & Custom reports on top of the \n\nArgus Safety, Affiliate & Insight systems. Project included upgrade and enhancement of these \n\nReports & Universes along with fixing issues being faced by the client in relation to \n\nperformance and functionality. \n\n4. Custom Reports Release for an EU Based Pharmaceutical Company \n\nThis Project was to create several Objects in SAP Business Objects for Ad-hoc reporting \n\nneeds and for Standard Reports as well. In addition to this, some of the standard reports were \n\nupdated and validated as per the Business requirements. \n\n \nRoles & Responsibilities: \n\n▪ Creating database packages/functions to achieve various functionalities in the reports / \nInterface and Update ETL code to make it compatible to new version of System \n\n▪ Updating the Universes & Custom Reports, Designing and Developing the report in SAP \nBusiness Objects Web intelligence and Universe Designer \n\n▪ Requirement gathering, System demonstration & evidence walkthroughs to Client \n▪ Preparing Design Documents (Functional Specification, Unit Detail Design, etc) \n▪ Authoring Scenarios and validation scripts, deployment scripts and executing those scripts on \n\nHPALM for Validation and Production Environment of the client \n\n\n\n▪ Onsite Experience during Project release \n▪ Supporting post Go-Live Hypercare – Incident Management and Change requests \n\n \n\nSOFTWARE SKILLS \n\n▪ Languages: SQL, PL/SQL, JAVA, Python (Basics), HTML5, CSS \n▪ Databases: Oracle, MySQL \n▪ Tools / IDE’s: SAP Business Objects Web Intelligence, Universe Designer, HP ALM, Argus \n\nSafety, Argus Insight, HP ALM, Smart IT (For Incident Management), Anaconda, Eclipse, \n\nIntelliJ \n\n▪ Proficient in Microsoft Office (Word, Excel, PowerPoint)  \n\nPROFESSIONAL SKILLS \n\n▪ Quick learning ability \n▪ Adaptability to new environment \n\n▪ Team Work \n▪ Leadership and Management Skills \n\nAREAS OF INTERSET \n\n▪ Software Development \n▪ Database Management \n\n▪ Web Development \n\n \n\nEDUCATIONAL QUALIFICATION \n\n \n\nACADEMIC PROJECTS \n\n1. Prediction of Employee Attrition in Organizations (ML Based Project) \n\nThe project was to do analysis of HR data by applying various ML algorithms and compares \n\ntheir performances. The system enables users to predict whether the employee will leave or \n\nnot based upon various input parameters. \n\nTools & Technologies: Python, Anaconda-Spyder, Machine Learning \n\n2. Campus Connect Classroom Scheduling System  \nThe project was done under Aricent Employability Enhancement Program, conducted by \n\nNASSCOM. This system enables users to schedule trainings without any conflicts as per the \n\navailability of the trainers and the classrooms.          \n\nTools & Technologies: Java Swing, MySQL, Eclipse   \n\nPERSONAL DETAILS \n\n Father’s Name   : Mr. Jitendra Agarwal \n\n Date of Birth   : August 12th, 1996 \n\n Languages Known  : English, Hindi \n\n Permanent Address  : Rama Foam, Raja Ram Market, Siklapur, \n\n  Bareilly, U.P. - 243003 \n\nQUALIFICATION YEAR BOARD/UNIVERSITY COLLEGE SCORE \n\nBachelor of Technology \n\nin Computer Science & \n\nEngineering \n\n2014 – 2018  Dr. APJ Abdul Kalam \n\nTechnical University \n\n(Formerly UPTU), Lucknow \n\nABES Engineering \n\nCollege, Ghaziabad \n\n80.84% \n\nIntermediate, PCM with \n\nComputer Science \n\n2013 – 2014 CISCE (ISC Board), New \n\nDelhi \n\nG.P.M. College, \n\nBareilly \n\n90.80 % \n\nHigh School 2011 – 2012  CISCE (ICSE Board), New \n\nDelhi \n\nG.P.M. College, \n\nBareilly \n\n89.86%","annotation":[{"label":["10 %"],"points":[{"start":5050,"end":5145,"text":"G.P.M. College, \n\nBareilly \n\n90.80 % \n\nHigh School 2011 – 2012  CISCE (ICSE Board), New \n\nDelhi "}]},{"label":["12 %"],"points":[{"start":4961,"end":5047,"text":"Intermediate, PCM with \n\nComputer Science \n\n2013 – 2014 CISCE (ISC Board), New \n\nDelhi "}]},{"label":["Highest degree"],"points":[{"start":4764,"end":4860,"text":"Bachelor of Technology \n\nin Computer Science & \n\nEngineering \n\n2014 – 2018  Dr. APJ Abdul Kalam \n"}]},{"label":["Skills"],"points":[{"start":4468,"end":4470,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":4103,"end":4108,"text":"Python"}]},{"label":["Total experience"],"points":[{"start":3783,"end":4076,"text":"Prediction of Employee Attrition in Organizations (ML Based Project) \n\nThe project was to do analysis of HR data by applying various ML algorithms and compares \n\ntheir performances. The system enables users to predict whether the employee will leave or \n\nnot based upon various input parameters"}]},{"label":["Skills"],"points":[{"start":3247,"end":3249,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3219,"end":3221,"text":"CSS"}]},{"label":["Skills"],"points":[{"start":3212,"end":3216,"text":"HTML5"}]},{"label":["Skills"],"points":[{"start":3195,"end":3200,"text":"Python"}]},{"label":["Skills"],"points":[{"start":3184,"end":3186,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":3181,"end":3186,"text":"PL/SQL"}]},{"label":["Skills"],"points":[{"start":3176,"end":3178,"text":"SQL"}]},{"label":["Total experience"],"points":[{"start":2377,"end":2542,"text":"Creating database packages/functions to achieve various functionalities in the reports / \nInterface and Update ETL code to make it compatible to new version of System"}]},{"label":["Total experience"],"points":[{"start":2036,"end":2340,"text":"Custom Reports Release for an EU Based Pharmaceutical Company \n\nThis Project was to create several Objects in SAP Business Objects for Ad-hoc reporting \n\nneeds and for Standard Reports as well. In addition to this, some of the standard reports were \n\nupdated and validated as per the Business requirements"}]},{"label":["Total experience"],"points":[{"start":1578,"end":2029,"text":" Argus Upgrade for an EU Based Pharmaceutical Company \nThis project involves upgrading the Drug Safety System from Argus 7.0.2.4 to Argus 8.1.2.1. \n\nThe Safety Group has multiple Business Objects Universes & Custom reports on top of the \n\nArgus Safety, Affiliate & Insight systems. Project included upgrade and enhancement of these \n\nReports & Universes along with fixing issues being faced by the client in relation to \n\nperformance and functionality."}]},{"label":["Total experience"],"points":[{"start":1257,"end":1571,"text":" Interface Implementation for an EU Based Pharmaceutical Company \nThis project was to implement a Custom Interface between Argus Safety and Medidata Rave \n\nCoder. This custom interface was required to support business process for central coding \n\nreview, and consistency in coding across Safety and clinical systems"}]},{"label":["Total experience"],"points":[{"start":949,"end":1250,"text":"Develop Report for an EU Based Pharmaceutical Company \nThis project is to develop a new report based on SAP Business Objects Web Intelligence, as \n\nper the business specific requirements. The report has various Line Listings are developed. In \n\naddition to it, various Validation Checks are implemented"}]},{"label":["Experience in current company"],"points":[{"start":786,"end":805,"text":"Associate Consultant"}]},{"label":["Total experience"],"points":[{"start":496,"end":710,"text":"Seeking an opportunity in an organization where I can work on the leading areas of technology to \n\nachieve high career growth through a continuous learning process to keep myself dynamic, visionary \n\nand competitive"}]},{"label":["Total experience"],"points":[{"start":159,"end":472,"text":"1.7 years of Experience in Consulting & providing custom solutions to Pharmaceutical companies in \n\nDrug Safety and Surveillance. Experience in writing database objects (Procedures, Functions, \n\nPackages, etc.) and reports development and testing using SAP Business Objects Web Intelligence \n\nand Universe Designer"}]},{"label":["Email"],"points":[{"start":107,"end":132,"text":"anmol.agarwal012@gmail.com"}]},{"label":["Phone"],"points":[{"start":33,"end":42,"text":"9958594438"}]},{"label":["Name"],"points":[{"start":0,"end":12,"text":"ANMOL AGARWAL"}]}],"extras":null,"metadata":{"first_done_at":1631179153000,"last_updated_at":1631179153000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "ABOUT ME \n\nSeeking an opportunity to utilize my professional as well as interpersonal skills for the growth of the organization and me \nas well. Always eager to expand horizons of technical experience and knowledge. Highly inclined towards applicative \napproach of the technology. \n\n \n\nEXPERIENCE \n\nAssociate Implementation Consultant \n\n16th Sept 2019 to Present \n\nReyan Consultancy Services LLP, Delhi \n\nAssociate Business Analyst \n\n1st Aug 2017 to 13th Sept 2019 \n\nPrasora Private Limited, Gurgaon \n\n \n\nTECHNOLOGY USED \n\n MySQL \n\n SQL Server \n\n Amazon Web Services \n\n Microsoft Azure \n\n Php \n\n Microsoft Report Builder \n\nPROJECTS DONE WITH REYAN CONSULTANCY SERVICES LLP \n\n1. Creation of Virtual Instance on Microsoft Azure \n\n2. Migration of ticket management system on Microsoft Azure from Amazon Web Services. \n\n3. Maintenance & addition of new feature in company’s internal project website (build over php) admin module and \n\nuser module. \n\n \n\nPROJECTS DONE WITH PRASORA PRIVATE LIMITED \n\n1. Project 1 [Vocational Training Institute, Apparel Training & Design Centre] \n\n• Refactoring old code from scratch. \n\n• Complete academic tracking of candidate enrolled for various courses which includes different stages like \nenrollment, training, assessment, placement of a trainee. \n\n• Inventory Management of organization spread over 260 locations. \n\n• Payroll for 600 employees. \n\n• Library Management System. \n\n• GST Invoice generation & various other reports via Microsoft Report Builder. \n\n2. Project 2 [E Commerce & Apparel Manufacturing, Mr. Button] \n\n• Workflow management of organization men’s made to measure suits, trousers, jackets etc. \n\n    \n\nCHHAVI KANT SINGH \n  \n\n  Associate Implementation Consultant \n\n  \n\nCONTACT INFORMATION   \nH No.2618 , Street No.8 , Bihari   \nColony, Shahadra , Delhi - 110032      \n +91   –   9807728807   \n  \nchhavikant@hotmail.com   \n  \n  \n\n\n\n• Inventory management of SKU. \n\n• Job Order & Purchase Order management and published reports using Microsoft report builder. \n\n• Invoice creation for vendors using Microsoft Report Builder. \n\nEDUCATION \n\nMASTERS OF COMPUTER APPLICATION \n2019 – (Currently Pursuing) \n \n\nSwami Vivekanand Subharti University, Meerut, \nUttar Pradesh \n\nPOST GRADUATE DIPLOMA IN COMPUTER \nAPPLICATION \n2018-2019 \n \n\nSuresh Gyan Vihar University, Jaipur \n\nGNIIT (Software Development) \n2013-2017 \n\n \n\nNIIT, Connaught Place, Delhi \n\nBACHELOR OF ARTS \n2013-2016 \n\n \n\nDeen Dayal Upadhyay University,Gorakhpur, \nUttar Pradesh \n\nCLASS XIIth \n2012-2013 \n\n \n\nKendriya Vidyalaya Air Force Station \nNaliya,Kutch, Gujarat \n\nCLASS Xth \n2010-2011 \n\nKendriya Vidyalaya Jahalalli East,Bangalore \n\nPROFICIENCY \n\n• Development of database structure from scratch. \n• Query Writing & Refactoring. \n• Implementation & troubleshoot of ERP at client side. \n\n• Client Interaction. \n• MS Excel. \n\nPERSONAL SKILLS \n\n• Perseverance \n\n• Adaptability \n• Research \n• Planning \n\nACTIVITIES & INTERESTS \n\n• Playing Cricket \n• Listening Music \n• Traveling \n\n \n\n \n\n \n\n \n\nI hereby declare that above-mentioned information is correct to the best of my knowledge and belief.","annotation":[{"label":["Skills"],"points":[{"start":2832,"end":2839,"text":"MS Excel"}]},{"label":["10 %"],"points":[{"start":2584,"end":2649,"text":"CLASS Xth \n2010-2011 \n\nKendriya Vidyalaya Jahalalli East,Bangalore"}]},{"label":["12 %"],"points":[{"start":2494,"end":2557,"text":"CLASS XIIth \n2012-2013 \n\n \n\nKendriya Vidyalaya Air Force Station"}]},{"label":["Grad. score"],"points":[{"start":2162,"end":2282,"text":"Swami Vivekanand Subharti University, Meerut, \nUttar Pradesh \n\nPOST GRADUATE DIPLOMA IN COMPUTER \nAPPLICATION \n2018-2019 "}]},{"label":["Highest degree"],"points":[{"start":2097,"end":2155,"text":"MASTERS OF COMPUTER APPLICATION \n2019 – (Currently Pursuing"}]},{"label":["Total experience"],"points":[{"start":2022,"end":2080,"text":"Invoice creation for vendors using Microsoft Report Builder"}]},{"label":["Total experience"],"points":[{"start":1926,"end":2015,"text":"Job Order & Purchase Order management and published reports using Microsoft report builder"}]},{"label":["Email"],"points":[{"start":1856,"end":1877,"text":"chhavikant@hotmail.com"}]},{"label":["Phone"],"points":[{"start":1839,"end":1848,"text":"9807728807"}]},{"label":["Address"],"points":[{"start":1752,"end":1820,"text":"H No.2618 , Street No.8 , Bihari   \nColony, Shahadra , Delhi - 110032"}]},{"label":["Name"],"points":[{"start":1662,"end":1678,"text":"CHHAVI KANT SINGH"}]},{"label":["Total experience"],"points":[{"start":1421,"end":1495,"text":"GST Invoice generation & various other reports via Microsoft Report Builder"}]},{"label":["Total experience"],"points":[{"start":1291,"end":1352,"text":"Inventory Management of organization spread over 260 locations"}]},{"label":["Total experience"],"points":[{"start":1122,"end":1284,"text":"Complete academic tracking of candidate enrolled for various courses which includes different stages like \nenrollment, training, assessment, placement of a trainee"}]}],"extras":null,"metadata":{"first_done_at":1631180623000,"last_updated_at":1631180623000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Gurpreet Singh  \n\n \nPhone: 9855329665, 7986475827 \nEmail: sidhu.gurpreet12221@gmail.com \n \nObjective \n \nLooking for a challenging career in IT industry which demands the best of my professional ability in terms of technical and \nanalytical skills and helps me in broadening and enhancing my current skill and knowledge that can provide benefits to the \norganization. \n \n\nProfessional Summary \n \n\n● 2+ years of experience in Information Technology Industry in Software Development. \n● Currently working as Software Engineer with Indus Valley Partners, Noida. \n● Experience in backend database development. \n● Functional Knowledge of Hedge Fund eco system. \n● Worked for multiple American based Hedge Fund investing companies. \n\n \n\nEmployment History \n \n\n● Software Engineer with Indus Valley Partners Pvt Ltd Noida October  2017 To Till Date. \n \n\nTechnical Competencies \n \nDatabase  - MS-SQL 2012, 2016 \nLanguages  - C#, Python3 \nOS   - Window 7, 10, Windows XP \nTools   - SSIS, SSRS, Power BI, SQL Profiler, Chrome Dev Tools, MS-Excel \nRepository  - SVN \nTracking - JIRA, FogBugz \n \n\n \nProjects Assignments \n \n\nIVP Polaris(Jan 2018 till date) \n \nRole    - Developer \n \nDescription   - IVP Polaris is a data warehouse specifically designed for Alternative Asset Managers  \n\n         in multi-Strategy, multi-Counterparty environments.  \n           IVP Polaris enables hedge funds to support a host of middle office functions on a single,  \n\n            integrated database platform. IVP Polaris, also comes with a suite of pre-built business  \n          applications and reports that can reduce time-to-market and operational risk. \n \nResponsibilities - Client Interaction \n   Requirement gathering and analysis \n   Developing various SSRS reports along with the underlying database objects \n   Bug fixing and Enhancements \n   Testing of the SSRS and DB objects and deploying on DEV, UAT and Prod environments \n   Database backup and restore to various environments \n \nTeam size   - 5 \n \n \n \n \n \n\n\n\nIVP EDM(Feb 2018 - July 2018) \n \nRole    - Developer \n \nDescription -  IVP EDM(Enterprise data management) is an ETL tool that replaces the SSIS.  \n\nIt is used to fetch/upload data from/to various sources like files(CSV,Excel), FTP etc \napplying various validation and tranformations on the data and loading to database. \n \n\nResponsibilities -  Client Interaction \n   Requirement gathering and analysis \n   Worked on changing the ETL tool from SSIS to IVP EDM(Enterprise data management) \n \nTeam size  - 3 \n \nReal Time Ticket Reporting Dashboard(August 2018 till date) \n \nRole  - Developer \n \nDescription - An application that downloads ticket data from third party ticketing system at scheduled  \n\nintervals and on Ad-hoc requests. The dashboard is used to get the billability and work done on \nclients. \n \n\nResponsibilities - Requirement gathering and analysis. \nDatabase design and developement \n\n   Code written for consuming Web API. \n   Project Documentation \n \nTeam size - 2 \n \n\nEducational Qualifications \n \n\nGrade Percentage Institute Year of Passing \n\nB.Tech 80 % Chandigarh Group of Colleges 2018 \n\nSenior Secondary \nExamination \n\n72.2 % Sudesh Vakita Convent Sen. Sec. \nSchool \n\n2014 \n\nHigher Secondary \nExamination \n\n9.4 CGPA P.K.S. International School 2012 \n\n \n\nHobbies/Interpersonal Skills \n \n\n• Keen learner and good listener. \n\n• Meticulous planner and Team player \n\n• Browsing on internet to get updated with current affairs and issues. \n• Watching sports \n\n \n\nPersonal Information \n \n\n• Date of Birth        :  2nd March 1996                        \n\n• Gender/Marital Status  :  Male/Unmarried \n\n• Language Proficiency  :  English, Punjabi & Hindi     \n\n• Permanent Address :  #474 Near Bus Stand, V.P.O. Balluana (Bathinda)                                                    \n \n\nDeclaration \n\nI do hereby declare that the above information is true to the best of my knowledge. \n\n \n\n(Gurpreet Singh)","annotation":[{"label":["Name"],"points":[{"start":3902,"end":3915,"text":"Gurpreet Singh"}]},{"label":["10 %"],"points":[{"start":3196,"end":3269,"text":"Higher Secondary \nExamination \n\n9.4 CGPA P.K.S. International School 2012 "}]},{"label":["12 %"],"points":[{"start":3108,"end":3186,"text":"Senior Secondary \nExamination \n\n72.2 % Sudesh Vakita Convent Sen. Sec. \nSchool "}]},{"label":["Highest degree"],"points":[{"start":3015,"end":3105,"text":"Grade Percentage Institute Year of Passing \n\nB.Tech 80 % Chandigarh Group of Colleges 2018 "}]},{"label":["Total experience"],"points":[{"start":2606,"end":2801,"text":"n application that downloads ticket data from third party ticketing system at scheduled  \n\nintervals and on Ad-hoc requests. The dashboard is used to get the billability and work done on \nclients."}]},{"label":["Skills"],"points":[{"start":2442,"end":2445,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2138,"end":2141,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":1185,"end":1628,"text":"IVP Polaris is a data warehouse specifically designed for Alternative Asset Managers  \n\n         in multi-Strategy, multi-Counterparty environments.  \n           IVP Polaris enables hedge funds to support a host of middle office functions on a single,  \n\n            integrated database platform. IVP Polaris, also comes with a suite of pre-built business  \n          applications and reports that can reduce time-to-market and operational risk"}]},{"label":["Skills"],"points":[{"start":1026,"end":1033,"text":"MS-Excel"}]},{"label":["Skills"],"points":[{"start":984,"end":991,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":972,"end":975,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":884,"end":889,"text":"MS-SQL"}]},{"label":["Experience in current company"],"points":[{"start":778,"end":812,"text":"Indus Valley Partners Pvt Ltd Noida"}]},{"label":["Total experience"],"points":[{"start":398,"end":478,"text":"2+ years of experience in Information Technology Industry in Software Development"}]},{"label":["Total experience"],"points":[{"start":104,"end":364,"text":"Looking for a challenging career in IT industry which demands the best of my professional ability in terms of technical and \nanalytical skills and helps me in broadening and enhancing my current skill and knowledge that can provide benefits to the \norganization"}]},{"label":["Email"],"points":[{"start":58,"end":86,"text":"sidhu.gurpreet12221@gmail.com"}]},{"label":["Phone"],"points":[{"start":39,"end":48,"text":"7986475827"}]},{"label":["Phone"],"points":[{"start":27,"end":36,"text":"9855329665"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Gurpreet Singh"}]}],"extras":null,"metadata":{"first_done_at":1631183350000,"last_updated_at":1631183350000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
{"content": "Gurpreet Singh  \n\n \nPhone: 9855329665, 7986475827 \nEmail: sidhu.gurpreet12221@gmail.com \n \nObjective \n \nLooking for a challenging career in IT industry which demands the best of my professional ability in terms of technical and \nanalytical skills and helps me in broadening and enhancing my current skill and knowledge that can provide benefits to the \norganization. \n \n\nProfessional Summary \n \n\n● 2+ years of experience in Information Technology Industry in Software Development. \n● Currently working as Software Engineer with Indus Valley Partners, Noida. \n● Experience in backend database development. \n● Functional Knowledge of Hedge Fund eco system. \n● Worked for multiple American based Hedge Fund investing companies. \n\n \n\nEmployment History \n \n\n● Software Engineer with Indus Valley Partners Pvt Ltd Noida October  2017 To Till Date. \n \n\nTechnical Competencies \n \nDatabase  - MS-SQL 2012, 2016 \nLanguages  - C#, Python3 \nOS   - Window 7, 10, Windows XP \nTools   - SSIS, SSRS, Power BI, SQL Profiler, Chrome Dev Tools, MS-Excel \nRepository  - SVN \nTracking - JIRA, FogBugz \n \n\n \nProjects Assignments \n \n\nIVP Polaris(Jan 2018 till date) \n \nRole    - Developer \n \nDescription   - IVP Polaris is a data warehouse specifically designed for Alternative Asset Managers  \n\n         in multi-Strategy, multi-Counterparty environments.  \n           IVP Polaris enables hedge funds to support a host of middle office functions on a single,  \n\n            integrated database platform. IVP Polaris, also comes with a suite of pre-built business  \n          applications and reports that can reduce time-to-market and operational risk. \n \nResponsibilities - Client Interaction \n   Requirement gathering and analysis \n   Developing various SSRS reports along with the underlying database objects \n   Bug fixing and Enhancements \n   Testing of the SSRS and DB objects and deploying on DEV, UAT and Prod environments \n   Database backup and restore to various environments \n \nTeam size   - 5 \n \n \n \n \n \n\n\n\nIVP EDM(Feb 2018 - July 2018) \n \nRole    - Developer \n \nDescription -  IVP EDM(Enterprise data management) is an ETL tool that replaces the SSIS.  \n\nIt is used to fetch/upload data from/to various sources like files(CSV,Excel), FTP etc \napplying various validation and tranformations on the data and loading to database. \n \n\nResponsibilities -  Client Interaction \n   Requirement gathering and analysis \n   Worked on changing the ETL tool from SSIS to IVP EDM(Enterprise data management) \n \nTeam size  - 3 \n \nReal Time Ticket Reporting Dashboard(August 2018 till date) \n \nRole  - Developer \n \nDescription - An application that downloads ticket data from third party ticketing system at scheduled  \n\nintervals and on Ad-hoc requests. The dashboard is used to get the billability and work done on \nclients. \n \n\nResponsibilities - Requirement gathering and analysis. \nDatabase design and developement \n\n   Code written for consuming Web API. \n   Project Documentation \n \nTeam size - 2 \n \n\nEducational Qualifications \n \n\nGrade Percentage Institute Year of Passing \n\nB.Tech 80 % Chandigarh Group of Colleges 2018 \n\nSenior Secondary \nExamination \n\n72.2 % Sudesh Vakita Convent Sen. Sec. \nSchool \n\n2014 \n\nHigher Secondary \nExamination \n\n9.4 CGPA P.K.S. International School 2012 \n\n \n\nHobbies/Interpersonal Skills \n \n\n• Keen learner and good listener. \n\n• Meticulous planner and Team player \n\n• Browsing on internet to get updated with current affairs and issues. \n• Watching sports \n\n \n\nPersonal Information \n \n\n• Date of Birth        :  2nd March 1996                        \n\n• Gender/Marital Status  :  Male/Unmarried \n\n• Language Proficiency  :  English, Punjabi & Hindi     \n\n• Permanent Address :  #474 Near Bus Stand, V.P.O. Balluana (Bathinda)                                                    \n \n\nDeclaration \n\nI do hereby declare that the above information is true to the best of my knowledge. \n\n \n\n(Gurpreet Singh)","annotation":[{"label":["Name"],"points":[{"start":3902,"end":3915,"text":"Gurpreet Singh"}]},{"label":["10 %"],"points":[{"start":3228,"end":3268,"text":"9.4 CGPA P.K.S. International School 2012"}]},{"label":["12 %"],"points":[{"start":3140,"end":3193,"text":"72.2 % Sudesh Vakita Convent Sen. Sec. \nSchool \n\n2014 "}]},{"label":["Highest degree"],"points":[{"start":3060,"end":3123,"text":"B.Tech 80 % Chandigarh Group of Colleges 2018 \n\nSenior Secondary"}]},{"label":["Total experience"],"points":[{"start":2604,"end":2800,"text":" An application that downloads ticket data from third party ticketing system at scheduled  \n\nintervals and on Ad-hoc requests. The dashboard is used to get the billability and work done on \nclients"}]},{"label":["Skills"],"points":[{"start":2442,"end":2445,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":2138,"end":2141,"text":"SSIS"}]},{"label":["Total experience"],"points":[{"start":2069,"end":2317,"text":"IVP EDM(Enterprise data management) is an ETL tool that replaces the SSIS.  \n\nIt is used to fetch/upload data from/to various sources like files(CSV,Excel), FTP etc \napplying various validation and tranformations on the data and loading to database."}]},{"label":["Skills"],"points":[{"start":1841,"end":1844,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":1734,"end":1737,"text":"SSRS"}]},{"label":["Total experience"],"points":[{"start":1185,"end":1629,"text":"IVP Polaris is a data warehouse specifically designed for Alternative Asset Managers  \n\n         in multi-Strategy, multi-Counterparty environments.  \n           IVP Polaris enables hedge funds to support a host of middle office functions on a single,  \n\n            integrated database platform. IVP Polaris, also comes with a suite of pre-built business  \n          applications and reports that can reduce time-to-market and operational risk."}]},{"label":["Skills"],"points":[{"start":1026,"end":1033,"text":"MS-Excel"}]},{"label":["Skills"],"points":[{"start":994,"end":996,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":984,"end":991,"text":"Power BI"}]},{"label":["Skills"],"points":[{"start":978,"end":981,"text":"SSRS"}]},{"label":["Skills"],"points":[{"start":972,"end":975,"text":"SSIS"}]},{"label":["Skills"],"points":[{"start":920,"end":926,"text":"Python3"}]},{"label":["Skills"],"points":[{"start":916,"end":917,"text":"C#"}]},{"label":["Skills"],"points":[{"start":887,"end":889,"text":"SQL"}]},{"label":["Skills"],"points":[{"start":884,"end":889,"text":"MS-SQL"}]},{"label":["Experience in current company"],"points":[{"start":778,"end":812,"text":"Indus Valley Partners Pvt Ltd Noida"}]},{"label":["designation"],"points":[{"start":755,"end":771,"text":"Software Engineer"}]},{"label":["designation"],"points":[{"start":505,"end":521,"text":"Software Engineer"}]},{"label":["Total experience"],"points":[{"start":398,"end":478,"text":"2+ years of experience in Information Technology Industry in Software Development"}]},{"label":["Total experience"],"points":[{"start":104,"end":364,"text":"Looking for a challenging career in IT industry which demands the best of my professional ability in terms of technical and \nanalytical skills and helps me in broadening and enhancing my current skill and knowledge that can provide benefits to the \norganization"}]},{"label":["Email"],"points":[{"start":58,"end":86,"text":"sidhu.gurpreet12221@gmail.com"}]},{"label":["Phone"],"points":[{"start":39,"end":48,"text":"7986475827"}]},{"label":["Phone"],"points":[{"start":27,"end":36,"text":"9855329665"}]},{"label":["Name"],"points":[{"start":0,"end":13,"text":"Gurpreet Singh"}]}],"extras":null,"metadata":{"first_done_at":1631182539000,"last_updated_at":1631182539000,"sec_taken":0,"last_updated_by":"vikash.kumar@polestarllp.com","status":"done","evaluation":"NONE"}}
